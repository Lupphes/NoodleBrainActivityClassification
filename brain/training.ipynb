{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'preprocessing'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmodels\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbrain_solver\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m preprocess_eeg_data\n\u001b[1;32m     11\u001b[0m VER \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m\n",
      "File \u001b[0;32m~/NoodleNappers/brain/brain_solver/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m preprocess_eeg_data\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'preprocessing'"
     ]
    }
   ],
   "source": [
    "import os, gc\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1\"\n",
    "import pandas as pd, numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import numpy\n",
    "import torchvision.models as models\n",
    "\n",
    "from brain_solver import preprocess_eeg_data\n",
    "\n",
    "VER = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (106800, 15)\n",
      "Targets ['seizure_vote', 'lpd_vote', 'gpd_vote', 'lrda_vote', 'grda_vote', 'other_vote']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eeg_id</th>\n",
       "      <th>eeg_sub_id</th>\n",
       "      <th>eeg_label_offset_seconds</th>\n",
       "      <th>spectrogram_id</th>\n",
       "      <th>spectrogram_sub_id</th>\n",
       "      <th>spectrogram_label_offset_seconds</th>\n",
       "      <th>label_id</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>expert_consensus</th>\n",
       "      <th>seizure_vote</th>\n",
       "      <th>lpd_vote</th>\n",
       "      <th>gpd_vote</th>\n",
       "      <th>lrda_vote</th>\n",
       "      <th>grda_vote</th>\n",
       "      <th>other_vote</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1628180742</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>353733</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>127492639</td>\n",
       "      <td>42516</td>\n",
       "      <td>Seizure</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1628180742</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>353733</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3887563113</td>\n",
       "      <td>42516</td>\n",
       "      <td>Seizure</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1628180742</td>\n",
       "      <td>2</td>\n",
       "      <td>8.0</td>\n",
       "      <td>353733</td>\n",
       "      <td>2</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1142670488</td>\n",
       "      <td>42516</td>\n",
       "      <td>Seizure</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1628180742</td>\n",
       "      <td>3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>353733</td>\n",
       "      <td>3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2718991173</td>\n",
       "      <td>42516</td>\n",
       "      <td>Seizure</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1628180742</td>\n",
       "      <td>4</td>\n",
       "      <td>24.0</td>\n",
       "      <td>353733</td>\n",
       "      <td>4</td>\n",
       "      <td>24.0</td>\n",
       "      <td>3080632009</td>\n",
       "      <td>42516</td>\n",
       "      <td>Seizure</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       eeg_id  eeg_sub_id  eeg_label_offset_seconds  spectrogram_id  \\\n",
       "0  1628180742           0                       0.0          353733   \n",
       "1  1628180742           1                       6.0          353733   \n",
       "2  1628180742           2                       8.0          353733   \n",
       "3  1628180742           3                      18.0          353733   \n",
       "4  1628180742           4                      24.0          353733   \n",
       "\n",
       "   spectrogram_sub_id  spectrogram_label_offset_seconds    label_id  \\\n",
       "0                   0                               0.0   127492639   \n",
       "1                   1                               6.0  3887563113   \n",
       "2                   2                               8.0  1142670488   \n",
       "3                   3                              18.0  2718991173   \n",
       "4                   4                              24.0  3080632009   \n",
       "\n",
       "   patient_id expert_consensus  seizure_vote  lpd_vote  gpd_vote  lrda_vote  \\\n",
       "0       42516          Seizure             3         0         0          0   \n",
       "1       42516          Seizure             3         0         0          0   \n",
       "2       42516          Seizure             3         0         0          0   \n",
       "3       42516          Seizure             3         0         0          0   \n",
       "4       42516          Seizure             3         0         0          0   \n",
       "\n",
       "   grda_vote  other_vote  \n",
       "0          0           0  \n",
       "1          0           0  \n",
       "2          0           0  \n",
       "3          0           0  \n",
       "4          0           0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/hms-harmful-brain-activity-classification/train.csv')\n",
    "\n",
    "TARGETS = df.columns[-6:]\n",
    "print('Train shape:', df.shape )\n",
    "print('Targets', list(TARGETS))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Create Non-Overlapping Eeg Id Train Data\n",
    "The competition data description says that test data does not have multiple crops from the same eeg_id. Therefore we will train and validate using only 1 crop per eeg_id. There is a discussion about this here.\n",
    "https://www.kaggle.com/competitions/hms-harmful-brain-activity-classification/discussion/467021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'preprocess_eeg_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mpreprocess_eeg_data\u001b[49m(df, TARGETS, consensus_col\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexpert_consensus\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'preprocess_eeg_data' is not defined"
     ]
    }
   ],
   "source": [
    "preprocess_eeg_data(df, TARGETS, consensus_col='expert_consensus')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create ResNet18 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/pytorch/vision/zipball/v0.10.0\" to /home/osloup/.cache/torch/hub/v0.10.0.zip\n",
      "/home/osloup/NoodleNappers/brain/venv/lib64/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/osloup/NoodleNappers/brain/venv/lib64/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /home/osloup/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
      "100%|██████████| 44.7M/44.7M [00:01<00:00, 43.8MB/s]\n"
     ]
    }
   ],
   "source": [
    "# Model creation\n",
    "model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet18', pretrained=True) # Can change to 152 or some other version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, data_loaders, epochs=100, lr=0.01, device=d2l.try_gpu()):\n",
    "    # Trains the model net with data from the data_loaders['train'] and data_loaders['val'].\n",
    "    net = net.to(device)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "\n",
    "    animator = d2l.Animator(xlabel='epoch',\n",
    "                            legend=['train loss', 'train acc', 'validation loss', 'validation acc'],\n",
    "                            figsize=(10, 5))\n",
    "\n",
    "    timer = {'train': d2l.Timer(), 'val': d2l.Timer()}\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # monitor loss, accuracy, number of samples\n",
    "        metrics = {'train': d2l.Accumulator(3), 'val': d2l.Accumulator(3)}\n",
    "\n",
    "        for phase in ('train', 'val'):\n",
    "            # switch network to train/eval mode\n",
    "            net.train(phase == 'train')\n",
    "\n",
    "            for i, (x, y) in enumerate(data_loaders[phase]):\n",
    "                timer[phase].start()\n",
    "\n",
    "                # move to device\n",
    "                x = x.to(device)\n",
    "                y = y.to(device)\n",
    "\n",
    "                # compute prediction\n",
    "                y_hat = net(x)\n",
    "                \n",
    "                if y_hat.shape[1] == 1:\n",
    "                    # compute binary cross-entropy loss\n",
    "                    loss = torch.nn.BCEWithLogitsLoss()(y_hat[:, 0], y.to(torch.float))\n",
    "                else:\n",
    "                    # compute cross-entropy loss\n",
    "                    loss = torch.nn.CrossEntropyLoss()(y_hat, y)\n",
    "\n",
    "                if phase == 'train':\n",
    "                    # compute gradients and update weights\n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                metrics[phase].add(loss * x.shape[0],\n",
    "                                   accuracy(y_hat, y) * x.shape[0],\n",
    "                                   x.shape[0])\n",
    "\n",
    "                timer[phase].stop()\n",
    "\n",
    "        animator.add(epoch + 1,\n",
    "            (metrics['train'][0] / metrics['train'][2],\n",
    "             metrics['train'][1] / metrics['train'][2],\n",
    "             metrics['val'][0] / metrics['val'][2],\n",
    "             metrics['val'][1] / metrics['val'][2]))\n",
    "\n",
    "    train_loss = metrics['train'][0] / metrics['train'][2]\n",
    "    train_acc  = metrics['train'][1] / metrics['train'][2]\n",
    "    val_loss   = metrics['val'][0] / metrics['val'][2]\n",
    "    val_acc    = metrics['val'][1] / metrics['val'][2]\n",
    "    examples_per_sec = metrics['train'][2] * epochs / timer['train'].sum()\n",
    "    \n",
    "    print(f'train loss {train_loss:.3f}, train acc {train_acc:.3f}, '\n",
    "          f'val loss {val_loss:.3f}, val acc {val_acc:.3f}')\n",
    "    print(f'{examples_per_sec:.1f} examples/sec '\n",
    "          f'on {str(device)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
