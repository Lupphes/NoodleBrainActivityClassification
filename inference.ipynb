{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Brain Solver Python Inference Notebook\n",
    "\n",
    "This notebook utilizes the custom `brain_solver` package for analyzing brain activity data. Our data sources include official datasets from Kaggle competitions and additional datasets for enhanced model training and evaluation.\n",
    "\n",
    "This is the Inference notebook.\n",
    "\n",
    "**Authors: Luppo Sloup, Dick Blankvoort, Tygo Francissen (MLiP Group 9)**\n",
    "\n",
    "## Data Sources\n",
    "\n",
    "### Official:\n",
    "\n",
    "- **HMS - Harmful Brain Activity Classification**\n",
    "  - **Source:** [Kaggle Competition](https://www.kaggle.com/competitions/hms-harmful-brain-activity-classification)\n",
    "  - **Description:** This competition focuses on classifying harmful brain activity. It includes a comprehensive dataset for training and testing models.\n",
    "\n",
    "- **Brain-Spectrograms**\n",
    "  - **Source:** [Kaggle Dataset](https://www.kaggle.com/datasets/cdeotte/brain-spectrograms)\n",
    "  - **Description:** The `specs.npy` file contains all the spectrograms from the HMS competition, offering a detailed view of brain activity through visual representations.\n",
    "\n",
    "### Additional:\n",
    "\n",
    "- **Brain-EEG-Spectrograms**\n",
    "  - **Source:** [Kaggle Dataset](https://www.kaggle.com/datasets/cdeotte/brain-eeg-spectrograms)\n",
    "  - **Description:** The `EEG_Spectrograms` folder includes one NumPy file per EEG ID, with each array shaped as (128x256x4), representing (frequency, time, montage chain). This dataset provides a more nuanced understanding of brain activity through EEG spectrograms. They were created based on the raw data.\n",
    "\n",
    "- **hms_efficientnetb0_pt_ckpts**\n",
    "  - **Source:** [Kaggle Dataset](https://www.kaggle.com/datasets/crackle/hms-efficientnetb0-pt-ckpts)\n",
    "  - **Description:** This dataset offers pre-trained checkpoints for EfficientNetB0 models, tailored for the HMS competition. It's intended for use in fine-tuning models on the specific task of harmful brain activity classification.\n",
    "\n",
    "### Overview:\n",
    "\n",
    "In addition to the data sources above, the following inputs are needed for this notebook:\n",
    "\n",
    "<img src=\"images/overview_inference.png\" alt=\"overview2\" width=\"250\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These commands install the packages that are required for the notebook, should only be used when running the notebook on Kaggle\n",
    "!pip install d2l --no-index --find-links=file:///kaggle/input/d2l-package/d2l/\n",
    "!pip install /kaggle/input/brain-solver/brain_solver-1.0.0-py3-none-any.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports for the notebook\n",
    "import os, sys, gc, torch, warnings\n",
    "import numpy as np, pandas as pd, pytorch_lightning as pl\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers.utils import logging\n",
    "from brain_solver import (\n",
    "    Helpers as hp,\n",
    "    EEGDataset,\n",
    "    Config,\n",
    "    Trainer as tr,\n",
    ")\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "logging.set_verbosity(logging.CRITICAL)\n",
    "\n",
    "# Setup for CUDA device selection\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config Class Summary\n",
    "\n",
    "The `Config` class manages configurations for the brain activity classification project. It includes:\n",
    "\n",
    "- **Data and Model Paths**: Centralizes paths for data (e.g., EEG, spectrograms) and model checkpoints.\n",
    "- **Training Parameters**: Configures training details like epochs, batch size, and learning rate.\n",
    "- **Feature Flags**: Toggles for using model settings, wavelets, spectrograms, and reading options.\n",
    "\n",
    "We designed this class for easy adjustments to facilitate model development and experimentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Possibility to set a local path for the data\n",
    "full_path = \"\"\n",
    "config = Config(\n",
    "    full_path,\n",
    "    full_path + \"out/\",\n",
    "    USE_EEG_SPECTROGRAMS=True,\n",
    "    USE_KAGGLE_SPECTROGRAMS=True,\n",
    "    should_read_brain_spectograms=False,\n",
    "    should_read_eeg_spectrogram_files=False,\n",
    "    USE_PRETRAINED_MODEL=False,\n",
    "    FINE_TUNE=False,\n",
    ")\n",
    "\n",
    "# Path to set for Kaggle\n",
    "full_path = \"/kaggle/input/\"\n",
    "config = Config(\n",
    "    full_path,\n",
    "    \"/kaggle/working/\",\n",
    "    USE_EEG_SPECTROGRAMS=True,\n",
    "    USE_KAGGLE_SPECTROGRAMS=True,\n",
    "    should_read_brain_spectograms=False,\n",
    "    should_read_eeg_spectrogram_files=False,\n",
    "    USE_PRETRAINED_MODEL=False,\n",
    "    FINE_TUNE=False,\n",
    ")\n",
    "\n",
    "# Load scoring function\n",
    "sys.path.append(full_path + \"kaggle-kl-div\")\n",
    "from kaggle_kl_div import score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output folder if it does not exist\n",
    "if not os.path.exists(config.output_path):\n",
    "    os.makedirs(config.output_path)\n",
    "\n",
    "# Initialize random environment\n",
    "pl.seed_everything(config.seed, workers=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the train CSV file\n",
    "train_df: pd.DataFrame = hp.load_csv(config.data_train_csv)\n",
    "\n",
    "if train_df is None:\n",
    "    print(\"Failed to load the CSV file.\")\n",
    "    exit()\n",
    "else:\n",
    "    EEG_IDS = train_df.eeg_id.unique()\n",
    "    TARGETS = train_df.columns[-6:]\n",
    "    TARS = {\"Seizure\": 0, \"LPD\": 1, \"GPD\": 2, \"LRDA\": 3, \"GRDA\": 4, \"Other\": 5}\n",
    "    TARS_INV = {x: y for y, x in TARS.items()}\n",
    "    print(\"Train shape:\", train_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the test CSV file\n",
    "test_df = pd.read_csv(config.data_test_csv)\n",
    "print(\"Test shape\", test_df.shape)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the Kaggle spectrograms\n",
    "spectrograms2 = hp.read_spectrograms(\n",
    "    path=config.data_spectograms_test,\n",
    "    data_path_train_on_brain_spectograms_dataset_specs=None,\n",
    "    read_files=True,\n",
    ")\n",
    "\n",
    "# Continue with renaming for DataLoader\n",
    "test_df = test_df.rename({\"spectrogram_id\": \"spec_id\"}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the EEG spectrograms\n",
    "DISPLAY = 1\n",
    "EEG_IDS2 = test_df.eeg_id.unique()\n",
    "all_eegs2 = {}\n",
    "\n",
    "print(\"Converting Test EEG to Spectrograms...\")\n",
    "print()\n",
    "for i, eeg_id in enumerate(EEG_IDS2):\n",
    "    # Create spectogram from EEG parquet file\n",
    "    img = hp.spectrogram_from_eeg(f\"{config.data_eeg_test}{eeg_id}.parquet\", i < DISPLAY, config.use_wavelet)\n",
    "    all_eegs2[eeg_id] = img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Infer efficientNet on test data\n",
    "preds = []\n",
    "test_ds = EEGDataset(test_df, specs=spectrograms2, eeg_specs=all_eegs2, targets=TARGETS, mode=\"test\")\n",
    "test_loader = DataLoader(test_ds, shuffle=False, batch_size=64, num_workers=3)\n",
    "\n",
    "for i in range(5):\n",
    "    print(\"#\" * 25)\n",
    "    print(f\"### Testing Fold {i+1}\")\n",
    "\n",
    "    ckpt_file = (\n",
    "        f\"EffNet_version{config.VER}_fold{i+1}.pth\"\n",
    "        if config.trained_model_path is None or config.FINE_TUNE\n",
    "        else f\"{config.trained_model_path}/EffNet_v{config.VER}_f{i}.ckpt\"\n",
    "    )\n",
    "\n",
    "    if config.trained_model_path is None or config.FINE_TUNE:\n",
    "        model = torch.load(config.full_path + \"trained-model-effnet-mlip9/\" + ckpt_file)\n",
    "    else:\n",
    "        model = tr.load_from_checkpoint(\n",
    "        ckpt_file, weight_file=config.trained_weight_file,  use_kaggle_spectrograms=config.USE_KAGGLE_SPECTROGRAMS, use_eeg_spectrograms=config.USE_EEG_SPECTROGRAMS\n",
    "    )\n",
    "    model = model.to(device).eval()\n",
    "    fold_preds = []\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        for test_batch in test_loader:\n",
    "            test_batch = test_batch.to(device)\n",
    "            pred = torch.softmax(model(test_batch), dim=1).cpu().numpy()\n",
    "            fold_preds.append(pred)\n",
    "\n",
    "            # Delete variables not needed to free up memory\n",
    "            del test_batch, pred\n",
    "            gc.collect()  # Manually collect garbage\n",
    "\n",
    "            if device.type == \"cuda\":  # Optionally clear CUDA cache if using GPU\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "        fold_preds = np.concatenate(fold_preds)\n",
    "\n",
    "    preds.append(fold_preds)\n",
    "\n",
    "    del model\n",
    "    gc.collect()\n",
    "    if device.type == \"cuda\":\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "# Print a prediction and the shape of the predictions\n",
    "pred = np.mean(preds, axis=0)\n",
    "print()\n",
    "print(\"Test preds shape\", pred.shape)\n",
    "pred[0][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a submission file\n",
    "sub = pd.DataFrame({\"eeg_id\": test_df.eeg_id.values})\n",
    "sub[TARGETS] = pred\n",
    "sub.to_csv(\"submission.csv\", index=False)\n",
    "print(\"Submissionn shape\", sub.shape)\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check to confirm that the sum of the predictions is 1\n",
    "sub.iloc[:, -6:].sum(axis=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
