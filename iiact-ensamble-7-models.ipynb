{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5ce3a2c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-10T18:31:10.935579Z",
     "iopub.status.busy": "2024-03-10T18:31:10.935226Z",
     "iopub.status.idle": "2024-03-10T18:31:10.956617Z",
     "shell.execute_reply": "2024-03-10T18:31:10.955380Z",
     "shell.execute_reply.started": "2024-03-10T18:31:10.935549Z"
    },
    "papermill": {
     "duration": 0.0363,
     "end_time": "2024-03-13T22:58:47.603225",
     "exception": false,
     "start_time": "2024-03-13T22:58:47.566925",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# IIACT: Ensemble for HMS Brain Comp by MLiP team\n",
    "This is combination and ensemble notebook for Kaggle's HMS brain comp. based on [Previous Notebook](https://www.kaggle.com/code/luepoe/iiact-ensamble-features-head-starter) and [Thisone](https://www.kaggle.com/code/anilyagiz/hms-multiple-model-ensemble-4-notebooks-19b844) \n",
    "\n",
    "\n",
    "- https://www.kaggle.com/code/cdeotte/efficientnetb0-starter-lb-0-43 (That is the our model and our code)\n",
    "- https://www.kaggle.com/code/yunsuxiaozi/hms-baseline-resnet34d-512-512-inference-6-models\n",
    "- https://www.kaggle.com/code/andreasbis/hms-inference-lb-0-41\n",
    "- https://www.kaggle.com/code/nartaa/features-head-starter-lb-0-36\n",
    "\n",
    "Extra that needs to be added to this so its more vertasille:\n",
    "- [LB 0.46] DilatedInception WaveNet - Inference (https://www.kaggle.com/code/abaojiang/lb-0-46-dilatedinception-wavenet-inference/notebook?scriptVersionId=163448688)\n",
    "- CatBoost Starter - [LB 0.60]: [Notebook][https://www.kaggle.com/code/cdeotte/catboost-starter-lb-0-60] and our trained dataset on this\n",
    "\n",
    "**The Ensemble achieves LB 0.34** \n",
    "\n",
    "Features+Head Starter uses Chris Deotte's Kaggle dataset [here][1]. Also Uses Chris's EEG spectrograms [here][3] (modified version) \n",
    "\n",
    "This notebook is based on the work of JIYUANZHANG, found [here](https://www.kaggle.com/code/kitsuha/3-model-ensemble-lb-0-37)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3556644",
   "metadata": {
    "papermill": {
     "duration": 0.034444,
     "end_time": "2024-03-13T22:58:47.670280",
     "exception": false,
     "start_time": "2024-03-13T22:58:47.635836",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Intro and Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e086e41b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T22:58:47.739472Z",
     "iopub.status.busy": "2024-03-13T22:58:47.739089Z",
     "iopub.status.idle": "2024-03-13T22:59:40.226946Z",
     "shell.execute_reply": "2024-03-13T22:59:40.225668Z"
    },
    "papermill": {
     "duration": 52.525384,
     "end_time": "2024-03-13T22:59:40.229321",
     "exception": false,
     "start_time": "2024-03-13T22:58:47.703937",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %pip install d2l --no-index --find-links=file:///kaggle/input/d2l-package/d2l/\n",
    "# %pip install /kaggle/input/brain-solver/brain_solver-0.9.0-py3-none-any.whl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c2bf07",
   "metadata": {
    "papermill": {
     "duration": 0.041551,
     "end_time": "2024-03-13T22:59:40.312534",
     "exception": false,
     "start_time": "2024-03-13T22:59:40.270983",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Config Class Summary\n",
    "\n",
    "The `Config` class manages configurations for a brain activity classification project. It includes:\n",
    "\n",
    "- **Data and Model Paths**: Centralizes paths for data (e.g., EEG, spectrograms) and model checkpoints.\n",
    "- **Training Parameters**: Configures training details like epochs, batch size, and learning rate.\n",
    "- **Feature Flags**: Toggles for using wavelets, spectrograms, and reading options.\n",
    "\n",
    "Designed for easy adjustments to facilitate model development and experimentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ee87b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T22:59:40.397220Z",
     "iopub.status.busy": "2024-03-13T22:59:40.396813Z",
     "iopub.status.idle": "2024-03-13T22:59:58.763743Z",
     "shell.execute_reply": "2024-03-13T22:59:58.762786Z"
    },
    "papermill": {
     "duration": 18.413167,
     "end_time": "2024-03-13T22:59:58.766320",
     "exception": false,
     "start_time": "2024-03-13T22:59:40.353153",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from brain_solver import Config\n",
    "\n",
    "full_path = \"/home/osloup/NoodleNappers/data/\" # Luppo\n",
    "# full_path = \"C:/Users/tygof/Documents/Semester 8/MLiP/NoodleNappers/data/\" # Tygo\n",
    "# full_path = \"C:/Users/dahbl/Documents/TrueDocs/Uni/Year 4/Semester 2/Machine Learning in Practice/brain/data/\" # Dick\n",
    "config = Config(full_path,  full_path + \"out/\", USE_EEG_SPECTROGRAMS=True, USE_KAGGLE_SPECTROGRAMS=True, should_read_brain_spectograms=False, should_read_eeg_spectrogram_files=False, USE_PRETRAINED_MODEL=True, FINE_TUNE=True)\n",
    "\n",
    "# Kaggle Pull\n",
    "# full_path = \"/kaggle/input/\"\n",
    "# config = Config(\n",
    "#     full_path,\n",
    "#     \"/kaggle/working/\",\n",
    "#     USE_EEG_SPECTROGRAMS=False,\n",
    "#     VER=5,\n",
    "#     USE_KAGGLE_SPECTROGRAMS=True,\n",
    "#     should_read_brain_spectograms=False,\n",
    "#     should_read_eeg_spectrogram_files=False,\n",
    "#     USE_PRETRAINED_MODEL=False,\n",
    "# )\n",
    "\n",
    "import sys\n",
    "\n",
    "# sys.path.append(full_path + \"kaggle-kl-div\")\n",
    "# from kaggle_kl_div import score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb1235e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T22:59:58.849516Z",
     "iopub.status.busy": "2024-03-13T22:59:58.848900Z",
     "iopub.status.idle": "2024-03-13T22:59:58.867633Z",
     "shell.execute_reply": "2024-03-13T22:59:58.866701Z"
    },
    "papermill": {
     "duration": 0.062617,
     "end_time": "2024-03-13T22:59:58.869889",
     "exception": false,
     "start_time": "2024-03-13T22:59:58.807272",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "# Create Output folder if does not exist\n",
    "if not os.path.exists(config.output_path):\n",
    "    os.makedirs(config.output_path)\n",
    "\n",
    "# Initialize random environment\n",
    "pl.seed_everything(config.seed, workers=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a881856f",
   "metadata": {
    "papermill": {
     "duration": 0.039994,
     "end_time": "2024-03-13T22:59:58.950408",
     "exception": false,
     "start_time": "2024-03-13T22:59:58.910414",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model 1 - Starter/Ours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3016caa9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T22:59:59.035207Z",
     "iopub.status.busy": "2024-03-13T22:59:59.034803Z",
     "iopub.status.idle": "2024-03-13T22:59:59.128975Z",
     "shell.execute_reply": "2024-03-13T22:59:59.128042Z"
    },
    "papermill": {
     "duration": 0.138669,
     "end_time": "2024-03-13T22:59:59.131138",
     "exception": false,
     "start_time": "2024-03-13T22:59:58.992469",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import pytorch_lightning as pl\n",
    "from brain_solver import (\n",
    "    Helpers as hp,\n",
    "    Trainer as tr,\n",
    "    BrainModel as br,\n",
    "    EEGDataset,\n",
    "    Network,\n",
    ")\n",
    "from brain_solver import Wav2Vec2 as w2v\n",
    "from brain_solver import Filters, FilterType\n",
    "from transformers.utils import logging\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Suppress warnings if desired\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "logging.set_verbosity(logging.CRITICAL)\n",
    "\n",
    "# Setup for CUDA device selection\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42aae80f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T22:59:59.214250Z",
     "iopub.status.busy": "2024-03-13T22:59:59.213632Z",
     "iopub.status.idle": "2024-03-13T22:59:59.550458Z",
     "shell.execute_reply": "2024-03-13T22:59:59.549160Z"
    },
    "papermill": {
     "duration": 0.38124,
     "end_time": "2024-03-13T22:59:59.552680",
     "exception": false,
     "start_time": "2024-03-13T22:59:59.171440",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df: pd.DataFrame = hp.load_csv(config.data_train_csv)\n",
    "test_df = pd.read_csv(config.data_test_csv)\n",
    "\n",
    "if train_df is None:\n",
    "    print(\"Failed to load the CSV file.\")\n",
    "    exit()\n",
    "else:\n",
    "    EEG_IDS = train_df.eeg_id.unique()\n",
    "    TARGETS = train_df.columns[-6:]\n",
    "    TARS = {\"Seizure\": 0, \"LPD\": 1, \"GPD\": 2, \"LRDA\": 3, \"GRDA\": 4, \"Other\": 5}\n",
    "    TARS_INV = {x: y for y, x in TARS.items()}\n",
    "    print(\"Train shape:\", train_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26af9190",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T22:59:59.638813Z",
     "iopub.status.busy": "2024-03-13T22:59:59.637760Z",
     "iopub.status.idle": "2024-03-13T22:59:59.911630Z",
     "shell.execute_reply": "2024-03-13T22:59:59.910778Z"
    },
    "papermill": {
     "duration": 0.318369,
     "end_time": "2024-03-13T22:59:59.913993",
     "exception": false,
     "start_time": "2024-03-13T22:59:59.595624",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "spectrograms = hp.read_spectrograms(\n",
    "    path=config.data_spectograms_test,\n",
    "    data_path_train_on_brain_spectograms_dataset_specs=None,\n",
    "    read_files=True,\n",
    ")\n",
    "\n",
    "# Continue with renaming for DataLoader\n",
    "test_df = test_df.rename({\"spectrogram_id\": \"spec_id\"}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4202e216",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T22:59:59.999387Z",
     "iopub.status.busy": "2024-03-13T22:59:59.998975Z",
     "iopub.status.idle": "2024-03-13T23:00:11.419519Z",
     "shell.execute_reply": "2024-03-13T23:00:11.418103Z"
    },
    "papermill": {
     "duration": 11.467825,
     "end_time": "2024-03-13T23:00:11.423683",
     "exception": false,
     "start_time": "2024-03-13T22:59:59.955858",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# READ ALL EEG SPECTROGRAMS\n",
    "DISPLAY = 1\n",
    "EEG_IDS2 = test_df.eeg_id.unique()\n",
    "all_eegs2 = {}\n",
    "\n",
    "print(\"Converting Test EEG to Spectrograms...\")\n",
    "for i, eeg_id in enumerate(EEG_IDS2):\n",
    "    all_eegs2[eeg_id] = hp.spectrogram_from_eeg(\n",
    "        f\"{config.data_eeg_test}{eeg_id}.parquet\", False, config.use_wavelet\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68791302",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T23:00:11.577035Z",
     "iopub.status.busy": "2024-03-13T23:00:11.576433Z",
     "iopub.status.idle": "2024-03-13T23:00:19.000421Z",
     "shell.execute_reply": "2024-03-13T23:00:18.999329Z"
    },
    "papermill": {
     "duration": 7.483679,
     "end_time": "2024-03-13T23:00:19.003359",
     "exception": false,
     "start_time": "2024-03-13T23:00:11.519680",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# INFER EFFICIENTNET ON TEST\n",
    "preds = []\n",
    "test_ds = EEGDataset(\n",
    "    test_df, specs=spectrograms, eeg_specs=all_eegs2, targets=TARGETS, mode=\"test\"\n",
    ")\n",
    "test_loader = DataLoader(test_ds, shuffle=False, batch_size=64, num_workers=3)\n",
    "\n",
    "for i in range(5):\n",
    "    print(\"#\" * 25)\n",
    "    print(f\"### Testing Fold {i+1}\")\n",
    "\n",
    "    ckpt_file = (\n",
    "        f\"EffNet_version{config.VER}_fold{i+1}.pth\"\n",
    "    )\n",
    "    model = torch.load(config.full_path + \"trained-model-effnet-mlip9/\" + ckpt_file)\n",
    "    model = model.to(device).eval()\n",
    "    fold_preds = []\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        for test_batch in test_loader:\n",
    "            test_batch = test_batch.to(device)\n",
    "            pred = torch.softmax(model(test_batch), dim=1).cpu().numpy()\n",
    "            fold_preds.append(pred)\n",
    "\n",
    "            # Delete variables not needed to free up memory\n",
    "            del test_batch, pred\n",
    "            gc.collect()  # Manually collect garbage\n",
    "\n",
    "            if device.type == \"cuda\":  # Optionally clear CUDA cache if using GPU\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "        fold_preds = np.concatenate(fold_preds)\n",
    "\n",
    "    preds.append(fold_preds)\n",
    "\n",
    "    del model\n",
    "    gc.collect()\n",
    "    if device.type == \"cuda\":\n",
    "        torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910d2f50",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T23:00:19.091499Z",
     "iopub.status.busy": "2024-03-13T23:00:19.090702Z",
     "iopub.status.idle": "2024-03-13T23:00:19.097389Z",
     "shell.execute_reply": "2024-03-13T23:00:19.096280Z"
    },
    "papermill": {
     "duration": 0.052481,
     "end_time": "2024-03-13T23:00:19.099630",
     "exception": false,
     "start_time": "2024-03-13T23:00:19.047149",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pred_model1 = np.mean(preds, axis=0)\n",
    "print()\n",
    "print(\"Test preds shape\", pred_model1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f731eee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T23:00:19.187105Z",
     "iopub.status.busy": "2024-03-13T23:00:19.186225Z",
     "iopub.status.idle": "2024-03-13T23:00:19.192188Z",
     "shell.execute_reply": "2024-03-13T23:00:19.191178Z"
    },
    "papermill": {
     "duration": 0.053073,
     "end_time": "2024-03-13T23:00:19.194376",
     "exception": false,
     "start_time": "2024-03-13T23:00:19.141303",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Continue with renaming for DataLoader\n",
    "test_df = test_df.rename({\"spec_id\": \"spectrogram_id\"}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dadb5d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T23:00:19.281294Z",
     "iopub.status.busy": "2024-03-13T23:00:19.280447Z",
     "iopub.status.idle": "2024-03-13T23:00:19.285237Z",
     "shell.execute_reply": "2024-03-13T23:00:19.284231Z"
    },
    "papermill": {
     "duration": 0.050763,
     "end_time": "2024-03-13T23:00:19.287415",
     "exception": false,
     "start_time": "2024-03-13T23:00:19.236652",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# sub1 = pd.DataFrame({\"eeg_id\": test_df.eeg_id.values})\n",
    "# sub1[TARGETS] = pred_model1[0]\n",
    "# sub1.to_csv(\"submission_model1.csv\", index=False)\n",
    "# print(\"Submissionn shape\", sub1.shape)\n",
    "# sub1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad99150",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T23:00:19.373849Z",
     "iopub.status.busy": "2024-03-13T23:00:19.372963Z",
     "iopub.status.idle": "2024-03-13T23:00:19.379927Z",
     "shell.execute_reply": "2024-03-13T23:00:19.379051Z"
    },
    "papermill": {
     "duration": 0.051397,
     "end_time": "2024-03-13T23:00:19.382227",
     "exception": false,
     "start_time": "2024-03-13T23:00:19.330830",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pred_model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2fe1c4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T23:00:19.466865Z",
     "iopub.status.busy": "2024-03-13T23:00:19.466523Z",
     "iopub.status.idle": "2024-03-13T23:00:19.470686Z",
     "shell.execute_reply": "2024-03-13T23:00:19.469765Z"
    },
    "papermill": {
     "duration": 0.047687,
     "end_time": "2024-03-13T23:00:19.472685",
     "exception": false,
     "start_time": "2024-03-13T23:00:19.424998",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # SANITY CHECK TO CONFIRM PREDICTIONS SUM TO ONE\n",
    "# sub1.iloc[:, -6:].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f65b76c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T23:00:19.554732Z",
     "iopub.status.busy": "2024-03-13T23:00:19.554400Z",
     "iopub.status.idle": "2024-03-13T23:00:19.794501Z",
     "shell.execute_reply": "2024-03-13T23:00:19.793379Z"
    },
    "papermill": {
     "duration": 0.284184,
     "end_time": "2024-03-13T23:00:19.796690",
     "exception": false,
     "start_time": "2024-03-13T23:00:19.512506",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "del spectrograms, all_eegs2\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09eebc54",
   "metadata": {
    "papermill": {
     "duration": 0.043311,
     "end_time": "2024-03-13T23:00:19.884984",
     "exception": false,
     "start_time": "2024-03-13T23:00:19.841673",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model 2 - ResNet34d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c648d6f6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T23:00:19.973378Z",
     "iopub.status.busy": "2024-03-13T23:00:19.972581Z",
     "iopub.status.idle": "2024-03-13T23:00:19.978591Z",
     "shell.execute_reply": "2024-03-13T23:00:19.977596Z"
    },
    "papermill": {
     "duration": 0.052526,
     "end_time": "2024-03-13T23:00:19.980702",
     "exception": false,
     "start_time": "2024-03-13T23:00:19.928176",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import random\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992b69d9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T23:00:20.068616Z",
     "iopub.status.busy": "2024-03-13T23:00:20.068223Z",
     "iopub.status.idle": "2024-03-13T23:00:20.073356Z",
     "shell.execute_reply": "2024-03-13T23:00:20.072346Z"
    },
    "papermill": {
     "duration": 0.052426,
     "end_time": "2024-03-13T23:00:20.075535",
     "exception": false,
     "start_time": "2024-03-13T23:00:20.023109",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_transform = transforms.Resize((512, 512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34369fbe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T23:00:20.164720Z",
     "iopub.status.busy": "2024-03-13T23:00:20.163764Z",
     "iopub.status.idle": "2024-03-13T23:00:28.586287Z",
     "shell.execute_reply": "2024-03-13T23:00:28.585253Z"
    },
    "papermill": {
     "duration": 8.470545,
     "end_time": "2024-03-13T23:00:28.588893",
     "exception": false,
     "start_time": "2024-03-13T23:00:20.118348",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "models = []\n",
    "for i in range(config.num_folds):\n",
    "    model = torch.load(f\"{config.resnet34d}HMS_resnet_fold{i}.pth\")\n",
    "    models.append(model)\n",
    "model = torch.load(\n",
    "    f\"{config.full_path}hms-baseline-resnet34d-512-512-training/HMS_resnet.pth\"\n",
    ")\n",
    "models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16fcfb02",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T23:00:28.677248Z",
     "iopub.status.busy": "2024-03-13T23:00:28.676258Z",
     "iopub.status.idle": "2024-03-13T23:00:28.682712Z",
     "shell.execute_reply": "2024-03-13T23:00:28.681554Z"
    },
    "papermill": {
     "duration": 0.053765,
     "end_time": "2024-03-13T23:00:28.684932",
     "exception": false,
     "start_time": "2024-03-13T23:00:28.631167",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "\n",
    "\n",
    "seed_everything(config.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c3ade9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T23:00:28.766932Z",
     "iopub.status.busy": "2024-03-13T23:00:28.766564Z",
     "iopub.status.idle": "2024-03-13T23:00:28.809084Z",
     "shell.execute_reply": "2024-03-13T23:00:28.808048Z"
    },
    "papermill": {
     "duration": 0.085059,
     "end_time": "2024-03-13T23:00:28.811423",
     "exception": false,
     "start_time": "2024-03-13T23:00:28.726364",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "submission = pd.read_csv(f\"{config.competition_data_path}/sample_submission.csv\")\n",
    "submission = submission.merge(test_df, on=\"eeg_id\", how=\"left\")\n",
    "submission[\"path\"] = submission[\"spectrogram_id\"].apply(\n",
    "    lambda x: config.data_spectograms_test + str(x) + \".parquet\"\n",
    ")\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162bdf1a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T23:00:28.896077Z",
     "iopub.status.busy": "2024-03-13T23:00:28.895681Z",
     "iopub.status.idle": "2024-03-13T23:00:30.864244Z",
     "shell.execute_reply": "2024-03-13T23:00:30.863051Z"
    },
    "papermill": {
     "duration": 2.013018,
     "end_time": "2024-03-13T23:00:30.866775",
     "exception": false,
     "start_time": "2024-03-13T23:00:28.853757",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "paths = submission[\"path\"].values\n",
    "pred_model2 = []\n",
    "for path in paths:\n",
    "    eps = 1e-6\n",
    "    data = pd.read_parquet(path)\n",
    "\n",
    "    data = data.fillna(-1).values[:, 1:].T\n",
    "    data = data[:, 0:300]  # (400,300)\n",
    "    data = np.clip(data, np.exp(-6), np.exp(10))\n",
    "    data = np.log(data)\n",
    "    data_mean = data.mean(axis=(0, 1))\n",
    "    data_std = data.std(axis=(0, 1))\n",
    "    data = (data - data_mean) / (data_std + eps)\n",
    "    data_tensor = torch.unsqueeze(torch.Tensor(data), dim=0)\n",
    "    data = image_transform(data_tensor)\n",
    "    test_pred = []\n",
    "    for model in models:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            pred = F.softmax(model(data.unsqueeze(0)))[0]\n",
    "            pred = pred.detach().cpu().numpy()\n",
    "        test_pred.append(pred)\n",
    "    test_pred = np.array(test_pred).mean(axis=0)\n",
    "    pred_model2.append(test_pred)\n",
    "pred_model2 = np.array(pred_model2)\n",
    "pred_model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f2f840",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T23:00:30.956933Z",
     "iopub.status.busy": "2024-03-13T23:00:30.956520Z",
     "iopub.status.idle": "2024-03-13T23:00:30.974617Z",
     "shell.execute_reply": "2024-03-13T23:00:30.973512Z"
    },
    "papermill": {
     "duration": 0.063713,
     "end_time": "2024-03-13T23:00:30.977066",
     "exception": false,
     "start_time": "2024-03-13T23:00:30.913353",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sub2 = pd.read_csv(f\"{config.competition_data_path}/sample_submission.csv\")\n",
    "labels = [\"seizure\", \"lpd\", \"gpd\", \"lrda\", \"grda\", \"other\"]\n",
    "for i in range(len(labels)):\n",
    "    sub2[f\"{labels[i]}_vote\"] = pred_model2[:, i]\n",
    "sub2.head()\n",
    "# sub2.to_csv(\"submission_model2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b922ecc",
   "metadata": {
    "papermill": {
     "duration": 0.042769,
     "end_time": "2024-03-13T23:00:31.067496",
     "exception": false,
     "start_time": "2024-03-13T23:00:31.024727",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model 3 - ResNet34d, EfficientNetB0 and EfficientnetB1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa550b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T23:00:31.155672Z",
     "iopub.status.busy": "2024-03-13T23:00:31.155291Z",
     "iopub.status.idle": "2024-03-13T23:00:31.458651Z",
     "shell.execute_reply": "2024-03-13T23:00:31.457581Z"
    },
    "papermill": {
     "duration": 0.350771,
     "end_time": "2024-03-13T23:00:31.460964",
     "exception": false,
     "start_time": "2024-03-13T23:00:31.110193",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Importing essential libraries\n",
    "import gc\n",
    "import os\n",
    "import random\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "# PyTorch for deep learning\n",
    "import timm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# torchvision for image processing and augmentation\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Suppressing minor warnings to keep the output clean\n",
    "warnings.filterwarnings(\"ignore\", category=Warning)\n",
    "\n",
    "# Reclaim memory no longer in use.\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb173bd0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T23:00:31.549285Z",
     "iopub.status.busy": "2024-03-13T23:00:31.548831Z",
     "iopub.status.idle": "2024-03-13T23:00:31.556575Z",
     "shell.execute_reply": "2024-03-13T23:00:31.555563Z"
    },
    "papermill": {
     "duration": 0.054117,
     "end_time": "2024-03-13T23:00:31.558956",
     "exception": false,
     "start_time": "2024-03-13T23:00:31.504839",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "config.seed = 42\n",
    "image_transform = transforms.Resize((512, 512))\n",
    "\n",
    "\n",
    "# Set the seed for reproducibility across multiple libraries\n",
    "def set_seed(seed):\n",
    "    print(f\"Setting seed non standard one: {seed}\")\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "\n",
    "\n",
    "set_seed(config.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe7266f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T23:00:31.648082Z",
     "iopub.status.busy": "2024-03-13T23:00:31.647666Z",
     "iopub.status.idle": "2024-03-13T23:00:43.671965Z",
     "shell.execute_reply": "2024-03-13T23:00:43.670887Z"
    },
    "papermill": {
     "duration": 12.071297,
     "end_time": "2024-03-13T23:00:43.674126",
     "exception": false,
     "start_time": "2024-03-13T23:00:31.602829",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load and store the trained models for each fold into a list\n",
    "models = []\n",
    "\n",
    "# Load ResNet34d\n",
    "for i in range(config.num_folds):\n",
    "    # Create the same model architecture as during training\n",
    "    model_resnet = timm.create_model(\n",
    "        \"resnet34d\", pretrained=False, num_classes=6, in_chans=1\n",
    "    )\n",
    "\n",
    "    # Load the trained weights from the corresponding file\n",
    "    model_resnet.load_state_dict(\n",
    "        torch.load(\n",
    "            f\"{config.train_resnet34d}resnet34d_fold{i}.pth\",\n",
    "            map_location=torch.device(\"cpu\"),\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Append the loaded model to the models list\n",
    "    models.append(model_resnet)\n",
    "\n",
    "# Reclaim memory no longer in use.\n",
    "gc.collect()\n",
    "\n",
    "# Load EfficientNetB0\n",
    "for j in range(config.num_folds):\n",
    "    # Create the same model architecture as during training\n",
    "    model_effnet_b0 = timm.create_model(\n",
    "        \"efficientnet_b0\", pretrained=False, num_classes=6, in_chans=1\n",
    "    )\n",
    "\n",
    "    # Load the trained weights from the corresponding file\n",
    "    model_effnet_b0.load_state_dict(\n",
    "        torch.load(\n",
    "            f\"{config.efficientnetb0}efficientnet_b0_fold{j}.pth\",\n",
    "            map_location=torch.device(\"cpu\"),\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Append the loaded model to the models list\n",
    "    models.append(model_effnet_b0)\n",
    "\n",
    "# Reclaim memory no longer in use.\n",
    "gc.collect()\n",
    "\n",
    "# Load EfficientNetB1\n",
    "for k in range(config.num_folds):\n",
    "    # Create the same model architecture as during training\n",
    "    model_effnet_b1 = timm.create_model(\n",
    "        \"efficientnet_b1\", pretrained=False, num_classes=6, in_chans=1\n",
    "    )\n",
    "\n",
    "    # Load the trained weights from the corresponding file\n",
    "    model_effnet_b1.load_state_dict(\n",
    "        torch.load(\n",
    "            f\"{config.efficientnetb1}efficientnet_b1_fold{k}.pth\",\n",
    "            map_location=torch.device(\"cpu\"),\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Append the loaded model to the models list\n",
    "    models.append(model_effnet_b1)\n",
    "\n",
    "# Reclaim memory no longer in use.\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07bf4a49",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T23:00:43.758942Z",
     "iopub.status.busy": "2024-03-13T23:00:43.758238Z",
     "iopub.status.idle": "2024-03-13T23:00:44.091327Z",
     "shell.execute_reply": "2024-03-13T23:00:44.090216Z"
    },
    "papermill": {
     "duration": 0.377987,
     "end_time": "2024-03-13T23:00:44.093571",
     "exception": false,
     "start_time": "2024-03-13T23:00:43.715584",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load test data and sample submission dataframe\n",
    "test_df = pd.read_csv(config.data_test_csv)\n",
    "submission = pd.read_csv(f\"{config.competition_data_path}/sample_submission.csv\")\n",
    "\n",
    "# Merge the submission dataframe with the test data on EEG IDs\n",
    "submission = submission.merge(test_df, on=\"eeg_id\", how=\"left\")\n",
    "\n",
    "# Generate file paths for each spectrogram based on the EEG data in the submission dataframe\n",
    "submission[\"path\"] = submission[\"spectrogram_id\"].apply(\n",
    "    lambda x: f\"{config.data_spectograms_test}{x}.parquet\"\n",
    ")\n",
    "\n",
    "# Display the first few rows of the submission dataframe\n",
    "display(submission.head())\n",
    "\n",
    "# Reclaim memory no longer in use\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db03b91a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T23:00:44.183258Z",
     "iopub.status.busy": "2024-03-13T23:00:44.182838Z",
     "iopub.status.idle": "2024-03-13T23:00:44.187538Z",
     "shell.execute_reply": "2024-03-13T23:00:44.186454Z"
    },
    "papermill": {
     "duration": 0.052455,
     "end_time": "2024-03-13T23:00:44.189732",
     "exception": false,
     "start_time": "2024-03-13T23:00:44.137277",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## TYGO HEEERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db82d76",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T23:00:44.277632Z",
     "iopub.status.busy": "2024-03-13T23:00:44.277303Z",
     "iopub.status.idle": "2024-03-13T23:00:47.924373Z",
     "shell.execute_reply": "2024-03-13T23:00:47.923309Z"
    },
    "papermill": {
     "duration": 3.693843,
     "end_time": "2024-03-13T23:00:47.926630",
     "exception": false,
     "start_time": "2024-03-13T23:00:44.232787",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the weights for each model (those are ours)\n",
    "weight_resnet34d = 0.26\n",
    "weight_effnetb0 = 0.48\n",
    "weight_effnetb1 = 0.26\n",
    "\n",
    "# Amazing weights from new ensemble that were defined by the guy \n",
    "# weight_resnet34d = 0.25\n",
    "# weight_effnetb0 = 0.42\n",
    "# weight_effnetb1 = 0.33\n",
    "\n",
    "# Get file paths for test spectrograms\n",
    "paths = submission[\"path\"].values\n",
    "pred_model3 = []\n",
    "\n",
    "# Generate predictions for each spectrogram using all models\n",
    "for path in paths:\n",
    "    eps = 1e-6\n",
    "    # Read and preprocess spectrogram data\n",
    "    data = pd.read_parquet(path)\n",
    "    data = data.fillna(-1).values[:, 1:].T\n",
    "    data = np.clip(data, np.exp(-6), np.exp(10))\n",
    "    data = np.log(data)\n",
    "\n",
    "    # Normalize the data\n",
    "    data_mean = data.mean(axis=(0, 1))\n",
    "    data_std = data.std(axis=(0, 1))\n",
    "    data = (data - data_mean) / (data_std + eps)\n",
    "    data_tensor = torch.unsqueeze(torch.Tensor(data), dim=0)\n",
    "    data = image_transform(data_tensor)\n",
    "\n",
    "    test_pred = []\n",
    "\n",
    "    # Generate predictions using all models\n",
    "    for model in models:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            pred = F.softmax(model(data.unsqueeze(0)))[0]\n",
    "            pred = pred.detach().cpu().numpy()\n",
    "        test_pred.append(pred)\n",
    "\n",
    "    # Combine predictions from all models using weighted voting\n",
    "    weighted_pred = (\n",
    "        weight_resnet34d * np.mean(test_pred[: config.num_folds], axis=0)\n",
    "        + weight_effnetb0\n",
    "        * np.mean(test_pred[config.num_folds : 2 * config.num_folds], axis=0)\n",
    "        + weight_effnetb1 * np.mean(test_pred[2 * config.num_folds :], axis=0)\n",
    "    )\n",
    "\n",
    "    pred_model3.append(weighted_pred)\n",
    "\n",
    "# Convert the list of predictions to a NumPy array for further processing\n",
    "pred_model3 = np.array(pred_model3)\n",
    "\n",
    "\n",
    "# Reclaim memory no longer in use\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599964bc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T23:00:48.014385Z",
     "iopub.status.busy": "2024-03-13T23:00:48.013440Z",
     "iopub.status.idle": "2024-03-13T23:00:48.018037Z",
     "shell.execute_reply": "2024-03-13T23:00:48.017163Z"
    },
    "papermill": {
     "duration": 0.050392,
     "end_time": "2024-03-13T23:00:48.020197",
     "exception": false,
     "start_time": "2024-03-13T23:00:47.969805",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Model 3\n",
    "# eeg_id_values = [3911565283]\n",
    "# TARGETS = [\n",
    "#     \"seizure_vote\",\n",
    "#     \"lpd_vote\",\n",
    "#     \"gpd_vote\",\n",
    "#     \"lrda_vote\",\n",
    "#     \"grda_vote\",\n",
    "#     \"other_vote\",\n",
    "# ]\n",
    "# sub3 = pd.DataFrame({\"eeg_id\": eeg_id_values})\n",
    "# sub3[TARGETS] = pred_model3\n",
    "# print(\"Submission shape\", sub3.shape)\n",
    "# sub3.to_csv(\"submission_model3.csv\", index=False)\n",
    "# sub3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1ae812",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T23:00:48.105616Z",
     "iopub.status.busy": "2024-03-13T23:00:48.105294Z",
     "iopub.status.idle": "2024-03-13T23:00:48.111924Z",
     "shell.execute_reply": "2024-03-13T23:00:48.110988Z"
    },
    "papermill": {
     "duration": 0.052008,
     "end_time": "2024-03-13T23:00:48.114077",
     "exception": false,
     "start_time": "2024-03-13T23:00:48.062069",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pred_model3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b4f4cd",
   "metadata": {
    "papermill": {
     "duration": 0.041024,
     "end_time": "2024-03-13T23:00:48.194946",
     "exception": false,
     "start_time": "2024-03-13T23:00:48.153922",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model 4 - Features+Head Ensemble "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c52a174",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T23:00:48.281138Z",
     "iopub.status.busy": "2024-03-13T23:00:48.280764Z",
     "iopub.status.idle": "2024-03-13T23:01:04.609236Z",
     "shell.execute_reply": "2024-03-13T23:01:04.607891Z"
    },
    "papermill": {
     "duration": 16.375329,
     "end_time": "2024-03-13T23:01:04.611481",
     "exception": false,
     "start_time": "2024-03-13T23:00:48.236152",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os, random\n",
    "import tensorflow as tf\n",
    "import tensorflow\n",
    "import tensorflow.keras.backend as K\n",
    "import pandas as pd, numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "LOAD_BACKBONE_FROM = config.efficientnetb_tf_keras\n",
    "LOAD_MODELS_FROM = config.futures_head_starters_models\n",
    "HMS_PATH = config.competition_data_path\n",
    "VER = 50\n",
    "DATA_TYPE = \"KER\"  # K|E|R|KE|KR|ER|KER\n",
    "USE_PROCESSED = True  # Use processed downsampled Raw EEG\n",
    "submission = True\n",
    "\n",
    "# Setup for ensemble\n",
    "ENSEMBLE = True\n",
    "LBs = [\n",
    "    0.41,\n",
    "    0.39,\n",
    "    0.41,\n",
    "    0.37,\n",
    "    0.39,\n",
    "    0.38,\n",
    "    0.36,\n",
    "]  # K|E|R|KE|KR|ER|KER for weighted ensemble we use LBs of each model\n",
    "VER_K = 43  # Kaggle's spectrogram model version\n",
    "VER_E = 42  # EEG's spectrogram model version\n",
    "VER_R = 37  # EEG's Raw wavenet model version, trained on single GPU\n",
    "VER_KE = 47  # Kaggle's and EEG's spectrogram model version\n",
    "VER_KR = 48  # Kaggle's spectrogram and Raw model version\n",
    "VER_ER = 49  # EEG's spectrogram and Raw model version\n",
    "VER_KER = 50  # EEG's, Kaggle's spectrograms and Raw model version\n",
    "\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# USE SINGLE GPU, MULTIPLE GPUS\n",
    "gpus = tf.config.list_physical_devices(\"GPU\")\n",
    "# WE USE MIXED PRECISION\n",
    "tf.config.optimizer.set_experimental_options({\"auto_mixed_precision\": True})\n",
    "if len(gpus) > 1:\n",
    "    strategy = tf.distribute.MirroredStrategy()\n",
    "    print(f\"Using {len(gpus)} GPUs\")\n",
    "else:\n",
    "    strategy = tf.distribute.OneDeviceStrategy(device=\"/gpu:0\")\n",
    "    print(f\"Using {len(gpus)} GPU\")\n",
    "\n",
    "TARGETS = [\n",
    "    \"seizure_vote\",\n",
    "    \"lpd_vote\",\n",
    "    \"gpd_vote\",\n",
    "    \"lrda_vote\",\n",
    "    \"grda_vote\",\n",
    "    \"other_vote\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc31f9f",
   "metadata": {
    "papermill": {
     "duration": 0.043504,
     "end_time": "2024-03-13T23:01:04.699211",
     "exception": false,
     "start_time": "2024-03-13T23:01:04.655707",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## DATA GENERATOR\n",
    "This data generator outputs 512x512x3, the spectrogram and eeg images are concatenated all togother in a single image. For using data augmention you can set `augment = True` when creating the train data generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87efc1df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T23:01:04.789380Z",
     "iopub.status.busy": "2024-03-13T23:01:04.788604Z",
     "iopub.status.idle": "2024-03-13T23:01:04.859048Z",
     "shell.execute_reply": "2024-03-13T23:01:04.858283Z"
    },
    "papermill": {
     "duration": 0.119404,
     "end_time": "2024-03-13T23:01:04.861162",
     "exception": false,
     "start_time": "2024-03-13T23:01:04.741758",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import albumentations as albu\n",
    "from scipy.signal import butter, lfilter\n",
    "import librosa\n",
    "\n",
    "FEATS2 = [\"Fp1\", \"T3\", \"C3\", \"O1\", \"Fp2\", \"C4\", \"T4\", \"O2\"]\n",
    "FEAT2IDX = {x: y for x, y in zip(FEATS2, range(len(FEATS2)))}\n",
    "FEATS = [\n",
    "    [\"Fp1\", \"F7\", \"T3\", \"T5\", \"O1\"],\n",
    "    [\"Fp1\", \"F3\", \"C3\", \"P3\", \"O1\"],\n",
    "    [\"Fp2\", \"F8\", \"T4\", \"T6\", \"O2\"],\n",
    "    [\"Fp2\", \"F4\", \"C4\", \"P4\", \"O2\"],\n",
    "]\n",
    "\n",
    "\n",
    "class DataGenerator:\n",
    "    \"Generates data for Keras\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        data,\n",
    "        specs=None,\n",
    "        eeg_specs=None,\n",
    "        raw_eegs=None,\n",
    "        augment=False,\n",
    "        mode=\"train\",\n",
    "        data_type=DATA_TYPE,\n",
    "    ):\n",
    "        self.data = data\n",
    "        self.augment = augment\n",
    "        self.mode = mode\n",
    "        self.data_type = data_type\n",
    "        self.specs = specs\n",
    "        self.eeg_specs = eeg_specs\n",
    "        self.raw_eegs = raw_eegs\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        X, y = self.data_generation(index)\n",
    "        if self.augment:\n",
    "            X = self.augmentation(X)\n",
    "        return X, y\n",
    "\n",
    "    def __call__(self):\n",
    "        for i in range(self.__len__()):\n",
    "            yield self.__getitem__(i)\n",
    "\n",
    "            if i == self.__len__() - 1:\n",
    "                self.on_epoch_end()\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.mode == \"train\":\n",
    "            self.data = self.data.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "    def data_generation(self, index):\n",
    "        if self.data_type == \"KE\":\n",
    "            X, y = self.generate_all_specs(index)\n",
    "        elif self.data_type == \"E\" or self.data_type == \"K\":\n",
    "            X, y = self.generate_specs(index)\n",
    "        elif self.data_type == \"R\":\n",
    "            X, y = self.generate_raw(index)\n",
    "        elif self.data_type in [\"ER\", \"KR\"]:\n",
    "            X1, y = self.generate_specs(index)\n",
    "            X2, y = self.generate_raw(index)\n",
    "            X = (X1, X2)\n",
    "        elif self.data_type in [\"KER\"]:\n",
    "            X1, y = self.generate_all_specs(index)\n",
    "            X2, y = self.generate_raw(index)\n",
    "            X = (X1, X2)\n",
    "        return X, y\n",
    "\n",
    "    def generate_all_specs(self, index):\n",
    "        X = np.zeros((512, 512, 3), dtype=\"float32\")\n",
    "        y = np.zeros((6,), dtype=\"float32\")\n",
    "\n",
    "        row = self.data.iloc[index]\n",
    "        if self.mode == \"test\":\n",
    "            offset = 0\n",
    "        else:\n",
    "            offset = int(row.offset / 2)\n",
    "\n",
    "        eeg = self.eeg_specs[row.eeg_id]\n",
    "        spec = self.specs[row.spec_id]\n",
    "\n",
    "        imgs = [\n",
    "            spec[offset : offset + 300, k * 100 : (k + 1) * 100].T for k in [0, 2, 1, 3]\n",
    "        ]  # to match kaggle with eeg\n",
    "        img = np.stack(imgs, axis=-1)\n",
    "        # LOG TRANSFORM SPECTROGRAM\n",
    "        img = np.clip(img, np.exp(-4), np.exp(8))\n",
    "        img = np.log(img)\n",
    "\n",
    "        # STANDARDIZE PER IMAGE\n",
    "        img = np.nan_to_num(img, nan=0.0)\n",
    "\n",
    "        mn = img.flatten().min()\n",
    "        mx = img.flatten().max()\n",
    "        ep = 1e-5\n",
    "        img = 255 * (img - mn) / (mx - mn + ep)\n",
    "\n",
    "        X[0_0 + 56 : 100 + 56, :256, 0] = img[:, 22:-22, 0]  # LL_k\n",
    "        X[100 + 56 : 200 + 56, :256, 0] = img[:, 22:-22, 2]  # RL_k\n",
    "        X[0_0 + 56 : 100 + 56, :256, 1] = img[:, 22:-22, 1]  # LP_k\n",
    "        X[100 + 56 : 200 + 56, :256, 1] = img[:, 22:-22, 3]  # RP_k\n",
    "        X[0_0 + 56 : 100 + 56, :256, 2] = img[:, 22:-22, 2]  # RL_k\n",
    "        X[100 + 56 : 200 + 56, :256, 2] = img[:, 22:-22, 1]  # LP_k\n",
    "\n",
    "        X[0_0 + 56 : 100 + 56, 256:, 0] = img[:, 22:-22, 0]  # LL_k\n",
    "        X[100 + 56 : 200 + 56, 256:, 0] = img[:, 22:-22, 2]  # RL_k\n",
    "        X[0_0 + 56 : 100 + 56, 256:, 1] = img[:, 22:-22, 1]  # LP_k\n",
    "        X[100 + 56 : 200 + 56, 256:, 1] = img[:, 22:-22, 3]  # RP_K\n",
    "\n",
    "        # EEG\n",
    "        img = eeg\n",
    "        mn = img.flatten().min()\n",
    "        mx = img.flatten().max()\n",
    "        ep = 1e-5\n",
    "        img = 255 * (img - mn) / (mx - mn + ep)\n",
    "        X[200 + 56 : 300 + 56, :256, 0] = img[:, 22:-22, 0]  # LL_e\n",
    "        X[300 + 56 : 400 + 56, :256, 0] = img[:, 22:-22, 2]  # RL_e\n",
    "        X[200 + 56 : 300 + 56, :256, 1] = img[:, 22:-22, 1]  # LP_e\n",
    "        X[300 + 56 : 400 + 56, :256, 1] = img[:, 22:-22, 3]  # RP_e\n",
    "        X[200 + 56 : 300 + 56, :256, 2] = img[:, 22:-22, 2]  # RL_e\n",
    "        X[300 + 56 : 400 + 56, :256, 2] = img[:, 22:-22, 1]  # LP_e\n",
    "\n",
    "        X[200 + 56 : 300 + 56, 256:, 0] = img[:, 22:-22, 0]  # LL_e\n",
    "        X[300 + 56 : 400 + 56, 256:, 0] = img[:, 22:-22, 2]  # RL_e\n",
    "        X[200 + 56 : 300 + 56, 256:, 1] = img[:, 22:-22, 1]  # LP_e\n",
    "        X[300 + 56 : 400 + 56, 256:, 1] = img[:, 22:-22, 3]  # RP_e\n",
    "\n",
    "        if self.mode != \"test\":\n",
    "            y[:] = row[TARGETS]\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def generate_specs(self, index):\n",
    "        X = np.zeros((512, 512, 3), dtype=\"float32\")\n",
    "        y = np.zeros((6,), dtype=\"float32\")\n",
    "\n",
    "        row = self.data.iloc[index]\n",
    "        if self.mode == \"test\":\n",
    "            offset = 0\n",
    "        else:\n",
    "            offset = int(row.offset / 2)\n",
    "\n",
    "        if self.data_type in [\"E\", \"ER\"]:\n",
    "            img = self.eeg_specs[row.eeg_id]\n",
    "        elif self.data_type in [\"K\", \"KR\"]:\n",
    "            spec = self.specs[row.spec_id]\n",
    "            imgs = [\n",
    "                spec[offset : offset + 300, k * 100 : (k + 1) * 100].T\n",
    "                for k in [0, 2, 1, 3]\n",
    "            ]  # to match kaggle with eeg\n",
    "            img = np.stack(imgs, axis=-1)\n",
    "            # LOG TRANSFORM SPECTROGRAM\n",
    "            img = np.clip(img, np.exp(-4), np.exp(8))\n",
    "            img = np.log(img)\n",
    "\n",
    "            # STANDARDIZE PER IMAGE\n",
    "            img = np.nan_to_num(img, nan=0.0)\n",
    "\n",
    "        mn = img.flatten().min()\n",
    "        mx = img.flatten().max()\n",
    "        ep = 1e-5\n",
    "        img = 255 * (img - mn) / (mx - mn + ep)\n",
    "\n",
    "        X[0_0 + 56 : 100 + 56, :256, 0] = img[:, 22:-22, 0]\n",
    "        X[100 + 56 : 200 + 56, :256, 0] = img[:, 22:-22, 2]\n",
    "        X[0_0 + 56 : 100 + 56, :256, 1] = img[:, 22:-22, 1]\n",
    "        X[100 + 56 : 200 + 56, :256, 1] = img[:, 22:-22, 3]\n",
    "        X[0_0 + 56 : 100 + 56, :256, 2] = img[:, 22:-22, 2]\n",
    "        X[100 + 56 : 200 + 56, :256, 2] = img[:, 22:-22, 1]\n",
    "\n",
    "        X[0_0 + 56 : 100 + 56, 256:, 0] = img[:, 22:-22, 0]\n",
    "        X[100 + 56 : 200 + 56, 256:, 0] = img[:, 22:-22, 1]\n",
    "        X[0_0 + 56 : 100 + 56, 256:, 1] = img[:, 22:-22, 2]\n",
    "        X[100 + 56 : 200 + 56, 256:, 1] = img[:, 22:-22, 3]\n",
    "\n",
    "        X[200 + 56 : 300 + 56, :256, 0] = img[:, 22:-22, 0]\n",
    "        X[300 + 56 : 400 + 56, :256, 0] = img[:, 22:-22, 1]\n",
    "        X[200 + 56 : 300 + 56, :256, 1] = img[:, 22:-22, 2]\n",
    "        X[300 + 56 : 400 + 56, :256, 1] = img[:, 22:-22, 3]\n",
    "        X[200 + 56 : 300 + 56, :256, 2] = img[:, 22:-22, 3]\n",
    "        X[300 + 56 : 400 + 56, :256, 2] = img[:, 22:-22, 2]\n",
    "\n",
    "        X[200 + 56 : 300 + 56, 256:, 0] = img[:, 22:-22, 0]\n",
    "        X[300 + 56 : 400 + 56, 256:, 0] = img[:, 22:-22, 2]\n",
    "        X[200 + 56 : 300 + 56, 256:, 1] = img[:, 22:-22, 1]\n",
    "        X[300 + 56 : 400 + 56, 256:, 1] = img[:, 22:-22, 3]\n",
    "\n",
    "        if self.mode != \"test\":\n",
    "            y[:] = row[TARGETS]\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def generate_raw(self, index):\n",
    "        if USE_PROCESSED and self.mode != \"test\":\n",
    "            X = np.zeros((2_000, 8), dtype=\"float32\")\n",
    "            y = np.zeros((6,), dtype=\"float32\")\n",
    "            row = self.data.iloc[index]\n",
    "            X = self.raw_eegs[row.eeg_id]\n",
    "            y[:] = row[TARGETS]\n",
    "            return X, y\n",
    "\n",
    "        X = np.zeros((10_000, 8), dtype=\"float32\")\n",
    "        y = np.zeros((6,), dtype=\"float32\")\n",
    "\n",
    "        row = self.data.iloc[index]\n",
    "        eeg = self.raw_eegs[row.eeg_id]\n",
    "\n",
    "        # FEATURE ENGINEER\n",
    "        X[:, 0] = eeg[:, FEAT2IDX[\"Fp1\"]] - eeg[:, FEAT2IDX[\"T3\"]]\n",
    "        X[:, 1] = eeg[:, FEAT2IDX[\"T3\"]] - eeg[:, FEAT2IDX[\"O1\"]]\n",
    "\n",
    "        X[:, 2] = eeg[:, FEAT2IDX[\"Fp1\"]] - eeg[:, FEAT2IDX[\"C3\"]]\n",
    "        X[:, 3] = eeg[:, FEAT2IDX[\"C3\"]] - eeg[:, FEAT2IDX[\"O1\"]]\n",
    "\n",
    "        X[:, 4] = eeg[:, FEAT2IDX[\"Fp2\"]] - eeg[:, FEAT2IDX[\"C4\"]]\n",
    "        X[:, 5] = eeg[:, FEAT2IDX[\"C4\"]] - eeg[:, FEAT2IDX[\"O2\"]]\n",
    "\n",
    "        X[:, 6] = eeg[:, FEAT2IDX[\"Fp2\"]] - eeg[:, FEAT2IDX[\"T4\"]]\n",
    "        X[:, 7] = eeg[:, FEAT2IDX[\"T4\"]] - eeg[:, FEAT2IDX[\"O2\"]]\n",
    "\n",
    "        # STANDARDIZE\n",
    "        X = np.clip(X, -1024, 1024)\n",
    "        X = np.nan_to_num(X, nan=0) / 32.0\n",
    "\n",
    "        # BUTTER LOW-PASS FILTER\n",
    "        X = self.butter_lowpass_filter(X)\n",
    "        # Downsample\n",
    "        X = X[::5, :]\n",
    "\n",
    "        if self.mode != \"test\":\n",
    "            y[:] = row[TARGETS]\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def butter_lowpass_filter(self, data, cutoff_freq=20, sampling_rate=200, order=4):\n",
    "        nyquist = 0.5 * sampling_rate\n",
    "        normal_cutoff = cutoff_freq / nyquist\n",
    "        b, a = butter(order, normal_cutoff, btype=\"low\", analog=False)\n",
    "        filtered_data = lfilter(b, a, data, axis=0)\n",
    "        return filtered_data\n",
    "\n",
    "    def resize(self, img, size):\n",
    "        composition = albu.Compose([albu.Resize(size[0], size[1])])\n",
    "        return composition(image=img)[\"image\"]\n",
    "\n",
    "    def augmentation(self, img):\n",
    "        composition = albu.Compose([albu.HorizontalFlip(p=0.4)])\n",
    "        return composition(image=img)[\"image\"]\n",
    "\n",
    "\n",
    "def spectrogram_from_eeg(parquet_path):\n",
    "\n",
    "    # LOAD MIDDLE 50 SECONDS OF EEG SERIES\n",
    "    eeg = pd.read_parquet(parquet_path)\n",
    "    middle = (len(eeg) - 10_000) // 2\n",
    "    eeg = eeg.iloc[middle : middle + 10_000]\n",
    "\n",
    "    # VARIABLE TO HOLD SPECTROGRAM\n",
    "    img = np.zeros((100, 300, 4), dtype=\"float32\")\n",
    "\n",
    "    for k in range(4):\n",
    "        COLS = FEATS[k]\n",
    "\n",
    "        for kk in range(4):\n",
    "            # FILL NANS\n",
    "            x1 = eeg[COLS[kk]].values\n",
    "            x2 = eeg[COLS[kk + 1]].values\n",
    "            m = np.nanmean(x1)\n",
    "            if np.isnan(x1).mean() < 1:\n",
    "                x1 = np.nan_to_num(x1, nan=m)\n",
    "            else:\n",
    "                x1[:] = 0\n",
    "            m = np.nanmean(x2)\n",
    "            if np.isnan(x2).mean() < 1:\n",
    "                x2 = np.nan_to_num(x2, nan=m)\n",
    "            else:\n",
    "                x2[:] = 0\n",
    "\n",
    "            # COMPUTE PAIR DIFFERENCES\n",
    "            x = x1 - x2\n",
    "\n",
    "            # RAW SPECTROGRAM\n",
    "            mel_spec = librosa.feature.melspectrogram(\n",
    "                y=x,\n",
    "                sr=200,\n",
    "                hop_length=len(x) // 300,\n",
    "                n_fft=1024,\n",
    "                n_mels=100,\n",
    "                fmin=0,\n",
    "                fmax=20,\n",
    "                win_length=128,\n",
    "            )\n",
    "\n",
    "            # LOG TRANSFORM\n",
    "            width = (mel_spec.shape[1] // 30) * 30\n",
    "            mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max).astype(np.float32)[\n",
    "                :, :width\n",
    "            ]\n",
    "            img[:, :, k] += mel_spec_db\n",
    "\n",
    "        # AVERAGE THE 4 MONTAGE DIFFERENCES\n",
    "        img[:, :, k] /= 4.0\n",
    "\n",
    "    return img\n",
    "\n",
    "\n",
    "def eeg_from_parquet(parquet_path):\n",
    "\n",
    "    eeg = pd.read_parquet(parquet_path, columns=FEATS2)\n",
    "    rows = len(eeg)\n",
    "    offset = (rows - 10_000) // 2\n",
    "    eeg = eeg.iloc[offset : offset + 10_000]\n",
    "    data = np.zeros((10_000, len(FEATS2)))\n",
    "    for j, col in enumerate(FEATS2):\n",
    "\n",
    "        # FILL NAN\n",
    "        x = eeg[col].values.astype(\"float32\")\n",
    "        m = np.nanmean(x)\n",
    "        if np.isnan(x).mean() < 1:\n",
    "            x = np.nan_to_num(x, nan=m)\n",
    "        else:\n",
    "            x[:] = 0\n",
    "\n",
    "        data[:, j] = x\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b891d12",
   "metadata": {
    "papermill": {
     "duration": 0.049077,
     "end_time": "2024-03-13T23:01:04.961754",
     "exception": false,
     "start_time": "2024-03-13T23:01:04.912677",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### MODEL AND UTILITY FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ee2897",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T23:01:05.048222Z",
     "iopub.status.busy": "2024-03-13T23:01:05.047793Z",
     "iopub.status.idle": "2024-03-13T23:01:05.085345Z",
     "shell.execute_reply": "2024-03-13T23:01:05.084348Z"
    },
    "papermill": {
     "duration": 0.082388,
     "end_time": "2024-03-13T23:01:05.087539",
     "exception": false,
     "start_time": "2024-03-13T23:01:05.005151",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import (\n",
    "    Input,\n",
    "    Dense,\n",
    "    Multiply,\n",
    "    Add,\n",
    "    Conv1D,\n",
    "    Concatenate,\n",
    "    LayerNormalization,\n",
    ")\n",
    "\n",
    "\n",
    "def build_model():\n",
    "    K.clear_session()\n",
    "    with strategy.scope():\n",
    "        if DATA_TYPE in [\"R\"]:\n",
    "            model = build_wave_model()\n",
    "        elif DATA_TYPE in [\"K\", \"E\", \"KE\"]:\n",
    "            model = build_spec_model()\n",
    "        elif DATA_TYPE in [\"KR\", \"ER\", \"KER\"]:\n",
    "            model = build_hybrid_model()\n",
    "    return model\n",
    "\n",
    "\n",
    "def build_spec_model(hybrid=False):\n",
    "    inp = tf.keras.layers.Input((512, 512, 3))\n",
    "    base_model = load_model(f\"{LOAD_BACKBONE_FROM}\")\n",
    "    x = base_model(inp)\n",
    "    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "    if not hybrid:\n",
    "        x = tf.keras.layers.Dense(6, activation=\"softmax\", dtype=\"float32\")(x)\n",
    "    model = tf.keras.Model(inputs=inp, outputs=x)\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "    loss = tf.keras.losses.KLDivergence()\n",
    "    model.compile(loss=loss, optimizer=opt)\n",
    "    return model\n",
    "\n",
    "\n",
    "def wave_block(x, filters, kernel_size, n):\n",
    "    dilation_rates = [2**i for i in range(n)]\n",
    "    x = Conv1D(filters=filters, kernel_size=1, padding=\"same\")(x)\n",
    "    res_x = x\n",
    "    for dilation_rate in dilation_rates:\n",
    "        tanh_out = Conv1D(\n",
    "            filters=filters,\n",
    "            kernel_size=kernel_size,\n",
    "            padding=\"same\",\n",
    "            activation=\"tanh\",\n",
    "            dilation_rate=dilation_rate,\n",
    "        )(x)\n",
    "        sigm_out = Conv1D(\n",
    "            filters=filters,\n",
    "            kernel_size=kernel_size,\n",
    "            padding=\"same\",\n",
    "            activation=\"sigmoid\",\n",
    "            dilation_rate=dilation_rate,\n",
    "        )(x)\n",
    "        x = Multiply()([tanh_out, sigm_out])\n",
    "        x = Conv1D(filters=filters, kernel_size=1, padding=\"same\")(x)\n",
    "        res_x = Add()([res_x, x])\n",
    "    return res_x\n",
    "\n",
    "\n",
    "def build_wave_model(hybrid=False):\n",
    "\n",
    "    # INPUT\n",
    "    inp = tf.keras.Input(shape=(2_000, 8))\n",
    "\n",
    "    ############\n",
    "    # FEATURE EXTRACTION SUB MODEL\n",
    "    inp2 = tf.keras.Input(shape=(2_000, 1))\n",
    "    x = wave_block(inp2, 8, 4, 6)\n",
    "    x = wave_block(x, 16, 4, 6)\n",
    "    x = wave_block(x, 32, 4, 6)\n",
    "    x = wave_block(x, 64, 4, 6)\n",
    "    model2 = tf.keras.Model(inputs=inp2, outputs=x)\n",
    "    ###########\n",
    "\n",
    "    # LEFT TEMPORAL CHAIN\n",
    "    x1 = model2(inp[:, :, 0:1])\n",
    "    x1 = tf.keras.layers.GlobalAveragePooling1D()(x1)\n",
    "    x2 = model2(inp[:, :, 1:2])\n",
    "    x2 = tf.keras.layers.GlobalAveragePooling1D()(x2)\n",
    "    z1 = tf.keras.layers.Average()([x1, x2])\n",
    "\n",
    "    # LEFT PARASAGITTAL CHAIN\n",
    "    x1 = model2(inp[:, :, 2:3])\n",
    "    x1 = tf.keras.layers.GlobalAveragePooling1D()(x1)\n",
    "    x2 = model2(inp[:, :, 3:4])\n",
    "    x2 = tf.keras.layers.GlobalAveragePooling1D()(x2)\n",
    "    z2 = tf.keras.layers.Average()([x1, x2])\n",
    "\n",
    "    # RIGHT PARASAGITTAL CHAIN\n",
    "    x1 = model2(inp[:, :, 4:5])\n",
    "    x1 = tf.keras.layers.GlobalAveragePooling1D()(x1)\n",
    "    x2 = model2(inp[:, :, 5:6])\n",
    "    x2 = tf.keras.layers.GlobalAveragePooling1D()(x2)\n",
    "    z3 = tf.keras.layers.Average()([x1, x2])\n",
    "\n",
    "    # RIGHT TEMPORAL CHAIN\n",
    "    x1 = model2(inp[:, :, 6:7])\n",
    "    x1 = tf.keras.layers.GlobalAveragePooling1D()(x1)\n",
    "    x2 = model2(inp[:, :, 7:8])\n",
    "    x2 = tf.keras.layers.GlobalAveragePooling1D()(x2)\n",
    "    z4 = tf.keras.layers.Average()([x1, x2])\n",
    "\n",
    "    # COMBINE CHAINS\n",
    "    y = tf.keras.layers.Concatenate()([z1, z2, z3, z4])\n",
    "    if not hybrid:\n",
    "        y = tf.keras.layers.Dense(64, activation=\"relu\")(y)\n",
    "        y = tf.keras.layers.Dense(6, activation=\"softmax\", dtype=\"float32\")(y)\n",
    "\n",
    "    # COMPILE MODEL\n",
    "    model = tf.keras.Model(inputs=inp, outputs=y)\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "    loss = tf.keras.losses.KLDivergence()\n",
    "    model.compile(loss=loss, optimizer=opt)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def build_hybrid_model():\n",
    "    model_spec = build_spec_model(True)\n",
    "    model_wave = build_wave_model(True)\n",
    "    inputs = [model_spec.input, model_wave.input]\n",
    "    x = [model_spec.output, model_wave.output]\n",
    "    x = tf.keras.layers.Concatenate()(x)\n",
    "    x = tf.keras.layers.Dense(6, activation=\"softmax\", dtype=\"float32\")(x)\n",
    "\n",
    "    # COMPILE MODEL\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=x)\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "    loss = tf.keras.losses.KLDivergence()\n",
    "    model.compile(loss=loss, optimizer=opt)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def score(y_true, y_pred):\n",
    "    kl = tf.keras.metrics.KLDivergence()\n",
    "    return kl(y_true, y_pred)\n",
    "\n",
    "\n",
    "def plot_hist(hist):\n",
    "    metrics = [\"loss\"]\n",
    "    for i, metric in enumerate(metrics):\n",
    "        plt.figure(figsize=(10, 4))\n",
    "        plt.subplot(1, 2, i + 1)\n",
    "        plt.plot(hist[metric])\n",
    "        plt.plot(hist[f\"val_{metric}\"])\n",
    "        plt.title(f\"{metric}\", size=12)\n",
    "        plt.ylabel(f\"{metric}\", size=12)\n",
    "        plt.xlabel(\"epoch\", size=12)\n",
    "        plt.legend([\"train\", \"validation\"], loc=\"upper left\")\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "def dataset(\n",
    "    data,\n",
    "    mode=\"train\",\n",
    "    batch_size=8,\n",
    "    data_type=DATA_TYPE,\n",
    "    augment=False,\n",
    "    specs=None,\n",
    "    eeg_specs=None,\n",
    "    raw_eegs=None,\n",
    "):\n",
    "\n",
    "    BATCH_SIZE_PER_REPLICA = batch_size\n",
    "    BATCH_SIZE = BATCH_SIZE_PER_REPLICA * strategy.num_replicas_in_sync\n",
    "    gen = DataGenerator(\n",
    "        data,\n",
    "        mode=mode,\n",
    "        data_type=data_type,\n",
    "        augment=augment,\n",
    "        specs=specs,\n",
    "        eeg_specs=eeg_specs,\n",
    "        raw_eegs=raw_eegs,\n",
    "    )\n",
    "    if data_type in [\"K\", \"E\", \"KE\"]:\n",
    "        inp = tf.TensorSpec(shape=(512, 512, 3), dtype=tf.float32)\n",
    "    elif data_type in [\"KR\", \"ER\", \"KER\"]:\n",
    "        inp = (\n",
    "            tf.TensorSpec(shape=(512, 512, 3), dtype=tf.float32),\n",
    "            tf.TensorSpec(shape=(2000, 8), dtype=tf.float32),\n",
    "        )\n",
    "    elif data_type in [\"R\"]:\n",
    "        inp = tf.TensorSpec(shape=(2000, 8), dtype=tf.float32)\n",
    "\n",
    "    output_signature = (inp, tf.TensorSpec(shape=(6,), dtype=tf.float32))\n",
    "    dataset = tf.data.Dataset.from_generator(\n",
    "        generator=gen, output_signature=output_signature\n",
    "    ).batch(BATCH_SIZE)\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def reset_seed(seed):\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af82143d",
   "metadata": {
    "papermill": {
     "duration": 0.042536,
     "end_time": "2024-03-13T23:01:05.172050",
     "exception": false,
     "start_time": "2024-03-13T23:01:05.129514",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Infer Test and Create Submission CSV\n",
    "\n",
    "Infer the test data and create a `config.output_path` file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd30634b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T23:01:05.258589Z",
     "iopub.status.busy": "2024-03-13T23:01:05.257746Z",
     "iopub.status.idle": "2024-03-13T23:01:05.267710Z",
     "shell.execute_reply": "2024-03-13T23:01:05.266497Z"
    },
    "papermill": {
     "duration": 0.055188,
     "end_time": "2024-03-13T23:01:05.269880",
     "exception": false,
     "start_time": "2024-03-13T23:01:05.214692",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if submission:\n",
    "    test = pd.read_csv(config.data_test_csv)\n",
    "    print(\"Test shape\", test.shape)\n",
    "    test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52983752",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T23:01:05.365763Z",
     "iopub.status.busy": "2024-03-13T23:01:05.365079Z",
     "iopub.status.idle": "2024-03-13T23:01:05.407356Z",
     "shell.execute_reply": "2024-03-13T23:01:05.406140Z"
    },
    "papermill": {
     "duration": 0.091977,
     "end_time": "2024-03-13T23:01:05.409871",
     "exception": false,
     "start_time": "2024-03-13T23:01:05.317894",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# READ ALL SPECTROGRAMS\n",
    "if submission:\n",
    "    files2 = os.listdir(config.data_spectograms_test)\n",
    "    print(f\"There are {len(files2)} test spectrogram parquets\")\n",
    "\n",
    "    spectrograms = {}\n",
    "    for i, f in enumerate(files2):\n",
    "        if i % 100 == 0:\n",
    "            print(i, \", \", end=\"\")\n",
    "        tmp = pd.read_parquet(f\"{config.data_spectograms_test}/{f}\")\n",
    "        name = int(f.split(\".\")[0])\n",
    "        spectrograms[name] = tmp.iloc[:, 1:].values\n",
    "\n",
    "    # RENAME FOR DATA GENERATOR\n",
    "    test = test.rename({\"spectrogram_id\": \"spec_id\"}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b8e9a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T23:01:05.500228Z",
     "iopub.status.busy": "2024-03-13T23:01:05.499798Z",
     "iopub.status.idle": "2024-03-13T23:01:05.772279Z",
     "shell.execute_reply": "2024-03-13T23:01:05.770485Z"
    },
    "papermill": {
     "duration": 0.3266,
     "end_time": "2024-03-13T23:01:05.781652",
     "exception": false,
     "start_time": "2024-03-13T23:01:05.455052",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# READ ALL EEG SPECTROGRAMS\n",
    "if submission:\n",
    "    DISPLAY = 0\n",
    "    EEG_IDS2 = test.eeg_id.unique()\n",
    "    all_eegs2 = {}\n",
    "\n",
    "    print(\"Converting Test EEG to Spectrograms...\")\n",
    "    print()\n",
    "    for i, eeg_id in enumerate(EEG_IDS2):\n",
    "\n",
    "        # CREATE SPECTROGRAM FROM EEG PARQUET\n",
    "        img = spectrogram_from_eeg(f\"{config.data_eeg_test}{eeg_id}.parquet\")\n",
    "        all_eegs2[eeg_id] = img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13916bb0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T23:01:05.953284Z",
     "iopub.status.busy": "2024-03-13T23:01:05.952336Z",
     "iopub.status.idle": "2024-03-13T23:01:05.973774Z",
     "shell.execute_reply": "2024-03-13T23:01:05.972355Z"
    },
    "papermill": {
     "duration": 0.069078,
     "end_time": "2024-03-13T23:01:05.976299",
     "exception": false,
     "start_time": "2024-03-13T23:01:05.907221",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# READ ALL RAW EEG SIGNALS\n",
    "if submission:\n",
    "    all_raw_eegs2 = {}\n",
    "    EEG_IDS2 = test.eeg_id.unique()\n",
    "\n",
    "    print(\"Processing Test EEG parquets...\")\n",
    "    print()\n",
    "    for i, eeg_id in enumerate(EEG_IDS2):\n",
    "\n",
    "        # SAVE EEG TO PYTHON DICTIONARY OF NUMPY ARRAYS\n",
    "        data = eeg_from_parquet(f\"{config.data_eeg_test}{eeg_id}.parquet\")\n",
    "        all_raw_eegs2[eeg_id] = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8042c528",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T23:01:06.081155Z",
     "iopub.status.busy": "2024-03-13T23:01:06.080131Z",
     "iopub.status.idle": "2024-03-13T23:03:44.630045Z",
     "shell.execute_reply": "2024-03-13T23:03:44.628805Z"
    },
    "papermill": {
     "duration": 158.606094,
     "end_time": "2024-03-13T23:03:44.632404",
     "exception": false,
     "start_time": "2024-03-13T23:01:06.026310",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Submission ON TEST with ensemble\n",
    "if submission and ENSEMBLE:\n",
    "    preds = []\n",
    "    params = {\"specs\": spectrograms, \"eeg_specs\": all_eegs2, \"raw_eegs\": all_raw_eegs2}\n",
    "    test_dataset_K = dataset(test, data_type=\"K\", mode=\"test\", **params)\n",
    "    test_dataset_E = dataset(test, data_type=\"E\", mode=\"test\", **params)\n",
    "    test_dataset_R = dataset(test, data_type=\"R\", mode=\"test\", **params)\n",
    "    test_dataset_KE = dataset(test, data_type=\"KE\", mode=\"test\", **params)\n",
    "    test_dataset_KR = dataset(test, data_type=\"KR\", mode=\"test\", **params)\n",
    "    test_dataset_ER = dataset(test, data_type=\"ER\", mode=\"test\", **params)\n",
    "    test_dataset_KER = dataset(test, data_type=\"KER\", mode=\"test\", **params)\n",
    "\n",
    "    # LB SCORE WEIGHTS FOR EACH MODEL\n",
    "    lbs = 1 - np.array(LBs)\n",
    "    weights = lbs / lbs.sum()\n",
    "    model_spec = build_spec_model()\n",
    "    model_wave = build_wave_model()\n",
    "    model_hybrid = build_hybrid_model()\n",
    "\n",
    "    for i in range(5):\n",
    "        print(f\"Fold {i+1}\")\n",
    "\n",
    "        model_spec.load_weights(f\"{LOAD_MODELS_FROM}/model_K_{VER_K}_{i}.weights.h5\")\n",
    "        pred_K = model_spec.predict(test_dataset_K, verbose=1)\n",
    "\n",
    "        model_spec.load_weights(f\"{LOAD_MODELS_FROM}/model_E_{VER_E}_{i}.weights.h5\")\n",
    "        pred_E = model_spec.predict(test_dataset_E, verbose=1)\n",
    "\n",
    "        model_wave.load_weights(f\"{LOAD_MODELS_FROM}/model_R_{VER_R}_{i}.weights.h5\")\n",
    "        pred_R = model_wave.predict(test_dataset_R, verbose=1)\n",
    "\n",
    "        model_spec.load_weights(f\"{LOAD_MODELS_FROM}/model_KE_{VER_KE}_{i}.weights.h5\")\n",
    "        pred_KE = model_spec.predict(test_dataset_KE, verbose=1)\n",
    "\n",
    "        model_hybrid.load_weights(\n",
    "            f\"{LOAD_MODELS_FROM}/model_KR_{VER_KR}_{i}.weights.h5\"\n",
    "        )\n",
    "        pred_KR = model_hybrid.predict(test_dataset_KR, verbose=1)\n",
    "\n",
    "        model_hybrid.load_weights(\n",
    "            f\"{LOAD_MODELS_FROM}/model_ER_{VER_ER}_{i}.weights.h5\"\n",
    "        )\n",
    "        pred_ER = model_hybrid.predict(test_dataset_ER, verbose=1)\n",
    "\n",
    "        model_hybrid.load_weights(\n",
    "            f\"{LOAD_MODELS_FROM}/model_KER_{VER_KER}_{i}.weights.h5\"\n",
    "        )\n",
    "        pred_KER = model_hybrid.predict(test_dataset_KER, verbose=1)\n",
    "\n",
    "        pred = np.array([pred_K, pred_E, pred_R, pred_KE, pred_KR, pred_ER, pred_KER])\n",
    "        pred = np.average(pred, axis=0, weights=weights)\n",
    "        preds.append(pred)\n",
    "\n",
    "    pred_model4 = np.mean(preds, axis=0)\n",
    "    print(\"Test preds shape\", pred_model4.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ec5aff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T23:03:44.737268Z",
     "iopub.status.busy": "2024-03-13T23:03:44.736127Z",
     "iopub.status.idle": "2024-03-13T23:03:45.829975Z",
     "shell.execute_reply": "2024-03-13T23:03:45.828869Z"
    },
    "papermill": {
     "duration": 1.147064,
     "end_time": "2024-03-13T23:03:45.832236",
     "exception": false,
     "start_time": "2024-03-13T23:03:44.685172",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# FREE MEMORY\n",
    "del model_spec, model_wave, model_hybrid\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c98a1ad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T23:03:45.940292Z",
     "iopub.status.busy": "2024-03-13T23:03:45.939117Z",
     "iopub.status.idle": "2024-03-13T23:03:45.943905Z",
     "shell.execute_reply": "2024-03-13T23:03:45.943025Z"
    },
    "papermill": {
     "duration": 0.063314,
     "end_time": "2024-03-13T23:03:45.946191",
     "exception": false,
     "start_time": "2024-03-13T23:03:45.882877",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# if submission:\n",
    "#     sub4 = pd.DataFrame({\"eeg_id\": test.eeg_id.values})\n",
    "#     sub4[TARGETS] = pred_model4\n",
    "#     print(\"Submissionn shape\", sub4.shape)\n",
    "#     print()\n",
    "#     sub4.to_csv(\"submission_model4.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30eaac8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T23:03:46.051111Z",
     "iopub.status.busy": "2024-03-13T23:03:46.050667Z",
     "iopub.status.idle": "2024-03-13T23:03:46.055059Z",
     "shell.execute_reply": "2024-03-13T23:03:46.054167Z"
    },
    "papermill": {
     "duration": 0.058951,
     "end_time": "2024-03-13T23:03:46.057278",
     "exception": false,
     "start_time": "2024-03-13T23:03:45.998327",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # SANITY CHECK TO CONFIRM PREDICTIONS SUM TO ONE\n",
    "# if submission:\n",
    "#     print(sub4.iloc[:, -6:].sum(axis=1).to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c574a99",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T23:03:46.161836Z",
     "iopub.status.busy": "2024-03-13T23:03:46.161458Z",
     "iopub.status.idle": "2024-03-13T23:03:46.169112Z",
     "shell.execute_reply": "2024-03-13T23:03:46.167443Z"
    },
    "papermill": {
     "duration": 0.062524,
     "end_time": "2024-03-13T23:03:46.171275",
     "exception": false,
     "start_time": "2024-03-13T23:03:46.108751",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pred_model4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0969117a",
   "metadata": {
    "papermill": {
     "duration": 0.051614,
     "end_time": "2024-03-13T23:03:46.272419",
     "exception": false,
     "start_time": "2024-03-13T23:03:46.220805",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model 5 - WaveNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a33cd042",
   "metadata": {
    "papermill": {
     "duration": 0.052023,
     "end_time": "2024-03-13T23:03:46.374789",
     "exception": false,
     "start_time": "2024-03-13T23:03:46.322766",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### [CV 0.68 | LB 0.46] DilatedInception WaveNet in PyTorch - Inference\n",
    "\n",
    "#### Introduction\n",
    "After joining this competition, I focus on validating how far raw EEG signals can go through many experiments. Finally, I find an simple architecture mixing the concept of **dilation** and **inception**, which can be seen as an extension of [Chris' version](https://www.kaggle.com/code/cdeotte/wavenet-starter-lb-0-52). And, I'm happy to announce that we can achieve CV 0.68 (below 0.7) and LB 0.46 with this architecture. Don't forget to upvote Chris' notebook!\n",
    "\n",
    "#### About this Notebook\n",
    "In this kernel, I run the inference process with 5-fold models (equally-weighted blending) and obtain LB 0.46. If you're also interested in training part, pleasse see [[LB 0.46] DilatedInception WaveNet - Training](https://www.kaggle.com/code/abaojiang/lb-0-46-dilatedinception-wavenet-training).\n",
    "\n",
    "#### Acknowledgements\n",
    "Special thanks to [@cdeotte](https://www.kaggle.com/cdeotte)'s sharing, [WaveNet Starter - [LB 0.52]](https://www.kaggle.com/code/cdeotte/wavenet-starter-lb-0-52).\n",
    "\n",
    "<a id=\"toc\"></a>\n",
    "## Table of Contents\n",
    "* [1. Load Data](#load_data)\n",
    "* [2. Define Dataset](#dataset)\n",
    "* [3. Create Test Loader](#test_loader)\n",
    "* [4. Define Model Architecture](#model)\n",
    "* [5. Load Models](#load_models)\n",
    "* [6. Run Inference](#infer)\n",
    "* [7. Submission](#sub)\n",
    "\n",
    "#### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c184581",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T23:03:46.479203Z",
     "iopub.status.busy": "2024-03-13T23:03:46.478753Z",
     "iopub.status.idle": "2024-03-13T23:03:46.486322Z",
     "shell.execute_reply": "2024-03-13T23:03:46.485250Z"
    },
    "papermill": {
     "duration": 0.061981,
     "end_time": "2024-03-13T23:03:46.488485",
     "exception": false,
     "start_time": "2024-03-13T23:03:46.426504",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "from typing import Any, Dict, List, Optional, Tuple, Type, Union\n",
    "import pickle\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yaml\n",
    "from scipy.signal import butter, lfilter\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7680acbd",
   "metadata": {
    "papermill": {
     "duration": 0.051282,
     "end_time": "2024-03-13T23:03:46.589845",
     "exception": false,
     "start_time": "2024-03-13T23:03:46.538563",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Define Data Paths and Configuration and Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99231919",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T23:03:46.692529Z",
     "iopub.status.busy": "2024-03-13T23:03:46.691588Z",
     "iopub.status.idle": "2024-03-13T23:03:46.700278Z",
     "shell.execute_reply": "2024-03-13T23:03:46.699270Z"
    },
    "papermill": {
     "duration": 0.062645,
     "end_time": "2024-03-13T23:03:46.702498",
     "exception": false,
     "start_time": "2024-03-13T23:03:46.639853",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATA_PATH = Path(config.competition_data_path)\n",
    "\n",
    "class CFG:\n",
    "    exp_id = \"0311-17-20-55\"\n",
    "    model_path = Path(f\"{config.full_path}/dilated-wavenet/0311-17-20-55\")\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    # == Data ==\n",
    "    # Chris' 8 channels\n",
    "    feats = [\n",
    "        \"Fp1\", \"T3\", \"C3\", \"O1\",\n",
    "        \"Fp2\", \"C4\", \"T4\", \"O2\"\n",
    "    ]\n",
    "    cast_eegs = True\n",
    "    dataset = {\n",
    "        \"eeg\": {\n",
    "            \"n_feats\": 8,\n",
    "            \"apply_chris_magic_ch8\": True,\n",
    "            \"normalize\": True,\n",
    "            \"apply_butter_lowpass_filter\": True,\n",
    "            \"apply_mu_law_encoding\": False,\n",
    "            \"downsample\": 5\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # == Data Loader ==\n",
    "    batch_size = 32\n",
    "    \n",
    "    \n",
    "N_CLASSES = 6\n",
    "TGT_VOTE_COLS = [\n",
    "    \"seizure_vote\", \"lpd_vote\", \"gpd_vote\", \"lrda_vote\",\n",
    "    \"grda_vote\", \"other_vote\"\n",
    "]\n",
    "EEG_FREQ = 200  # Hz\n",
    "EEG_WLEN = 50  # sec\n",
    "EEG_PTS = int(EEG_FREQ * EEG_WLEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e7125f8",
   "metadata": {
    "papermill": {
     "duration": 0.047917,
     "end_time": "2024-03-13T23:03:46.799036",
     "exception": false,
     "start_time": "2024-03-13T23:03:46.751119",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Load Data\n",
    "\n",
    "Note test data will be replaced with **hidden test set** during rerun."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b482654",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T23:03:46.901953Z",
     "iopub.status.busy": "2024-03-13T23:03:46.901147Z",
     "iopub.status.idle": "2024-03-13T23:03:46.910458Z",
     "shell.execute_reply": "2024-03-13T23:03:46.909429Z"
    },
    "papermill": {
     "duration": 0.064197,
     "end_time": "2024-03-13T23:03:46.912801",
     "exception": false,
     "start_time": "2024-03-13T23:03:46.848604",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def _get_eeg_window(file: Path) -> np.ndarray:\n",
    "    \"\"\"Return cropped EEG window.\n",
    "\n",
    "    Default setting is to return the middle 50-sec window.\n",
    "\n",
    "    Args:\n",
    "        file: EEG file path\n",
    "        test: if True, there's no need to truncate EEGs\n",
    "\n",
    "    Returns:\n",
    "        eeg_win: cropped EEG window \n",
    "    \"\"\"\n",
    "    eeg = pd.read_parquet(file, columns=CFG.feats)\n",
    "    n_pts = len(eeg)\n",
    "    offset = (n_pts - EEG_PTS) // 2\n",
    "    eeg = eeg.iloc[offset:offset + EEG_PTS]\n",
    "    \n",
    "    eeg_win = np.zeros((EEG_PTS, len(CFG.feats)))\n",
    "    for j, col in enumerate(CFG.feats):\n",
    "        if CFG.cast_eegs:\n",
    "            eeg_raw = eeg[col].values.astype(\"float32\")\n",
    "        else:\n",
    "            eeg_raw = eeg[col].values \n",
    "\n",
    "        # Fill missing values\n",
    "        mean = np.nanmean(eeg_raw)\n",
    "        if np.isnan(eeg_raw).mean() < 1:\n",
    "            eeg_raw = np.nan_to_num(eeg_raw, nan=mean)\n",
    "        else: \n",
    "            # All missing\n",
    "            eeg_raw[:] = 0\n",
    "        eeg_win[:, j] = eeg_raw \n",
    "        \n",
    "    return eeg_win "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9875295",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T23:03:47.019931Z",
     "iopub.status.busy": "2024-03-13T23:03:47.019295Z",
     "iopub.status.idle": "2024-03-13T23:03:47.028582Z",
     "shell.execute_reply": "2024-03-13T23:03:47.027544Z"
    },
    "papermill": {
     "duration": 0.064121,
     "end_time": "2024-03-13T23:03:47.030670",
     "exception": false,
     "start_time": "2024-03-13T23:03:46.966549",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv(DATA_PATH / \"test.csv\")\n",
    "print(f\"Test data shape | {test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f985f0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T23:03:47.136284Z",
     "iopub.status.busy": "2024-03-13T23:03:47.135196Z",
     "iopub.status.idle": "2024-03-13T23:03:47.172953Z",
     "shell.execute_reply": "2024-03-13T23:03:47.171906Z"
    },
    "papermill": {
     "duration": 0.095157,
     "end_time": "2024-03-13T23:03:47.177042",
     "exception": false,
     "start_time": "2024-03-13T23:03:47.081885",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "uniq_eeg_ids = test[\"eeg_id\"].unique()\n",
    "n_uniq_eeg_ids = len(uniq_eeg_ids)\n",
    "\n",
    "all_eegs = {}\n",
    "for i, eeg_id in tqdm(enumerate(uniq_eeg_ids), total=n_uniq_eeg_ids):\n",
    "    eeg_win = _get_eeg_window(DATA_PATH / \"test_eegs\" / f\"{eeg_id}.parquet\")\n",
    "    all_eegs[eeg_id] = eeg_win\n",
    "\n",
    "print(f\"Demo EEG shape | {list(all_eegs.values())[0].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6902d74b",
   "metadata": {
    "papermill": {
     "duration": 0.04894,
     "end_time": "2024-03-13T23:03:47.282521",
     "exception": false,
     "start_time": "2024-03-13T23:03:47.233581",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### 2. Define Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc95e9ce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T23:03:47.385535Z",
     "iopub.status.busy": "2024-03-13T23:03:47.384670Z",
     "iopub.status.idle": "2024-03-13T23:03:47.404238Z",
     "shell.execute_reply": "2024-03-13T23:03:47.403299Z"
    },
    "papermill": {
     "duration": 0.07286,
     "end_time": "2024-03-13T23:03:47.406287",
     "exception": false,
     "start_time": "2024-03-13T23:03:47.333427",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class _EEGTransformer(object):\n",
    "    \"\"\"Data transformer for raw EEG signals.\"\"\"\n",
    "\n",
    "    FEAT2CODE = {f: i for i, f in enumerate(CFG.feats)}\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_feats: int,\n",
    "        apply_chris_magic_ch8: bool = True,\n",
    "        normalize: bool = True,\n",
    "        apply_butter_lowpass_filter: bool = True,\n",
    "        apply_mu_law_encoding: bool = False,\n",
    "        downsample: Optional[int] = None,\n",
    "    ) -> None:\n",
    "        self.n_feats = n_feats\n",
    "        self.apply_chris_magic_ch8 = apply_chris_magic_ch8\n",
    "        self.normalize = normalize\n",
    "        self.apply_butter_lowpass_filter = apply_butter_lowpass_filter\n",
    "        self.apply_mu_law_encoding = apply_mu_law_encoding\n",
    "        self.downsample = downsample\n",
    "\n",
    "    def transform(self, x: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Apply transformation on raw EEG signals.\n",
    "        \n",
    "        Args:\n",
    "            x: raw EEG signals, with shape (L, C)\n",
    "\n",
    "        Return:\n",
    "            x_: transformed EEG signals\n",
    "        \"\"\"\n",
    "        x_ = x.copy()\n",
    "        if self.apply_chris_magic_ch8:\n",
    "            x_ = self._apply_chris_magic_ch8(x_)\n",
    "\n",
    "        if self.normalize:\n",
    "            x_ = np.clip(x_, -1024, 1024)\n",
    "            x_ = np.nan_to_num(x_, nan=0) / 32.0\n",
    "\n",
    "        if self.apply_butter_lowpass_filter:\n",
    "            x_ = self._butter_lowpass_filter(x_) \n",
    "\n",
    "        if self.apply_mu_law_encoding:\n",
    "            x_ = self._quantize_data(x_, 1)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            x_ = x_[::self.downsample, :]\n",
    "\n",
    "        return x_\n",
    "\n",
    "    def _apply_chris_magic_ch8(self, x: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Generate features based on Chris' magic formula.\"\"\" \n",
    "        x_tmp = np.zeros((EEG_PTS, self.n_feats), dtype=\"float32\")\n",
    "\n",
    "        # Generate features\n",
    "        x_tmp[:, 0] = x[:, self.FEAT2CODE[\"Fp1\"]] - x[:, self.FEAT2CODE[\"T3\"]]\n",
    "        x_tmp[:, 1] = x[:, self.FEAT2CODE[\"T3\"]] - x[:, self.FEAT2CODE[\"O1\"]]\n",
    "        \n",
    "        x_tmp[:, 2] = x[:, self.FEAT2CODE[\"Fp1\"]] - x[:, self.FEAT2CODE[\"C3\"]]\n",
    "        x_tmp[:, 3] = x[:, self.FEAT2CODE[\"C3\"]] - x[:, self.FEAT2CODE[\"O1\"]]\n",
    "        \n",
    "        x_tmp[:, 4] = x[:, self.FEAT2CODE[\"Fp2\"]] - x[:, self.FEAT2CODE[\"C4\"]]\n",
    "        x_tmp[:, 5] = x[:, self.FEAT2CODE[\"C4\"]] - x[:, self.FEAT2CODE[\"O2\"]]\n",
    "        \n",
    "        x_tmp[:, 6] = x[:, self.FEAT2CODE[\"Fp2\"]] - x[:, self.FEAT2CODE[\"T4\"]]\n",
    "        x_tmp[:, 7] = x[:, self.FEAT2CODE[\"T4\"]] - x[:, self.FEAT2CODE[\"O2\"]]\n",
    "\n",
    "        return x_tmp\n",
    "\n",
    "    def _butter_lowpass_filter(self, data, cutoff_freq=20, sampling_rate=200, order=4):\n",
    "        nyquist = 0.5 * sampling_rate\n",
    "        normal_cutoff = cutoff_freq / nyquist\n",
    "        b, a = butter(order, normal_cutoff, btype=\"low\", analog=False)\n",
    "        filtered_data = lfilter(b, a, data, axis=0)\n",
    "\n",
    "        return filtered_data\n",
    "                \n",
    "    def _quantize_data(self, data, classes):\n",
    "        mu_x = self._mu_law_encoding(data, classes)\n",
    "        \n",
    "        return mu_x\n",
    "\n",
    "    def _mu_law_encoding(self, data, mu):\n",
    "        mu_x = np.sign(data) * np.log(1 + mu * np.abs(data)) / np.log(mu + 1)\n",
    "\n",
    "        return mu_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379fd430",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T23:03:47.508649Z",
     "iopub.status.busy": "2024-03-13T23:03:47.508262Z",
     "iopub.status.idle": "2024-03-13T23:03:47.524938Z",
     "shell.execute_reply": "2024-03-13T23:03:47.523927Z"
    },
    "papermill": {
     "duration": 0.071124,
     "end_time": "2024-03-13T23:03:47.527029",
     "exception": false,
     "start_time": "2024-03-13T23:03:47.455905",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class EEGDataset(Dataset):\n",
    "    \"\"\"Dataset for pure raw EEG signals.\n",
    "\n",
    "    Args:\n",
    "        data: processed data\n",
    "        split: data split\n",
    "\n",
    "    Attributes:\n",
    "        _n_samples: number of samples\n",
    "        _infer: if True, the dataset is constructed for inference\n",
    "            *Note: Ground truth is not provided.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        data: Dict[str,  Any],\n",
    "        split: str,\n",
    "        **dataset_cfg: Any,\n",
    "    ) -> None:\n",
    "        self.metadata = data[\"meta\"]\n",
    "        self.all_eegs = data[\"eeg\"]\n",
    "        self.dataset_cfg = dataset_cfg\n",
    "\n",
    "        # Raw EEG data transformer\n",
    "        self.eeg_params = dataset_cfg[\"eeg\"]\n",
    "        self.eeg_trafo = _EEGTransformer(**self.eeg_params)\n",
    "\n",
    "        self._set_n_samples()\n",
    "        self._infer = True if split == \"test\" else False\n",
    "\n",
    "        self._stream_X = True if self.all_eegs is None else False\n",
    "        self._X, self._y = self._transform()\n",
    "\n",
    "    def _set_n_samples(self) -> None:\n",
    "        assert len(self.metadata) == self.metadata[\"eeg_id\"].nunique()\n",
    "        self._n_samples = len(self.metadata)\n",
    "\n",
    "    def _transform(self) -> Tuple[Optional[np.ndarray], np.ndarray]:\n",
    "        \"\"\"Transform feature and target matrices.\"\"\"\n",
    "        if self.eeg_params[\"downsample\"] is not None:\n",
    "            eeg_len = int(EEG_PTS / self.eeg_params[\"downsample\"])\n",
    "        else:\n",
    "            eeg_len = int(EEG_PTS)\n",
    "        if not self._stream_X:\n",
    "            X = np.zeros((self._n_samples, eeg_len, self.eeg_params[\"n_feats\"]), dtype=\"float32\")\n",
    "        else:\n",
    "            X = None\n",
    "        y = np.zeros((self._n_samples, N_CLASSES), dtype=\"float32\") if not self._infer else None\n",
    "\n",
    "        for i, row in tqdm(self.metadata.iterrows(), total=len(self.metadata)):\n",
    "            # Process raw EEG signals\n",
    "            if not self._stream_X:\n",
    "                # Retrieve raw EEG signals\n",
    "                eeg = self.all_eegs[row[\"eeg_id\"]]\n",
    "\n",
    "                # Apply EEG transformer\n",
    "                x = self.eeg_trafo.transform(eeg)\n",
    "\n",
    "                X[i] = x\n",
    "\n",
    "            if not self._infer:\n",
    "                y[i] = row[TGT_VOTE_COLS] \n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return self._n_samples\n",
    "\n",
    "    def __getitem__(self, idx: int) -> Dict[str, Tensor]:\n",
    "        if self._X is None:\n",
    "            # Load data here...\n",
    "#             x = np.load(...)\n",
    "#             x = self.eeg_trafo.transform(x)\n",
    "            pass\n",
    "        else:\n",
    "            x = self._X[idx, ...]\n",
    "        data_sample = {\"x\": torch.tensor(x, dtype=torch.float32)}\n",
    "        if not self._infer:\n",
    "            data_sample[\"y\"] = torch.tensor(self._y[idx, :], dtype=torch.float32)\n",
    "\n",
    "        return data_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b43998",
   "metadata": {
    "papermill": {
     "duration": 0.050641,
     "end_time": "2024-03-13T23:03:47.629310",
     "exception": false,
     "start_time": "2024-03-13T23:03:47.578669",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<a id=\"test_loader\"></a>\n",
    "## 3. Create Test Loader\n",
    "[**<span style=\"color:#FEF1FE; background-color:#535d70;border-radius: 5px; padding: 2px\">Go to Table of Content</span>**](#toc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e8e09f6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T23:03:47.730358Z",
     "iopub.status.busy": "2024-03-13T23:03:47.729576Z",
     "iopub.status.idle": "2024-03-13T23:03:47.755721Z",
     "shell.execute_reply": "2024-03-13T23:03:47.754589Z"
    },
    "papermill": {
     "duration": 0.086752,
     "end_time": "2024-03-13T23:03:47.764320",
     "exception": false,
     "start_time": "2024-03-13T23:03:47.677568",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_data = {\"meta\": test, \"eeg\": all_eegs}\n",
    "test_loader = DataLoader(\n",
    "    EEGDataset(test_data, \"test\", **CFG.dataset),\n",
    "    batch_size=CFG.batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")\n",
    "print(f\"There are {len(test_loader.dataset)} test samples to infer.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a89e9bce",
   "metadata": {
    "papermill": {
     "duration": 0.049336,
     "end_time": "2024-03-13T23:03:47.865658",
     "exception": false,
     "start_time": "2024-03-13T23:03:47.816322",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### 4. Define Model Architecture\n",
    "\n",
    "[![Screenshot-2024-02-19-at-1-11-40-PM.png](https://i.postimg.cc/MKp8xVVV/Screenshot-2024-02-19-at-1-11-40-PM.png)](https://postimg.cc/7bdRnCBZ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab877a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T23:03:47.973100Z",
     "iopub.status.busy": "2024-03-13T23:03:47.972527Z",
     "iopub.status.idle": "2024-03-13T23:03:48.001579Z",
     "shell.execute_reply": "2024-03-13T23:03:48.000482Z"
    },
    "papermill": {
     "duration": 0.087349,
     "end_time": "2024-03-13T23:03:48.004138",
     "exception": false,
     "start_time": "2024-03-13T23:03:47.916789",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class _WaveBlock(nn.Module):\n",
    "    \"\"\"WaveNet block.\n",
    "\n",
    "    Args:\n",
    "        kernel_size: kernel size, pass a list of kernel sizes for\n",
    "            inception\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_layers: int, \n",
    "        in_dim: int,\n",
    "        h_dim: int,\n",
    "        kernel_size: Union[int, List[int]],\n",
    "        conv_module: Optional[Type[nn.Module]] = None,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.n_layers = n_layers\n",
    "        self.dilation_rates = [2**l for l in range(n_layers)]\n",
    "\n",
    "        self.in_conv = nn.Conv2d(in_dim, h_dim, kernel_size=(1, 1)) \n",
    "        self.gated_tcns = nn.ModuleList()\n",
    "        self.skip_convs = nn.ModuleList()\n",
    "        for layer in range(n_layers):\n",
    "            c_in, c_out = h_dim, h_dim\n",
    "            self.gated_tcns.append(\n",
    "                _GatedTCN(\n",
    "                    in_dim=c_in,\n",
    "                    h_dim=c_out,\n",
    "                    kernel_size=kernel_size,\n",
    "                    dilation_factor=self.dilation_rates[layer],\n",
    "                    conv_module=conv_module,\n",
    "                )\n",
    "            )\n",
    "            self.skip_convs.append(nn.Conv2d(h_dim, h_dim, kernel_size=(1, 1)))\n",
    "\n",
    "        # Initialize parameters\n",
    "        nn.init.xavier_uniform_(self.in_conv.weight, gain=nn.init.calculate_gain(\"relu\"))\n",
    "        nn.init.zeros_(self.in_conv.bias)\n",
    "        for i in range(len(self.skip_convs)):\n",
    "            nn.init.xavier_uniform_(self.skip_convs[i].weight, gain=nn.init.calculate_gain(\"relu\"))\n",
    "            nn.init.zeros_(self.skip_convs[i].bias)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        \"\"\"Forward pass.\n",
    "        \n",
    "        Shape:\n",
    "            x: (B, C, N, L), where C denotes in_dim\n",
    "            x_skip: (B, C', N, L), where C' denotes h_dim\n",
    "        \"\"\"\n",
    "        # Input convolution\n",
    "        x = self.in_conv(x)\n",
    "\n",
    "        x_skip = x\n",
    "        for layer in range(self.n_layers):\n",
    "            x = self.gated_tcns[layer](x)\n",
    "            x = self.skip_convs[layer](x)\n",
    "\n",
    "            # Skip-connection\n",
    "            x_skip = x_skip + x \n",
    "\n",
    "        return x_skip\n",
    "\n",
    "\n",
    "class _GatedTCN(nn.Module):\n",
    "    \"\"\"Gated temporal convolution layer.\n",
    "\n",
    "    Parameters:\n",
    "        conv_module: customized convolution module\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_dim: int,\n",
    "        h_dim: int,\n",
    "        kernel_size: Union[int, List[int]],\n",
    "        dilation_factor: int,\n",
    "        dropout: Optional[float] = None,\n",
    "        conv_module: Optional[Type[nn.Module]] = None,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        # Model blocks\n",
    "        if conv_module is None:\n",
    "            self.filt = nn.Conv2d(\n",
    "                in_channels=in_dim, out_channels=h_dim, kernel_size=(1, kernel_size), dilation=dilation_factor\n",
    "            )\n",
    "            self.gate = nn.Conv2d(\n",
    "                in_channels=in_dim, out_channels=h_dim, kernel_size=(1, kernel_size), dilation=dilation_factor\n",
    "            )\n",
    "        else:\n",
    "            self.filt = conv_module(\n",
    "                in_channels=in_dim, out_channels=h_dim, kernel_size=kernel_size, dilation=dilation_factor\n",
    "            )\n",
    "            self.gate = conv_module(\n",
    "                in_channels=in_dim, out_channels=h_dim, kernel_size=kernel_size, dilation=dilation_factor\n",
    "            )\n",
    "\n",
    "        if dropout is not None:\n",
    "            self.dropout = nn.Dropout(dropout)\n",
    "        else:\n",
    "            self.dropout = None\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        \"\"\"Forward pass.\n",
    "\n",
    "        Parameters:\n",
    "            x: input sequence\n",
    "\n",
    "        Return:\n",
    "            h: output sequence\n",
    "\n",
    "        Shape:\n",
    "            x: (B, C, N, L), where L denotes the input sequence length\n",
    "            h: (B, h_dim, N, L')\n",
    "        \"\"\"\n",
    "        x_filt = F.tanh(self.filt(x))\n",
    "        x_gate = F.sigmoid(self.gate(x))\n",
    "        h = x_filt * x_gate\n",
    "        if self.dropout is not None:\n",
    "            h = self.dropout(h)\n",
    "\n",
    "        return h\n",
    "\n",
    "\n",
    "class _DilatedInception(nn.Module):\n",
    "    \"\"\"Dilated inception layer.\n",
    "\n",
    "    Note that `out_channels` will be split across #kernels.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, \n",
    "        in_channels: int, \n",
    "        out_channels: int, \n",
    "        kernel_size: List[int], \n",
    "        dilation: int\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        # Network parameters\n",
    "        n_kernels = len(kernel_size)\n",
    "        assert out_channels % n_kernels == 0, \"`out_channels` must be divisible by #kernels.\"\n",
    "        h_dim = out_channels // n_kernels\n",
    "\n",
    "        # Model blocks\n",
    "        self.convs = nn.ModuleList()\n",
    "        for k in kernel_size:\n",
    "            self.convs.append(\n",
    "                nn.Conv2d(\n",
    "                    in_channels=in_channels, \n",
    "                    out_channels=h_dim, \n",
    "                    kernel_size=(1, k),\n",
    "                    padding=\"same\",\n",
    "                    dilation=dilation),\n",
    "            )\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        \"\"\"Forward pass.\n",
    "\n",
    "        Parameters:\n",
    "            x: input sequence\n",
    "\n",
    "        Return:\n",
    "            h: output sequence\n",
    "\n",
    "        Shape:\n",
    "            x: (B, C, N, L), where C = in_channels\n",
    "            h: (B, C', N, L'), where C' = out_channels\n",
    "        \"\"\"\n",
    "        x_convs = []\n",
    "        for conv in self.convs:\n",
    "            x_conv = conv(x)\n",
    "            x_convs.append(x_conv)\n",
    "        h = torch.cat(x_convs, dim=1)\n",
    "\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "493062a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T23:03:48.108400Z",
     "iopub.status.busy": "2024-03-13T23:03:48.107360Z",
     "iopub.status.idle": "2024-03-13T23:03:48.122963Z",
     "shell.execute_reply": "2024-03-13T23:03:48.122077Z"
    },
    "papermill": {
     "duration": 0.069001,
     "end_time": "2024-03-13T23:03:48.125070",
     "exception": false,
     "start_time": "2024-03-13T23:03:48.056069",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DilatedInceptionWaveNet(nn.Module):\n",
    "    \"\"\"WaveNet architecture with dilated inception conv.\"\"\"\n",
    "\n",
    "    def __init__(self,) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        kernel_size = [2, 3, 6, 7]\n",
    "\n",
    "        # Model blocks \n",
    "        self.wave_module = nn.Sequential(\n",
    "            _WaveBlock(12, 1, 16, kernel_size, _DilatedInception),\n",
    "            _WaveBlock(8, 16, 32, kernel_size, _DilatedInception),\n",
    "            _WaveBlock(4, 32, 64, kernel_size, _DilatedInception),\n",
    "            _WaveBlock(1, 64, 64, kernel_size, _DilatedInception),\n",
    "        )\n",
    "        self.output = nn.Sequential(\n",
    "            nn.Linear(64 * 4, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, N_CLASSES)\n",
    "        ) \n",
    "\n",
    "    def forward(self, inputs: Dict[str, Tensor]) -> Tensor:\n",
    "        \"\"\"Forward pass.\n",
    "\n",
    "        Shape:\n",
    "            x: (B, L, C)\n",
    "        \"\"\"\n",
    "        x = inputs[\"x\"]\n",
    "        bs, length, in_dim = x.shape\n",
    "        x = x.transpose(1, 2).unsqueeze(dim=2)  # (B, C, N, L), N is redundant\n",
    "\n",
    "        x_ll_1 = self.wave_module(x[:, 0:1, :])\n",
    "        x_ll_2 = self.wave_module(x[:, 1:2, :])\n",
    "        x_ll = (F.adaptive_avg_pool2d(x_ll_1, (1, 1)) + F.adaptive_avg_pool2d(x_ll_2, (1, 1))) / 2\n",
    "\n",
    "        x_rl_1 = self.wave_module(x[:, 2:3, :])\n",
    "        x_rl_2 = self.wave_module(x[:, 3:4, :])\n",
    "        x_rl = (F.adaptive_avg_pool2d(x_rl_1, (1, 1)) + F.adaptive_avg_pool2d(x_rl_2, (1, 1))) / 2\n",
    "\n",
    "        x_lp_1 = self.wave_module(x[:, 4:5, :])\n",
    "        x_lp_2 = self.wave_module(x[:, 5:6, :])\n",
    "        x_lp = (F.adaptive_avg_pool2d(x_lp_1, (1, 1)) + F.adaptive_avg_pool2d(x_lp_2, (1, 1))) / 2\n",
    "\n",
    "        x_rp_1 = self.wave_module(x[:, 6:7, :])\n",
    "        x_rp_2 = self.wave_module(x[:, 7:8, :])\n",
    "        x_rp = (F.adaptive_avg_pool2d(x_rp_1, (1, 1)) + F.adaptive_avg_pool2d(x_rp_2, (1, 1))) / 2\n",
    "\n",
    "        x = torch.cat([x_ll, x_rl, x_lp, x_rp], axis=1).reshape(bs, -1)\n",
    "        output = self.output(x)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ec7ae8",
   "metadata": {
    "papermill": {
     "duration": 0.050794,
     "end_time": "2024-03-13T23:03:48.227774",
     "exception": false,
     "start_time": "2024-03-13T23:03:48.176980",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### 5. Load Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7985d0c2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T23:03:48.332805Z",
     "iopub.status.busy": "2024-03-13T23:03:48.331877Z",
     "iopub.status.idle": "2024-03-13T23:03:50.183818Z",
     "shell.execute_reply": "2024-03-13T23:03:50.182774Z"
    },
    "papermill": {
     "duration": 1.907851,
     "end_time": "2024-03-13T23:03:50.186469",
     "exception": false,
     "start_time": "2024-03-13T23:03:48.278618",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "models = []\n",
    "for fold, file in enumerate(sorted(CFG.model_path.glob(\"./*.pth\"))):\n",
    "    print(f\"Load model from {file}...\")\n",
    "    fold_model = DilatedInceptionWaveNet()\n",
    "    fold_model.load_state_dict(torch.load(file, map_location=CFG.device))\n",
    "    fold_model = fold_model.to(CFG.device)\n",
    "    models.append(fold_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e6cdd12",
   "metadata": {
    "papermill": {
     "duration": 0.0545,
     "end_time": "2024-03-13T23:03:50.296929",
     "exception": false,
     "start_time": "2024-03-13T23:03:50.242429",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### 6. Run Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a79311",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T23:03:50.403988Z",
     "iopub.status.busy": "2024-03-13T23:03:50.403249Z",
     "iopub.status.idle": "2024-03-13T23:03:50.410311Z",
     "shell.execute_reply": "2024-03-13T23:03:50.409302Z"
    },
    "papermill": {
     "duration": 0.064145,
     "end_time": "2024-03-13T23:03:50.412730",
     "exception": false,
     "start_time": "2024-03-13T23:03:50.348585",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def _infer(inputs: Dict[str, Tensor], models: List[nn.Module]) -> Tensor:\n",
    "    n_models = len(models)\n",
    "\n",
    "    for i, model in enumerate(models):\n",
    "        model.eval()\n",
    "        y_pred_fold = F.softmax(model(inputs)) / n_models    # (B, N_CLASSES)\n",
    "        \n",
    "        if i == 0:\n",
    "            y_pred = y_pred_fold\n",
    "        else:\n",
    "            y_pred += y_pred_fold\n",
    "        \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df117c51",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T23:03:50.519667Z",
     "iopub.status.busy": "2024-03-13T23:03:50.519294Z",
     "iopub.status.idle": "2024-03-13T23:03:53.055539Z",
     "shell.execute_reply": "2024-03-13T23:03:53.054257Z"
    },
    "papermill": {
     "duration": 2.592037,
     "end_time": "2024-03-13T23:03:53.057769",
     "exception": false,
     "start_time": "2024-03-13T23:03:50.465732",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_preds = []\n",
    "for i, batch_data in enumerate(test_loader):\n",
    "    batch_data[\"x\"] = batch_data[\"x\"].to(CFG.device)\n",
    "    y_pred = _infer(batch_data, models)\n",
    "    y_preds.append(y_pred.detach().cpu().numpy())\n",
    "y_preds = np.vstack(y_preds)\n",
    "print(f\"Sum of row 0 in y_preds {np.sum(y_preds[0, :])}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed27f6ed",
   "metadata": {
    "papermill": {
     "duration": 0.052533,
     "end_time": "2024-03-13T23:03:53.162179",
     "exception": false,
     "start_time": "2024-03-13T23:03:53.109646",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### 7. Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5db8b09",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T23:03:53.269369Z",
     "iopub.status.busy": "2024-03-13T23:03:53.268586Z",
     "iopub.status.idle": "2024-03-13T23:03:53.273354Z",
     "shell.execute_reply": "2024-03-13T23:03:53.272360Z"
    },
    "papermill": {
     "duration": 0.060531,
     "end_time": "2024-03-13T23:03:53.275474",
     "exception": false,
     "start_time": "2024-03-13T23:03:53.214943",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pred_model5 = y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38dbbd10",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T23:03:53.385850Z",
     "iopub.status.busy": "2024-03-13T23:03:53.385453Z",
     "iopub.status.idle": "2024-03-13T23:03:53.393188Z",
     "shell.execute_reply": "2024-03-13T23:03:53.392033Z"
    },
    "papermill": {
     "duration": 0.065446,
     "end_time": "2024-03-13T23:03:53.395645",
     "exception": false,
     "start_time": "2024-03-13T23:03:53.330199",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pred_model5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9dd776",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T23:03:53.501140Z",
     "iopub.status.busy": "2024-03-13T23:03:53.500743Z",
     "iopub.status.idle": "2024-03-13T23:03:53.505177Z",
     "shell.execute_reply": "2024-03-13T23:03:53.504225Z"
    },
    "papermill": {
     "duration": 0.060253,
     "end_time": "2024-03-13T23:03:53.507429",
     "exception": false,
     "start_time": "2024-03-13T23:03:53.447176",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# if submission:\n",
    "#     sub5 = pd.DataFrame({\"eeg_id\": test.eeg_id.values})\n",
    "#     sub5[TARGETS] = pred_model5\n",
    "#     print(\"Submissionn shape\", sub5.shape)\n",
    "#     print()\n",
    "#     print(sub5.head().to_string())\n",
    "# #     sub5.to_csv(\"submission_model5.csv\", index=False)\n",
    "#     sub5.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8431db",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T23:03:53.614379Z",
     "iopub.status.busy": "2024-03-13T23:03:53.614022Z",
     "iopub.status.idle": "2024-03-13T23:03:53.618446Z",
     "shell.execute_reply": "2024-03-13T23:03:53.617468Z"
    },
    "papermill": {
     "duration": 0.06044,
     "end_time": "2024-03-13T23:03:53.620738",
     "exception": false,
     "start_time": "2024-03-13T23:03:53.560298",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # SANITY CHECK TO CONFIRM PREDICTIONS SUM TO ONE\n",
    "# if submission:\n",
    "#     print(sub5.iloc[:, -6:].sum(axis=1).to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a491e93",
   "metadata": {
    "papermill": {
     "duration": 0.05015,
     "end_time": "2024-03-13T23:03:53.723197",
     "exception": false,
     "start_time": "2024-03-13T23:03:53.673047",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model 6 - CatBoost Starter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80609a46",
   "metadata": {
    "papermill": {
     "duration": 0.051501,
     "end_time": "2024-03-13T23:03:53.825315",
     "exception": false,
     "start_time": "2024-03-13T23:03:53.773814",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## CatBoost Starter for Brain Comp\n",
    "This is a CatBoost starter notebook for Kaggle's brain comp. We use only spectrogram features. (The model does not use eeg features yet). We can improve the CV and LB score by engineering more (spectrogram and/or eeg) features and we can tune the CatBoost model (and/or use other ML DL models). Discussion about this starter is [here][2].\n",
    "\n",
    "In this notebook, we also compare five CV scores. Kaggle's sample submission uses equal predictions of 1/6 for all targets and achieves CV 1.46, LB 1.09. The best public notebook (on Jan 12th) [here][1] uses train means and achieves CV 1.26 LB 0.97. Our CatBoost model version 1 achieves CV 1.01 LB 0.81. Our CatBoost model version 2 achieves CV 0.82 LB 0.67. Then version 3 adds features from **EEG spectrograms** and achieves CV 0.74, wow! Let's see what LB is...\n",
    "\n",
    "### Exciting UPDATE!\n",
    "Version 3 of this notebook trains using **both** Kaggle spectrograms and my new **EEG spectrograms** from my Kaggle dataset [here][3] (which were created from my spectrogram starter [here][4]). We boost the CV score and (most likely) LB score by almost `+0.10`, wow! \n",
    "\n",
    "#### Version Notes\n",
    "* Version 1 - Uses spectrogram features from 10 minute window `means`. Achieves CV 1.01, LB 0.81\n",
    "* Version 2 - Uses spectrogram features from 10 minute and 20 second `means` and `mins`. Achieves CV 0.82, LB 0.67\n",
    "* Version 3 - Uses Kaggle spectrogrms **plus EEG spectrograms**. Achieves 0.74, LB to be determined...\n",
    "\n",
    "[1]: https://www.kaggle.com/code/seshurajup/eda-train-csv\n",
    "[2]: https://www.kaggle.com/competitions/hms-harmful-brain-activity-classification/discussion/467576\n",
    "[3]: https://www.kaggle.com/datasets/cdeotte/brain-eeg-spectrograms\n",
    "[4]: https://www.kaggle.com/code/cdeotte/how-to-make-spectrogram-from-eeg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9faee5a5",
   "metadata": {
    "papermill": {
     "duration": 0.049633,
     "end_time": "2024-03-13T23:03:53.924436",
     "exception": false,
     "start_time": "2024-03-13T23:03:53.874803",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966131f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T23:03:54.034761Z",
     "iopub.status.busy": "2024-03-13T23:03:54.034377Z",
     "iopub.status.idle": "2024-03-13T23:03:54.040019Z",
     "shell.execute_reply": "2024-03-13T23:03:54.038895Z"
    },
    "papermill": {
     "duration": 0.06379,
     "end_time": "2024-03-13T23:03:54.042254",
     "exception": false,
     "start_time": "2024-03-13T23:03:53.978464",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os, gc\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\"\n",
    "import pandas as pd, numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "VER = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4203fa6",
   "metadata": {
    "papermill": {
     "duration": 0.051373,
     "end_time": "2024-03-13T23:03:54.147732",
     "exception": false,
     "start_time": "2024-03-13T23:03:54.096359",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Load Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b1c75c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T23:03:54.255755Z",
     "iopub.status.busy": "2024-03-13T23:03:54.254866Z",
     "iopub.status.idle": "2024-03-13T23:03:54.428080Z",
     "shell.execute_reply": "2024-03-13T23:03:54.426924Z"
    },
    "papermill": {
     "duration": 0.229348,
     "end_time": "2024-03-13T23:03:54.430304",
     "exception": false,
     "start_time": "2024-03-13T23:03:54.200956",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(config.data_train_csv)\n",
    "TARGETS = df.columns[-6:]\n",
    "print(\"Train shape:\", df.shape)\n",
    "print(\"Targets\", list(TARGETS))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab6015db",
   "metadata": {
    "papermill": {
     "duration": 0.050318,
     "end_time": "2024-03-13T23:03:54.536306",
     "exception": false,
     "start_time": "2024-03-13T23:03:54.485988",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Create Non-Overlapping Eeg Id Train Data\n",
    "The competition data description says that test data does not have multiple crops from the same `eeg_id`. Therefore we will train and validate using only 1 crop per `eeg_id`. There is a discussion about this [here][1].\n",
    "\n",
    "[1]: https://www.kaggle.com/competitions/hms-harmful-brain-activity-classification/discussion/467021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3c58e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T23:03:54.641950Z",
     "iopub.status.busy": "2024-03-13T23:03:54.641548Z",
     "iopub.status.idle": "2024-03-13T23:03:54.734116Z",
     "shell.execute_reply": "2024-03-13T23:03:54.732590Z"
    },
    "papermill": {
     "duration": 0.15009,
     "end_time": "2024-03-13T23:03:54.736966",
     "exception": false,
     "start_time": "2024-03-13T23:03:54.586876",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = hp.preprocess_eeg_data(train_df, TARGETS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d071ef7e",
   "metadata": {
    "papermill": {
     "duration": 0.052204,
     "end_time": "2024-03-13T23:03:54.849072",
     "exception": false,
     "start_time": "2024-03-13T23:03:54.796868",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Infer Test and Create Submission CSV\n",
    "Below we use our 5 CatBoost fold models to infer the test data and create a `submission.csv` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d598acd6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T23:03:54.979314Z",
     "iopub.status.busy": "2024-03-13T23:03:54.978468Z",
     "iopub.status.idle": "2024-03-13T23:03:55.001563Z",
     "shell.execute_reply": "2024-03-13T23:03:55.000645Z"
    },
    "papermill": {
     "duration": 0.091518,
     "end_time": "2024-03-13T23:03:55.003634",
     "exception": false,
     "start_time": "2024-03-13T23:03:54.912116",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pywt, librosa\n",
    "\n",
    "USE_WAVELET = None\n",
    "\n",
    "NAMES = [\"LL\", \"LP\", \"RP\", \"RR\"]\n",
    "\n",
    "FEATS = [\n",
    "    [\"Fp1\", \"F7\", \"T3\", \"T5\", \"O1\"],\n",
    "    [\"Fp1\", \"F3\", \"C3\", \"P3\", \"O1\"],\n",
    "    [\"Fp2\", \"F8\", \"T4\", \"T6\", \"O2\"],\n",
    "    [\"Fp2\", \"F4\", \"C4\", \"P4\", \"O2\"],\n",
    "]\n",
    "\n",
    "\n",
    "# DENOISE FUNCTION\n",
    "def maddest(d, axis=None):\n",
    "    return np.mean(np.absolute(d - np.mean(d, axis)), axis)\n",
    "\n",
    "\n",
    "def denoise(x, wavelet=\"haar\", level=1):\n",
    "    coeff = pywt.wavedec(x, wavelet, mode=\"per\")\n",
    "    sigma = (1 / 0.6745) * maddest(coeff[-level])\n",
    "\n",
    "    uthresh = sigma * np.sqrt(2 * np.log(len(x)))\n",
    "    coeff[1:] = (pywt.threshold(i, value=uthresh, mode=\"hard\") for i in coeff[1:])\n",
    "\n",
    "    ret = pywt.waverec(coeff, wavelet, mode=\"per\")\n",
    "\n",
    "    return ret\n",
    "\n",
    "\n",
    "def spectrogram_from_eeg(parquet_path, display=False):\n",
    "\n",
    "    # LOAD MIDDLE 50 SECONDS OF EEG SERIES\n",
    "    eeg = pd.read_parquet(parquet_path)\n",
    "    middle = (len(eeg) - 10_000) // 2\n",
    "    eeg = eeg.iloc[middle : middle + 10_000]\n",
    "\n",
    "    # VARIABLE TO HOLD SPECTROGRAM\n",
    "    img = np.zeros((128, 256, 4), dtype=\"float32\")\n",
    "\n",
    "    if display:\n",
    "        plt.figure(figsize=(10, 7))\n",
    "    signals = []\n",
    "    for k in range(4):\n",
    "        COLS = FEATS[k]\n",
    "\n",
    "        for kk in range(4):\n",
    "\n",
    "            # COMPUTE PAIR DIFFERENCES\n",
    "            x = eeg[COLS[kk]].values - eeg[COLS[kk + 1]].values\n",
    "\n",
    "            # FILL NANS\n",
    "            m = np.nanmean(x)\n",
    "            if np.isnan(x).mean() < 1:\n",
    "                x = np.nan_to_num(x, nan=m)\n",
    "            else:\n",
    "                x[:] = 0\n",
    "\n",
    "            # DENOISE\n",
    "            if USE_WAVELET:\n",
    "                x = denoise(x, wavelet=USE_WAVELET)\n",
    "            signals.append(x)\n",
    "\n",
    "            # RAW SPECTROGRAM\n",
    "            mel_spec = librosa.feature.melspectrogram(\n",
    "                y=x,\n",
    "                sr=200,\n",
    "                hop_length=len(x) // 256,\n",
    "                n_fft=1024,\n",
    "                n_mels=128,\n",
    "                fmin=0,\n",
    "                fmax=20,\n",
    "                win_length=128,\n",
    "            )\n",
    "\n",
    "            # LOG TRANSFORM\n",
    "            width = (mel_spec.shape[1] // 32) * 32\n",
    "            mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max).astype(np.float32)[\n",
    "                :, :width\n",
    "            ]\n",
    "\n",
    "            # STANDARDIZE TO -1 TO 1\n",
    "            mel_spec_db = (mel_spec_db + 40) / 40\n",
    "            img[:, :, k] += mel_spec_db\n",
    "\n",
    "        # AVERAGE THE 4 MONTAGE DIFFERENCES\n",
    "        img[:, :, k] /= 4.0\n",
    "\n",
    "        if display:\n",
    "            plt.subplot(2, 2, k + 1)\n",
    "            plt.imshow(img[:, :, k], aspect=\"auto\", origin=\"lower\")\n",
    "            plt.title(f\"EEG {eeg_id} - Spectrogram {NAMES[k]}\")\n",
    "\n",
    "    if display:\n",
    "        plt.show()\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        offset = 0\n",
    "        for k in range(4):\n",
    "            if k > 0:\n",
    "                offset -= signals[3 - k].min()\n",
    "            plt.plot(range(10_000), signals[k] + offset, label=NAMES[3 - k])\n",
    "            offset += signals[3 - k].max()\n",
    "        plt.legend()\n",
    "        plt.title(f\"EEG {eeg_id} Signals\")\n",
    "        plt.show()\n",
    "        print()\n",
    "        print(\"#\" * 25)\n",
    "        print()\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3ab394",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T23:03:55.112384Z",
     "iopub.status.busy": "2024-03-13T23:03:55.111350Z",
     "iopub.status.idle": "2024-03-13T23:03:55.376983Z",
     "shell.execute_reply": "2024-03-13T23:03:55.375371Z"
    },
    "papermill": {
     "duration": 0.32494,
     "end_time": "2024-03-13T23:03:55.380921",
     "exception": false,
     "start_time": "2024-03-13T23:03:55.055981",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# CREATE ALL EEG SPECTROGRAMS\n",
    "DISPLAY = 0\n",
    "EEG_IDS2 = test.eeg_id.unique()\n",
    "all_eegs2 = {}\n",
    "\n",
    "print(\"Converting Test EEG to Spectrograms...\")\n",
    "print()\n",
    "for i, eeg_id in enumerate(EEG_IDS2):\n",
    "\n",
    "    # CREATE SPECTROGRAM FROM EEG PARQUET\n",
    "    all_eegs2[eeg_id] = spectrogram_from_eeg(\n",
    "        f\"{config.data_eeg_test}{eeg_id}.parquet\", False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6492b6b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T23:03:55.556839Z",
     "iopub.status.busy": "2024-03-13T23:03:55.555879Z",
     "iopub.status.idle": "2024-03-13T23:03:55.623782Z",
     "shell.execute_reply": "2024-03-13T23:03:55.622742Z"
    },
    "papermill": {
     "duration": 0.130081,
     "end_time": "2024-03-13T23:03:55.626349",
     "exception": false,
     "start_time": "2024-03-13T23:03:55.496268",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# FEATURE NAMES\n",
    "SPEC_COLS = pd.read_parquet(f\"{config.data_spectograms}1000086677.parquet\").columns[1:]\n",
    "FEATURES = [f\"{c}_mean_10m\" for c in SPEC_COLS]\n",
    "FEATURES += [f\"{c}_min_10m\" for c in SPEC_COLS]\n",
    "FEATURES += [f\"{c}_mean_20s\" for c in SPEC_COLS]\n",
    "FEATURES += [f\"{c}_min_20s\" for c in SPEC_COLS]\n",
    "FEATURES += [f\"eeg_mean_f{x}_10s\" for x in range(512)]\n",
    "FEATURES += [f\"eeg_min_f{x}_10s\" for x in range(512)]\n",
    "FEATURES += [f\"eeg_max_f{x}_10s\" for x in range(512)]\n",
    "FEATURES += [f\"eeg_std_f{x}_10s\" for x in range(512)]\n",
    "print(f\"We are creating {len(FEATURES)} features for {len(train)} rows... \", end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca3f3c7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T23:03:55.735662Z",
     "iopub.status.busy": "2024-03-13T23:03:55.734870Z",
     "iopub.status.idle": "2024-03-13T23:03:55.740302Z",
     "shell.execute_reply": "2024-03-13T23:03:55.739387Z"
    },
    "papermill": {
     "duration": 0.062779,
     "end_time": "2024-03-13T23:03:55.742496",
     "exception": false,
     "start_time": "2024-03-13T23:03:55.679717",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Continue with renaming for DataLoader\n",
    "test = test.rename({\"spectrogram_id\": \"spec_id\"}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8cc17e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T23:03:55.848322Z",
     "iopub.status.busy": "2024-03-13T23:03:55.847912Z",
     "iopub.status.idle": "2024-03-13T23:03:59.379766Z",
     "shell.execute_reply": "2024-03-13T23:03:59.378670Z"
    },
    "papermill": {
     "duration": 3.587392,
     "end_time": "2024-03-13T23:03:59.382032",
     "exception": false,
     "start_time": "2024-03-13T23:03:55.794640",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# FEATURE ENGINEER TEST\n",
    "data = np.zeros((len(test), len(FEATURES)))\n",
    "\n",
    "for k in range(len(test)):\n",
    "    row = test.iloc[k]\n",
    "    s = int(row.spec_id)\n",
    "    spec = pd.read_parquet(f\"{config.data_spectograms_test}{s}.parquet\")\n",
    "\n",
    "    # 10 MINUTE WINDOW FEATURES\n",
    "    x = np.nanmean(spec.iloc[:, 1:].values, axis=0)\n",
    "    data[k, :400] = x\n",
    "    x = np.nanmin(spec.iloc[:, 1:].values, axis=0)\n",
    "    data[k, 400:800] = x\n",
    "\n",
    "    # 20 SECOND WINDOW FEATURES\n",
    "    x = np.nanmean(spec.iloc[145:155, 1:].values, axis=0)\n",
    "    data[k, 800:1200] = x\n",
    "    x = np.nanmin(spec.iloc[145:155, 1:].values, axis=0)\n",
    "    data[k, 1200:1600] = x\n",
    "\n",
    "    # RESHAPE EEG SPECTROGRAMS 128x256x4 => 512x256\n",
    "    eeg_spec = np.zeros((512, 256), dtype=\"float32\")\n",
    "    xx = all_eegs2[row.eeg_id]\n",
    "    for j in range(4):\n",
    "        eeg_spec[128 * j : 128 * (j + 1),] = xx[:, :, j]\n",
    "\n",
    "    # 10 SECOND WINDOW FROM EEG SPECTROGRAMS\n",
    "    x = np.nanmean(eeg_spec.T[100:-100, :], axis=0)\n",
    "    data[k, 1600:2112] = x\n",
    "    x = np.nanmin(eeg_spec.T[100:-100, :], axis=0)\n",
    "    data[k, 2112:2624] = x\n",
    "    x = np.nanmax(eeg_spec.T[100:-100, :], axis=0)\n",
    "    data[k, 2624:3136] = x\n",
    "    x = np.nanstd(eeg_spec.T[100:-100, :], axis=0)\n",
    "    data[k, 3136:3648] = x\n",
    "\n",
    "test[FEATURES] = data\n",
    "print(\"New test shape\", test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8146e85",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T23:03:59.493758Z",
     "iopub.status.busy": "2024-03-13T23:03:59.493342Z",
     "iopub.status.idle": "2024-03-13T23:04:00.303759Z",
     "shell.execute_reply": "2024-03-13T23:04:00.302771Z"
    },
    "papermill": {
     "duration": 0.86974,
     "end_time": "2024-03-13T23:04:00.306283",
     "exception": false,
     "start_time": "2024-03-13T23:03:59.436543",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import catboost as cat\n",
    "from catboost import CatBoostClassifier, Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1c6146",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T23:04:00.412132Z",
     "iopub.status.busy": "2024-03-13T23:04:00.411689Z",
     "iopub.status.idle": "2024-03-13T23:04:02.831257Z",
     "shell.execute_reply": "2024-03-13T23:04:02.830071Z"
    },
    "papermill": {
     "duration": 2.476903,
     "end_time": "2024-03-13T23:04:02.833586",
     "exception": false,
     "start_time": "2024-03-13T23:04:00.356683",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# INFER CATBOOST ON TEST\n",
    "preds = []\n",
    "\n",
    "for i in range(5):\n",
    "    print(i, \", \", end=\"\")\n",
    "    model = CatBoostClassifier(task_type=\"GPU\")\n",
    "    model.load_model(\n",
    "        f\"{config.full_path}catboost-model/catboost_model/CAT_v{VER}_f{i}.cat\"\n",
    "    )\n",
    "\n",
    "    test_pool = Pool(data=test[FEATURES])\n",
    "\n",
    "    pred = model.predict_proba(test_pool)\n",
    "    preds.append(pred)\n",
    "pred_model6 = np.mean(preds, axis=0)\n",
    "print()\n",
    "print(\"Test preds shape\", pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c810d4dd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T23:04:02.941326Z",
     "iopub.status.busy": "2024-03-13T23:04:02.940918Z",
     "iopub.status.idle": "2024-03-13T23:04:03.398724Z",
     "shell.execute_reply": "2024-03-13T23:04:03.397639Z"
    },
    "papermill": {
     "duration": 0.514436,
     "end_time": "2024-03-13T23:04:03.400916",
     "exception": false,
     "start_time": "2024-03-13T23:04:02.886480",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# FREE MEMORY\n",
    "del data\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4318b6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T23:04:03.512936Z",
     "iopub.status.busy": "2024-03-13T23:04:03.512225Z",
     "iopub.status.idle": "2024-03-13T23:04:03.533735Z",
     "shell.execute_reply": "2024-03-13T23:04:03.532712Z"
    },
    "papermill": {
     "duration": 0.079675,
     "end_time": "2024-03-13T23:04:03.536087",
     "exception": false,
     "start_time": "2024-03-13T23:04:03.456412",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sub6 = pd.DataFrame({\"eeg_id\": test.eeg_id.values})\n",
    "sub6[TARGETS] = pred_model6\n",
    "sub6.to_csv(\"submission.csv\", index=False)\n",
    "print(\"Submissionn shape\", sub6.shape)\n",
    "sub6.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb75a33",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T23:04:03.654111Z",
     "iopub.status.busy": "2024-03-13T23:04:03.653293Z",
     "iopub.status.idle": "2024-03-13T23:04:03.663093Z",
     "shell.execute_reply": "2024-03-13T23:04:03.662059Z"
    },
    "papermill": {
     "duration": 0.069176,
     "end_time": "2024-03-13T23:04:03.665422",
     "exception": false,
     "start_time": "2024-03-13T23:04:03.596246",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# SANITY CHECK TO CONFIRM PREDICTIONS SUM TO ONE\n",
    "sub6.iloc[:, -6:].sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994edef5",
   "metadata": {
    "papermill": {
     "duration": 0.052674,
     "end_time": "2024-03-13T23:04:03.771392",
     "exception": false,
     "start_time": "2024-03-13T23:04:03.718718",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c4fe17",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T23:04:03.880491Z",
     "iopub.status.busy": "2024-03-13T23:04:03.879665Z",
     "iopub.status.idle": "2024-03-13T23:04:05.076381Z",
     "shell.execute_reply": "2024-03-13T23:04:05.074863Z"
    },
    "papermill": {
     "duration": 1.254658,
     "end_time": "2024-03-13T23:04:05.078857",
     "exception": false,
     "start_time": "2024-03-13T23:04:03.824199",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import sys\n",
    "import math\n",
    "import time\n",
    "import random\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Union\n",
    "from scipy.signal import butter, lfilter, freqz\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam, SGD, AdamW\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "sys.path.append(f\"{config.full_path}/kaggle-kl-div\")\n",
    "from kaggle_kl_div import score\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\"\n",
    "\n",
    "!cat /etc/os-release | grep -oP \"PRETTY_NAME=\\\"\\K([^\\\"]*)\"\n",
    "print(f\"BUILD_DATE={os.environ['BUILD_DATE']}, CONTAINER_NAME={os.environ['CONTAINER_NAME']}\")\n",
    "\n",
    "try:\n",
    "    print(\n",
    "        f\"PyTorch Version:{torch.__version__}, CUDA is available:{torch.cuda.is_available()}, Version CUDA:{torch.version.cuda}\"\n",
    "    )\n",
    "    print(\n",
    "        f\"Device Capability:{torch.cuda.get_device_capability()}, {torch.cuda.get_arch_list()}\"\n",
    "    )\n",
    "    print(\n",
    "        f\"CuDNN Enabled:{torch.backends.cudnn.enabled}, Version:{torch.backends.cudnn.version()}\"\n",
    "    )\n",
    "except Exception:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb71dac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T23:04:05.188803Z",
     "iopub.status.busy": "2024-03-13T23:04:05.188361Z",
     "iopub.status.idle": "2024-03-13T23:04:05.201056Z",
     "shell.execute_reply": "2024-03-13T23:04:05.200075Z"
    },
    "papermill": {
     "duration": 0.070404,
     "end_time": "2024-03-13T23:04:05.203291",
     "exception": false,
     "start_time": "2024-03-13T23:04:05.132887",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    VERSION = 75\n",
    "\n",
    "    model_name = \"resnet1d_gru\"\n",
    "\n",
    "    seed = 2024\n",
    "    batch_size = 32\n",
    "    num_workers = 0\n",
    "\n",
    "    fixed_kernel_size = 5\n",
    "    # kernels = [3, 5, 7, 9]\n",
    "    # linear_layer_features = 424\n",
    "    kernels = [3, 5, 7, 9, 11]\n",
    "    #linear_layer_features = 448  # Full Signal = 10_000\n",
    "    #linear_layer_features = 352  # Half Signal = 5_000\n",
    "    linear_layer_features = 304   # 1/5  Signal = 2_000\n",
    "\n",
    "    seq_length = 50  # Second's\n",
    "    sampling_rate = 200  # Hz\n",
    "    nsamples = seq_length * sampling_rate  #  \n",
    "    out_samples = nsamples // 5\n",
    "\n",
    "    # bandpass_filter = {\"low\": 0.5, \"high\": 20, \"order\": 2}\n",
    "    # rand_filter = {\"probab\": 0.1, \"low\": 10, \"high\": 20, \"band\": 1.0, \"order\": 2}\n",
    "    freq_channels = []  # [(8.0, 12.0)]; [(0.5, 4.5)]\n",
    "    filter_order = 2\n",
    "    random_close_zone = 0.0  # 0.2\n",
    "        \n",
    "    target_cols = [\n",
    "        \"seizure_vote\",\n",
    "        \"lpd_vote\",\n",
    "        \"gpd_vote\",\n",
    "        \"lrda_vote\",\n",
    "        \"grda_vote\",\n",
    "        \"other_vote\",\n",
    "    ]\n",
    "\n",
    "    # target_preds = [x + \"_pred\" for x in target_cols]\n",
    "    # label_to_num = {\"Seizure\": 0, \"LPD\": 1, \"GPD\": 2, \"LRDA\": 3, \"GRDA\": 4, \"Other\": 5}\n",
    "    # num_to_label = {v: k for k, v in label_to_num.items()}\n",
    "\n",
    "    map_features = [\n",
    "        (\"Fp1\", \"T3\"),\n",
    "        (\"T3\", \"O1\"),\n",
    "        (\"Fp1\", \"C3\"),\n",
    "        (\"C3\", \"O1\"),\n",
    "        (\"Fp2\", \"C4\"),\n",
    "        (\"C4\", \"O2\"),\n",
    "        (\"Fp2\", \"T4\"),\n",
    "        (\"T4\", \"O2\"),\n",
    "        #('Fz', 'Cz'), ('Cz', 'Pz'),        \n",
    "    ]\n",
    "\n",
    "    eeg_features = [\"Fp1\", \"T3\", \"C3\", \"O1\", \"Fp2\", \"C4\", \"T4\", \"O2\"]  # 'Fz', 'Cz', 'Pz']\n",
    "        # 'F3', 'P3', 'F7', 'T5', 'Fz', 'Cz', 'Pz', 'F4', 'P4', 'F8', 'T6', 'EKG']                    \n",
    "    feature_to_index = {x: y for x, y in zip(eeg_features, range(len(eeg_features)))}\n",
    "    simple_features = []  # 'Fz', 'Cz', 'Pz', 'EKG'\n",
    "\n",
    "    # eeg_features = [row for row in feature_to_index]\n",
    "    # eeg_feat_size = len(eeg_features)\n",
    "    \n",
    "    n_map_features = len(map_features)\n",
    "    in_channels = n_map_features + n_map_features * len(freq_channels) + len(simple_features)\n",
    "    target_size = len(target_cols)\n",
    "    \n",
    "    PATH = f\"{config.full_path}hms-harmful-brain-activity-classification/\"\n",
    "    test_eeg = f\"{config.full_path}hms-harmful-brain-activity-classification/test_eegs/\"\n",
    "    test_csv = f\"{config.full_path}hms-harmful-brain-activity-classification/test.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1cdf7b0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T23:04:05.315597Z",
     "iopub.status.busy": "2024-03-13T23:04:05.315219Z",
     "iopub.status.idle": "2024-03-13T23:04:05.320930Z",
     "shell.execute_reply": "2024-03-13T23:04:05.319954Z"
    },
    "papermill": {
     "duration": 0.064758,
     "end_time": "2024-03-13T23:04:05.323150",
     "exception": false,
     "start_time": "2024-03-13T23:04:05.258392",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "koef_1 = 1.0\n",
    "model_weights = [\n",
    "    {\n",
    "        'bandpass_filter':{'low':0.5, 'high':20, 'order':2}, \n",
    "        'file_data': \n",
    "        [\n",
    "            {'koef':koef_1, 'file_mask':f\"{config.full_path}hms-resnet1d-gru-weights-v102/pop_1_weight_oof/*_best.pth\"},\n",
    "            #{'koef':koef_1, 'file_mask':f\"{config.full_path}hms-resnet1d-gru-weights-v102/pop_2_weight_oof/*_best.pth\"},\n",
    "        ]\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e525d3b4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T23:04:05.431717Z",
     "iopub.status.busy": "2024-03-13T23:04:05.431322Z",
     "iopub.status.idle": "2024-03-13T23:04:05.448532Z",
     "shell.execute_reply": "2024-03-13T23:04:05.447516Z"
    },
    "papermill": {
     "duration": 0.074195,
     "end_time": "2024-03-13T23:04:05.450770",
     "exception": false,
     "start_time": "2024-03-13T23:04:05.376575",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def init_logger(log_file=\"./test.log\"):\n",
    "    from logging import getLogger, INFO, FileHandler, Formatter, StreamHandler\n",
    "\n",
    "    logger = getLogger(__name__)\n",
    "    logger.setLevel(INFO)\n",
    "    handler1 = StreamHandler()\n",
    "    handler1.setFormatter(Formatter(\"%(message)s\"))\n",
    "    handler2 = FileHandler(filename=log_file)\n",
    "    handler2.setFormatter(Formatter(\"%(message)s\"))\n",
    "    logger.addHandler(handler1)\n",
    "    logger.addHandler(handler2)\n",
    "    return logger\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return \"%dm %ds\" % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return \"%s (remain %s)\" % (asMinutes(s), asMinutes(rs))\n",
    "\n",
    "\n",
    "def quantize_data(data, classes):\n",
    "    mu_x = mu_law_encoding(data, classes)\n",
    "    return mu_x  # quantized\n",
    "\n",
    "\n",
    "def mu_law_encoding(data, mu):\n",
    "    mu_x = np.sign(data) * np.log(1 + mu * np.abs(data)) / np.log(mu + 1)\n",
    "    return mu_x\n",
    "\n",
    "\n",
    "def mu_law_expansion(data, mu):\n",
    "    s = np.sign(data) * (np.exp(np.abs(data) * np.log(mu + 1)) - 1) / mu\n",
    "    return s\n",
    "\n",
    "\n",
    "def butter_bandpass(lowcut, highcut, fs, order=5):\n",
    "    return butter(order, [lowcut, highcut], fs=fs, btype=\"band\")\n",
    "\n",
    "\n",
    "def butter_bandpass_filter(data, lowcut, highcut, fs, order=5):\n",
    "    b, a = butter_bandpass(lowcut, highcut, fs, order=order)\n",
    "    y = lfilter(b, a, data)\n",
    "    return y\n",
    "\n",
    "\n",
    "def butter_lowpass_filter(\n",
    "    data, cutoff_freq=20, sampling_rate=CFG.sampling_rate, order=4\n",
    "):\n",
    "    nyquist = 0.5 * sampling_rate\n",
    "    normal_cutoff = cutoff_freq / nyquist\n",
    "    b, a = butter(order, normal_cutoff, btype=\"low\", analog=False)\n",
    "    filtered_data = lfilter(b, a, data, axis=0)\n",
    "    return filtered_data\n",
    "\n",
    "\n",
    "def denoise_filter(x):\n",
    "    #       ( ).\n",
    "    #   \n",
    "    y = butter_bandpass_filter(x, CFG.lowcut, CFG.highcut, CFG.sampling_rate, order=6)\n",
    "    y = (y + np.roll(y, -1) + np.roll(y, -2) + np.roll(y, -3)) / 4\n",
    "    y = y[0:-1:4]\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c03da7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T23:04:05.563736Z",
     "iopub.status.busy": "2024-03-13T23:04:05.563256Z",
     "iopub.status.idle": "2024-03-13T23:04:05.577396Z",
     "shell.execute_reply": "2024-03-13T23:04:05.576208Z"
    },
    "papermill": {
     "duration": 0.072744,
     "end_time": "2024-03-13T23:04:05.579565",
     "exception": false,
     "start_time": "2024-03-13T23:04:05.506821",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def eeg_from_parquet(\n",
    "    parquet_path: str, display: bool = False, seq_length=CFG.seq_length\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "            50  .     NaN\n",
    "       ( NaN).\n",
    "        :param parquet_path:    .\n",
    "        :param display:     .\n",
    "        :return data: np.array  (time_steps, eeg_features) -> (10_000, 8)\n",
    "    \"\"\"\n",
    "\n",
    "    #   50  \n",
    "    eeg = pd.read_parquet(parquet_path, columns=CFG.eeg_features)\n",
    "    rows = len(eeg)\n",
    "\n",
    "    #   ,   \n",
    "    offset = (rows - CFG.nsamples) // 2\n",
    "\n",
    "    #  50 ,       \n",
    "    eeg = eeg.iloc[offset : offset + CFG.nsamples]\n",
    "\n",
    "    if display:\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        offset = 0\n",
    "\n",
    "    #   numpy\n",
    "\n",
    "    #       \n",
    "    data = np.zeros((CFG.nsamples, len(CFG.eeg_features)))\n",
    "\n",
    "    for index, feature in enumerate(CFG.eeg_features):\n",
    "        x = eeg[feature].values.astype(\"float32\")  #   float32\n",
    "\n",
    "        #      ,  NaN.\n",
    "        mean = np.nanmean(x)\n",
    "        nan_percentage = np.isnan(x).mean()  # percentage of NaN values in feature\n",
    "\n",
    "        #   Nan\n",
    "        #    NaN       .\n",
    "        if nan_percentage < 1:  #     Nan,   \n",
    "            x = np.nan_to_num(x, nan=mean)\n",
    "        else:  #     Nan\n",
    "            x[:] = 0\n",
    "        data[:, index] = x\n",
    "\n",
    "        if display:\n",
    "            if index != 0:\n",
    "                offset += x.max()\n",
    "            plt.plot(range(CFG.nsamples), x - offset, label=feature)\n",
    "            offset -= x.min()\n",
    "\n",
    "    if display:\n",
    "        plt.legend()\n",
    "        name = parquet_path.split(\"/\")[-1].split(\".\")[0]\n",
    "        plt.yticks([])\n",
    "        plt.title(f\"EEG {name}\", size=16)\n",
    "        plt.show()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc993971",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T23:04:05.689503Z",
     "iopub.status.busy": "2024-03-13T23:04:05.688597Z",
     "iopub.status.idle": "2024-03-13T23:04:05.716968Z",
     "shell.execute_reply": "2024-03-13T23:04:05.716076Z"
    },
    "papermill": {
     "duration": 0.084779,
     "end_time": "2024-03-13T23:04:05.719258",
     "exception": false,
     "start_time": "2024-03-13T23:04:05.634479",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class EEGDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        df: pd.DataFrame,\n",
    "        batch_size: int,\n",
    "        eegs: Dict[int, np.ndarray],\n",
    "        mode: str = \"train\",\n",
    "        downsample: int = None,\n",
    "        bandpass_filter: Dict[str, Union[int, float]] = None,\n",
    "        rand_filter: Dict[str, Union[int, float]] = None,\n",
    "    ):\n",
    "        self.df = df\n",
    "        self.batch_size = batch_size\n",
    "        self.mode = mode\n",
    "        self.eegs = eegs\n",
    "        self.downsample = downsample\n",
    "        self.bandpass_filter = bandpass_filter\n",
    "        self.rand_filter = rand_filter\n",
    "        \n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Length of dataset.\n",
    "        \"\"\"\n",
    "        #     \n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Get one item.\n",
    "        \"\"\"\n",
    "        #    \n",
    "        X, y_prob = self.__data_generation(index)\n",
    "        if self.downsample is not None:\n",
    "            X = X[:: self.downsample, :]\n",
    "        output = {\n",
    "            \"eeg\": torch.tensor(X, dtype=torch.float32),\n",
    "            \"labels\": torch.tensor(y_prob, dtype=torch.float32),\n",
    "        }\n",
    "        return output\n",
    "\n",
    "    def __data_generation(self, index):\n",
    "        #  ,    \n",
    "        X = np.zeros(\n",
    "            (CFG.out_samples, CFG.in_channels), dtype=\"float32\"\n",
    "        )  # Size=(10000, 14)\n",
    "\n",
    "        row = self.df.iloc[index]  #  Pandas\n",
    "        data = self.eegs[row.eeg_id]  # Size=(10000, 8)\n",
    "        if CFG.nsamples != CFG.out_samples:\n",
    "            if self.mode != \"train\":\n",
    "                offset = (CFG.nsamples - CFG.out_samples) // 2\n",
    "            else:\n",
    "                #offset = random.randint(0, CFG.nsamples - CFG.out_samples)                \n",
    "                offset = ((CFG.nsamples - CFG.out_samples) * random.randint(0, 1000)) // 1000\n",
    "            data = data[offset:offset+CFG.out_samples,:]\n",
    "\n",
    "        for i, (feat_a, feat_b) in enumerate(CFG.map_features):\n",
    "            if self.mode == \"train\" and CFG.random_close_zone > 0 and random.uniform(0.0, 1.0) <= CFG.random_close_zone:\n",
    "                continue\n",
    "                \n",
    "            diff_feat = (\n",
    "                data[:, CFG.feature_to_index[feat_a]]\n",
    "                - data[:, CFG.feature_to_index[feat_b]]\n",
    "            )  # Size=(10000,)\n",
    "\n",
    "            if not self.bandpass_filter is None:\n",
    "                diff_feat = butter_bandpass_filter(\n",
    "                    diff_feat,\n",
    "                    self.bandpass_filter[\"low\"],\n",
    "                    self.bandpass_filter[\"high\"],\n",
    "                    CFG.sampling_rate,\n",
    "                    order=self.bandpass_filter[\"order\"],\n",
    "                )\n",
    "                    \n",
    "            if (\n",
    "                self.mode == \"train\"\n",
    "                and not self.rand_filter is None\n",
    "                and random.uniform(0.0, 1.0) <= self.rand_filter[\"probab\"]\n",
    "            ):\n",
    "                lowcut = random.randint(\n",
    "                    self.rand_filter[\"low\"], self.rand_filter[\"high\"]\n",
    "                )\n",
    "                highcut = lowcut + self.rand_filter[\"band\"]\n",
    "                diff_feat = butter_bandpass_filter(\n",
    "                    diff_feat,\n",
    "                    lowcut,\n",
    "                    highcut,\n",
    "                    CFG.sampling_rate,\n",
    "                    order=self.rand_filter[\"order\"],\n",
    "                )\n",
    "\n",
    "            X[:, i] = diff_feat\n",
    "\n",
    "        n = CFG.n_map_features\n",
    "        if len(CFG.freq_channels) > 0:\n",
    "            for i in range(CFG.n_map_features):\n",
    "                diff_feat = X[:, i]\n",
    "                for j, (lowcut, highcut) in enumerate(CFG.freq_channels):\n",
    "                    band_feat = butter_bandpass_filter(\n",
    "                        diff_feat, lowcut, highcut, CFG.sampling_rate, order=CFG.filter_order,  # 6\n",
    "                    )\n",
    "                    X[:, n] = band_feat\n",
    "                    n += 1\n",
    "\n",
    "        for spml_feat in CFG.simple_features:\n",
    "            feat_val = data[:, CFG.feature_to_index[spml_feat]]\n",
    "            \n",
    "            if not self.bandpass_filter is None:\n",
    "                feat_val = butter_bandpass_filter(\n",
    "                    feat_val,\n",
    "                    self.bandpass_filter[\"low\"],\n",
    "                    self.bandpass_filter[\"high\"],\n",
    "                    CFG.sampling_rate,\n",
    "                    order=self.bandpass_filter[\"order\"],\n",
    "                )\n",
    "\n",
    "            if (\n",
    "                self.mode == \"train\"\n",
    "                and not self.rand_filter is None\n",
    "                and random.uniform(0.0, 1.0) <= self.rand_filter[\"probab\"]\n",
    "            ):\n",
    "                lowcut = random.randint(\n",
    "                    self.rand_filter[\"low\"], self.rand_filter[\"high\"]\n",
    "                )\n",
    "                highcut = lowcut + self.rand_filter[\"band\"]\n",
    "                feat_val = butter_bandpass_filter(\n",
    "                    feat_val,\n",
    "                    lowcut,\n",
    "                    highcut,\n",
    "                    CFG.sampling_rate,\n",
    "                    order=self.rand_filter[\"order\"],\n",
    "                )\n",
    "\n",
    "            X[:, n] = feat_val\n",
    "            n += 1\n",
    "            \n",
    "        #     [-1024, 1024]\n",
    "        X = np.clip(X, -1024, 1024)\n",
    "\n",
    "        #  NaN      32\n",
    "        X = np.nan_to_num(X, nan=0) / 32.0\n",
    "\n",
    "        #       20 Hz.\n",
    "        X = butter_lowpass_filter(X, order=CFG.filter_order)  # 4\n",
    "\n",
    "        y_prob = np.zeros(CFG.target_size, dtype=\"float32\")  # Size=(6,)\n",
    "        if self.mode != \"test\":\n",
    "            y_prob = row[CFG.target_cols].values.astype(np.float32)\n",
    "\n",
    "        return X, y_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869a8038",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T23:04:05.827814Z",
     "iopub.status.busy": "2024-03-13T23:04:05.827100Z",
     "iopub.status.idle": "2024-03-13T23:04:05.856481Z",
     "shell.execute_reply": "2024-03-13T23:04:05.855514Z"
    },
    "papermill": {
     "duration": 0.086825,
     "end_time": "2024-03-13T23:04:05.858620",
     "exception": false,
     "start_time": "2024-03-13T23:04:05.771795",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ResNet_1D_Block(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels,\n",
    "        out_channels,\n",
    "        kernel_size,\n",
    "        stride,\n",
    "        padding,\n",
    "        downsampling,\n",
    "        dilation=1,\n",
    "        groups=1,\n",
    "        dropout=0.0,\n",
    "    ):\n",
    "        super(ResNet_1D_Block, self).__init__()\n",
    "\n",
    "        self.bn1 = nn.BatchNorm1d(num_features=in_channels)\n",
    "        # self.relu = nn.ReLU(inplace=False)\n",
    "        # self.relu_1 = nn.PReLU()\n",
    "        # self.relu_2 = nn.PReLU()\n",
    "        self.relu_1 = nn.Hardswish()\n",
    "        self.relu_2 = nn.Hardswish()\n",
    "\n",
    "        self.dropout = nn.Dropout(p=dropout, inplace=False)\n",
    "        self.conv1 = nn.Conv1d(\n",
    "            in_channels=in_channels,\n",
    "            out_channels=out_channels,\n",
    "            kernel_size=kernel_size,\n",
    "            stride=stride,\n",
    "            padding=padding,\n",
    "            dilation=dilation,\n",
    "            groups=groups,\n",
    "            bias=False,\n",
    "        )\n",
    "\n",
    "        self.bn2 = nn.BatchNorm1d(num_features=out_channels)\n",
    "        self.conv2 = nn.Conv1d(\n",
    "            in_channels=out_channels,\n",
    "            out_channels=out_channels,\n",
    "            kernel_size=kernel_size,\n",
    "            stride=stride,\n",
    "            padding=padding,\n",
    "            dilation=dilation,\n",
    "            groups=groups,\n",
    "            bias=False,\n",
    "        )\n",
    "\n",
    "        self.maxpool = nn.MaxPool1d(\n",
    "            kernel_size=2,\n",
    "            stride=2,\n",
    "            padding=0,\n",
    "            dilation=dilation,\n",
    "        )\n",
    "        self.downsampling = downsampling\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.bn1(x)\n",
    "        out = self.relu_1(out)\n",
    "        out = self.dropout(out)\n",
    "        out = self.conv1(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu_2(out)\n",
    "        out = self.dropout(out)\n",
    "        out = self.conv2(out)\n",
    "\n",
    "        out = self.maxpool(out)\n",
    "        identity = self.downsampling(x)\n",
    "\n",
    "        out += identity\n",
    "        return out\n",
    "\n",
    "\n",
    "class EEGNet(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        kernels,\n",
    "        in_channels,\n",
    "        fixed_kernel_size,\n",
    "        num_classes,\n",
    "        linear_layer_features,\n",
    "        dilation=1,\n",
    "        groups=1,\n",
    "    ):\n",
    "        super(EEGNet, self).__init__()\n",
    "        self.kernels = kernels\n",
    "        self.planes = 24\n",
    "        self.parallel_conv = nn.ModuleList()\n",
    "        self.in_channels = in_channels\n",
    "\n",
    "        for i, kernel_size in enumerate(list(self.kernels)):\n",
    "            sep_conv = nn.Conv1d(\n",
    "                in_channels=in_channels,\n",
    "                out_channels=self.planes,\n",
    "                kernel_size=(kernel_size),\n",
    "                stride=1,\n",
    "                padding=0,\n",
    "                dilation=dilation,\n",
    "                groups=groups,\n",
    "                bias=False,\n",
    "            )\n",
    "            self.parallel_conv.append(sep_conv)\n",
    "\n",
    "        self.bn1 = nn.BatchNorm1d(num_features=self.planes)\n",
    "        # self.relu = nn.ReLU(inplace=False)\n",
    "        # self.relu_1 = nn.ReLU()\n",
    "        # self.relu_2 = nn.ReLU()\n",
    "        self.relu_1 = nn.SiLU()\n",
    "        self.relu_2 = nn.SiLU()\n",
    "\n",
    "        self.conv1 = nn.Conv1d(\n",
    "            in_channels=self.planes,\n",
    "            out_channels=self.planes,\n",
    "            kernel_size=fixed_kernel_size,\n",
    "            stride=2,\n",
    "            padding=2,\n",
    "            dilation=dilation,\n",
    "            groups=groups,\n",
    "            bias=False,\n",
    "        )\n",
    "\n",
    "        self.block = self._make_resnet_layer(\n",
    "            kernel_size=fixed_kernel_size,\n",
    "            stride=1,\n",
    "            dilation=dilation,\n",
    "            groups=groups,\n",
    "            padding=fixed_kernel_size // 2,\n",
    "        )\n",
    "        self.bn2 = nn.BatchNorm1d(num_features=self.planes)\n",
    "        self.avgpool = nn.AvgPool1d(kernel_size=6, stride=6, padding=2)\n",
    "\n",
    "        self.rnn = nn.GRU(\n",
    "            input_size=self.in_channels,\n",
    "            hidden_size=128,\n",
    "            num_layers=1,\n",
    "            bidirectional=True,\n",
    "            # dropout=0.2,\n",
    "        )\n",
    "\n",
    "        self.fc = nn.Linear(in_features=linear_layer_features, out_features=num_classes)\n",
    "\n",
    "    def _make_resnet_layer(\n",
    "        self,\n",
    "        kernel_size,\n",
    "        stride,\n",
    "        dilation=1,\n",
    "        groups=1,\n",
    "        blocks=9,\n",
    "        padding=0,\n",
    "        dropout=0.0,\n",
    "    ):\n",
    "        layers = []\n",
    "        downsample = None\n",
    "        base_width = self.planes\n",
    "\n",
    "        for i in range(blocks):\n",
    "            downsampling = nn.Sequential(\n",
    "                nn.MaxPool1d(kernel_size=2, stride=2, padding=0)\n",
    "            )\n",
    "            layers.append(\n",
    "                ResNet_1D_Block(\n",
    "                    in_channels=self.planes,\n",
    "                    out_channels=self.planes,\n",
    "                    kernel_size=kernel_size,\n",
    "                    stride=stride,\n",
    "                    padding=padding,\n",
    "                    downsampling=downsampling,\n",
    "                    dilation=dilation,\n",
    "                    groups=groups,\n",
    "                    dropout=dropout,\n",
    "                )\n",
    "            )\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def extract_features(self, x):\n",
    "        x = x.permute(0, 2, 1)\n",
    "        out_sep = []\n",
    "\n",
    "        for i in range(len(self.kernels)):\n",
    "            sep = self.parallel_conv[i](x)\n",
    "            out_sep.append(sep)\n",
    "\n",
    "        out = torch.cat(out_sep, dim=2)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu_1(out)\n",
    "        out = self.conv1(out)\n",
    "\n",
    "        out = self.block(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu_2(out)\n",
    "        out = self.avgpool(out)\n",
    "\n",
    "        out = out.reshape(out.shape[0], -1)\n",
    "        rnn_out, _ = self.rnn(x.permute(0, 2, 1))\n",
    "        new_rnn_h = rnn_out[:, -1, :]  # <~~\n",
    "\n",
    "        new_out = torch.cat([out, new_rnn_h], dim=1)\n",
    "        return new_out\n",
    "\n",
    "    def forward(self, x):\n",
    "        new_out = self.extract_features(x)\n",
    "        result = self.fc(new_out)\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18383dda",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T23:04:05.969373Z",
     "iopub.status.busy": "2024-03-13T23:04:05.968473Z",
     "iopub.status.idle": "2024-03-13T23:04:05.976931Z",
     "shell.execute_reply": "2024-03-13T23:04:05.975780Z"
    },
    "papermill": {
     "duration": 0.066027,
     "end_time": "2024-03-13T23:04:05.979256",
     "exception": false,
     "start_time": "2024-03-13T23:04:05.913229",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def inference_function(test_loader, model, device):\n",
    "    model.eval()  # set model in evaluation mode\n",
    "    softmax = nn.Softmax(dim=1)\n",
    "    prediction_dict = {}\n",
    "    preds = []\n",
    "    with tqdm(test_loader, unit=\"test_batch\", desc=\"Inference\") as tqdm_test_loader:\n",
    "        for step, batch in enumerate(tqdm_test_loader):\n",
    "            X = batch.pop(\"eeg\").to(device)  # send inputs to `device`\n",
    "            batch_size = X.size(0)\n",
    "            with torch.no_grad():\n",
    "                y_preds = model(X)  # forward propagation pass\n",
    "            y_preds = softmax(y_preds)\n",
    "            preds.append(y_preds.to(\"cpu\").numpy())  # save pred_model7\n",
    "\n",
    "    prediction_dict[\"pred_model7\"] = np.concatenate(\n",
    "        preds\n",
    "    )  # np.array() of shape (fold_size, target_cols)\n",
    "    return prediction_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9dab7e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T23:04:06.095850Z",
     "iopub.status.busy": "2024-03-13T23:04:06.095431Z",
     "iopub.status.idle": "2024-03-13T23:04:06.111933Z",
     "shell.execute_reply": "2024-03-13T23:04:06.110735Z"
    },
    "papermill": {
     "duration": 0.076323,
     "end_time": "2024-03-13T23:04:06.114253",
     "exception": false,
     "start_time": "2024-03-13T23:04:06.037930",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(CFG.test_csv)\n",
    "print(f\"Test dataframe shape is: {test_df.shape}\")\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ebfa6d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T23:04:06.230745Z",
     "iopub.status.busy": "2024-03-13T23:04:06.229745Z",
     "iopub.status.idle": "2024-03-13T23:04:09.590402Z",
     "shell.execute_reply": "2024-03-13T23:04:09.589393Z"
    },
    "papermill": {
     "duration": 3.421617,
     "end_time": "2024-03-13T23:04:09.592728",
     "exception": false,
     "start_time": "2024-03-13T23:04:06.171111",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "koef_sum = 0\n",
    "koef_count = 0\n",
    "pred_model7 = []\n",
    "files = []\n",
    "    \n",
    "for model_block in model_weights:\n",
    "    test_dataset = EEGDataset(\n",
    "        df=test_df,\n",
    "        batch_size=CFG.batch_size,\n",
    "        mode=\"test\",\n",
    "        eegs=all_eegs,\n",
    "        bandpass_filter=model_block['bandpass_filter']\n",
    "    )\n",
    "\n",
    "    if len(pred_model7) == 0:\n",
    "        output = test_dataset[0]\n",
    "        X = output[\"eeg\"]\n",
    "        print(f\"X shape: {X.shape}\")\n",
    "                \n",
    "    test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=CFG.batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=CFG.num_workers,\n",
    "        pin_memory=True,\n",
    "        drop_last=False,\n",
    "    )\n",
    "\n",
    "    model = EEGNet(\n",
    "        kernels=CFG.kernels,\n",
    "        in_channels=CFG.in_channels,\n",
    "        fixed_kernel_size=CFG.fixed_kernel_size,\n",
    "        num_classes=CFG.target_size,\n",
    "        linear_layer_features=CFG.linear_layer_features,\n",
    "    )\n",
    "\n",
    "    for file_line in model_block['file_data']:\n",
    "        koef = file_line['koef']\n",
    "        for weight_model_file in glob(file_line['file_mask']):\n",
    "            files.append(weight_model_file)\n",
    "            checkpoint = torch.load(weight_model_file, map_location=device)\n",
    "            model.load_state_dict(checkpoint[\"model\"])\n",
    "            model.to(device)\n",
    "            prediction_dict = inference_function(test_loader, model, device)\n",
    "            predict = prediction_dict[\"pred_model7\"]\n",
    "            predict *= koef\n",
    "            koef_sum += koef\n",
    "            koef_count += 1\n",
    "            pred_model7.append(predict)\n",
    "            torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "\n",
    "pred_model7 = np.array(pred_model7)\n",
    "koef_sum /= koef_count\n",
    "pred_model7 /= koef_sum\n",
    "pred_model7 = np.mean(pred_model7, axis=0)\n",
    "pred_model7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60391408",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T23:04:09.709970Z",
     "iopub.status.busy": "2024-03-13T23:04:09.709201Z",
     "iopub.status.idle": "2024-03-13T23:04:10.214889Z",
     "shell.execute_reply": "2024-03-13T23:04:10.213814Z"
    },
    "papermill": {
     "duration": 0.5634,
     "end_time": "2024-03-13T23:04:10.217113",
     "exception": false,
     "start_time": "2024-03-13T23:04:09.653713",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_eeg_parquet_paths = glob(CFG.test_eeg + \"*.parquet\")\n",
    "test_eeg_df = pd.read_parquet(test_eeg_parquet_paths[0])\n",
    "test_eeg_features = test_eeg_df.columns\n",
    "print(f\"There are {len(test_eeg_features)} raw eeg features\")\n",
    "print(list(test_eeg_features))\n",
    "del test_eeg_df\n",
    "_ = gc.collect()\n",
    "\n",
    "# %%time\n",
    "all_eegs = {}\n",
    "eeg_ids = test_df.eeg_id.unique()\n",
    "for i, eeg_id in tqdm(enumerate(eeg_ids)):\n",
    "    # Save EEG to Python dictionary of numpy arrays\n",
    "    eeg_path = CFG.test_eeg + str(eeg_id) + \".parquet\"\n",
    "    data = eeg_from_parquet(eeg_path)\n",
    "    all_eegs[eeg_id] = data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce174a4",
   "metadata": {
    "papermill": {
     "duration": 0.052805,
     "end_time": "2024-03-13T23:04:10.327770",
     "exception": false,
     "start_time": "2024-03-13T23:04:10.274965",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4663e55b",
   "metadata": {
    "papermill": {
     "duration": 0.054991,
     "end_time": "2024-03-13T23:04:10.437669",
     "exception": false,
     "start_time": "2024-03-13T23:04:10.382678",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Manual for Tygo\n",
    "Submissions:\n",
    "1. His ensemble\n",
    "You need to first run his code, so we have nice score in LB.\n",
    "You can find the notebook here: https://www.kaggle.com/code/luppoduck/hms-blend-all-torch-publicmodel-simpleblend-lb-37/edit\n",
    "\n",
    "2. Our thing with ^8 and rounding with the weights he has for model 3\n",
    "The rouding and ^8 is already setup so now you just need to uncomment weights for Model 3 almost at the end.\n",
    "\n",
    "3. Our thing with ^8 and rounding with the weights he has for model 3, Without WaveNet and Catboost and Face+Head ensemble\n",
    "The rouding and ^8 is already setup and you uncomented his weights, so now you need to comment out model 4, 5 and 6 as he is not using them. You also need to comment them in the submission calculation here (the weights) otherwise it will crash.\n",
    "\n",
    "4. All 7 models with ^8 and rounding and his weights for model 3\n",
    "The rouding and ^8 is already setup and you uncomented his weights. So for this run uncomment the model 4, 5 and 6 and use all of them. And don't forget to uncomment the weights\n",
    "\n",
    "5. All 7 models with ^8 and rounding and our weights for model 3\n",
    "Now just uncomment everything and use our weights instead of his."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a503e67",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T23:04:10.549031Z",
     "iopub.status.busy": "2024-03-13T23:04:10.548197Z",
     "iopub.status.idle": "2024-03-13T23:04:10.556954Z",
     "shell.execute_reply": "2024-03-13T23:04:10.555910Z"
    },
    "papermill": {
     "duration": 0.067301,
     "end_time": "2024-03-13T23:04:10.559331",
     "exception": false,
     "start_time": "2024-03-13T23:04:10.492030",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Scores for each model, where lower is better\n",
    "scores = np.array([0.43, 0.45, 0.41, 0.34, 0.44, 0.60, 0.37])\n",
    "\n",
    "inverted_scores = 1 / scores\n",
    "transformed_scores = inverted_scores ** 8\n",
    "weights = transformed_scores / transformed_scores.sum()\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc2e657",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T23:04:10.671975Z",
     "iopub.status.busy": "2024-03-13T23:04:10.671085Z",
     "iopub.status.idle": "2024-03-13T23:04:10.680207Z",
     "shell.execute_reply": "2024-03-13T23:04:10.679193Z"
    },
    "papermill": {
     "duration": 0.066569,
     "end_time": "2024-03-13T23:04:10.682217",
     "exception": false,
     "start_time": "2024-03-13T23:04:10.615648",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "use_computed_weights = True\n",
    "manual_weights = [0.05, 0.05, 0.25, 0.65, 0.00, 0.05, 0.00]\n",
    "labels = [\"seizure\", \"lpd\", \"gpd\", \"lrda\", \"grda\", \"other\"]\n",
    "submission = pd.read_csv(f\"{config.competition_data_path}/sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c717061c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T23:04:10.795237Z",
     "iopub.status.busy": "2024-03-13T23:04:10.793891Z",
     "iopub.status.idle": "2024-03-13T23:04:10.815498Z",
     "shell.execute_reply": "2024-03-13T23:04:10.814414Z"
    },
    "papermill": {
     "duration": 0.080585,
     "end_time": "2024-03-13T23:04:10.818123",
     "exception": false,
     "start_time": "2024-03-13T23:04:10.737538",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in range(len(labels)):\n",
    "    if use_computed_weights:\n",
    "        # Use the computed weights\n",
    "        submission[f\"{labels[i]}_vote\"] = (\n",
    "            pred_model1[:, i] * weights[0] +\n",
    "            pred_model2[:, i] * weights[1] +\n",
    "            pred_model3[:, i] * weights[2] +\n",
    "            pred_model4[:, i] * weights[3] +\n",
    "            pred_model5[:, i] * weights[4] +\n",
    "            pred_model6[:, i] * weights[5] +\n",
    "            pred_model7[:, i] * weights[6]\n",
    "        )\n",
    "    else:\n",
    "        # Use the manually set weights\n",
    "        submission[f\"{labels[i]}_vote\"] = (\n",
    "            pred_model1[:, i] * manual_weights[0] +\n",
    "            pred_model2[:, i] * manual_weights[1] +\n",
    "            pred_model3[:, i] * manual_weights[2] +\n",
    "            pred_model4[:, i] * manual_weights[3] +\n",
    "            pred_model5[:, i] * manual_weights[4] +\n",
    "            pred_model6[:, i] * manual_weights[5] +\n",
    "            pred_model7[:, i] * manual_weights[7]\n",
    "        )\n",
    "submission.to_csv(f\"{config.output_path}submission.csv\", index=None)\n",
    "display(submission.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa1a958",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T23:04:10.936705Z",
     "iopub.status.busy": "2024-03-13T23:04:10.936336Z",
     "iopub.status.idle": "2024-03-13T23:04:10.940771Z",
     "shell.execute_reply": "2024-03-13T23:04:10.939767Z"
    },
    "papermill": {
     "duration": 0.065422,
     "end_time": "2024-03-13T23:04:10.942869",
     "exception": false,
     "start_time": "2024-03-13T23:04:10.877447",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # SANITY CHECK TO CONFIRM PREDICTIONS SUM TO ONE\n",
    "# submission.iloc[:, -6:].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05bc1c02",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T23:04:11.064227Z",
     "iopub.status.busy": "2024-03-13T23:04:11.063484Z",
     "iopub.status.idle": "2024-03-13T23:04:11.068385Z",
     "shell.execute_reply": "2024-03-13T23:04:11.067363Z"
    },
    "papermill": {
     "duration": 0.068729,
     "end_time": "2024-03-13T23:04:11.070714",
     "exception": false,
     "start_time": "2024-03-13T23:04:11.001985",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# delete this code\n",
    "# tempz=pd.read_csv(config.output_path)\n",
    "\n",
    "# tempz.iloc[0, 1] = 0.098192\n",
    "# tempz.iloc[0, 2] = 0.058772\n",
    "# tempz.iloc[0, 3] = 0.000671\n",
    "# tempz.iloc[0, 4] = 0.395016\n",
    "# tempz.iloc[0, 5] = 0.023945\n",
    "# tempz.iloc[0, 6] = 0.423405\n",
    "\n",
    "# tempz.to_csv(\"/kaggle/working/submission.csv\", index=False)\n",
    "# display(tempz.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885b1c0a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T23:04:11.184910Z",
     "iopub.status.busy": "2024-03-13T23:04:11.184505Z",
     "iopub.status.idle": "2024-03-13T23:04:11.214102Z",
     "shell.execute_reply": "2024-03-13T23:04:11.213073Z"
    },
    "papermill": {
     "duration": 0.089609,
     "end_time": "2024-03-13T23:04:11.216321",
     "exception": false,
     "start_time": "2024-03-13T23:04:11.126712",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Read the CSV file\n",
    "finalrounding = pd.read_csv(f\"{config.output_path}submission.csv\")\n",
    "\n",
    "seizure_vote_value = finalrounding.iloc[0, 1]\n",
    "\n",
    "lpd_vote_value = finalrounding.iloc[0, 2]\n",
    "\n",
    "gpd_vote_value = finalrounding.iloc[0, 3]\n",
    "\n",
    "lrda_vote_value = finalrounding.iloc[0, 4]\n",
    "\n",
    "grda_vote_value = finalrounding.iloc[0, 5]\n",
    "\n",
    "other_vote_value = finalrounding.iloc[0, 6]\n",
    "\n",
    "buffer_value = 0.0\n",
    "\n",
    "if seizure_vote_value < 0.06:\n",
    "    buffer_value = buffer_value + seizure_vote_value\n",
    "    finalrounding.iloc[0, 1] = 0\n",
    "    seizure_vote_value = 0\n",
    "\n",
    "if lpd_vote_value < 0.06:\n",
    "    buffer_value = buffer_value + lpd_vote_value\n",
    "    finalrounding.iloc[0, 2] = 0\n",
    "    lpd_vote_value = 0\n",
    "\n",
    "if gpd_vote_value < 0.06:\n",
    "    buffer_value = buffer_value + gpd_vote_value\n",
    "    finalrounding.iloc[0, 3] = 0\n",
    "    gpd_vote_value = 0\n",
    "\n",
    "if lrda_vote_value < 0.06:\n",
    "    buffer_value = buffer_value + lrda_vote_value\n",
    "    finalrounding.iloc[0, 4] = 0\n",
    "    lrda_vote_value = 0\n",
    "\n",
    "if grda_vote_value < 0.06:\n",
    "    buffer_value = buffer_value + grda_vote_value\n",
    "    finalrounding.iloc[0, 5] = 0\n",
    "    grda_vote_value = 0\n",
    "\n",
    "if other_vote_value < 0.06:\n",
    "    buffer_value = buffer_value + other_vote_value\n",
    "    finalrounding.iloc[0, 6] = 0\n",
    "    other_vote_value = 0\n",
    "\n",
    "vote_dict = {\n",
    "    \"var1\": seizure_vote_value,\n",
    "    \"var2\": lpd_vote_value,\n",
    "    \"var3\": gpd_vote_value,\n",
    "    \"var4\": lrda_vote_value,\n",
    "    \"var5\": grda_vote_value,\n",
    "}\n",
    "\n",
    "biggest_var_name = max(vote_dict, key=vote_dict.get)\n",
    "biggest_value = vote_dict[biggest_var_name]\n",
    "\n",
    "if biggest_var_name == \"var1\":\n",
    "    finalrounding.iloc[0, 1] += buffer_value\n",
    "\n",
    "if biggest_var_name == \"var2\":\n",
    "    finalrounding.iloc[0, 2] += buffer_value\n",
    "\n",
    "if biggest_var_name == \"var3\":\n",
    "    finalrounding.iloc[0, 3] += buffer_value\n",
    "\n",
    "if biggest_var_name == \"var4\":\n",
    "    finalrounding.iloc[0, 4] += buffer_value\n",
    "\n",
    "if biggest_var_name == \"var5\":\n",
    "    finalrounding.iloc[0, 5] += buffer_value\n",
    "\n",
    "finalrounding.to_csv((f\"{config.output_path}submission.csv\"), index=False)\n",
    "finalrounding.iloc[:, -6:].sum(axis=1)\n",
    "display(finalrounding.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc5345e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T23:04:11.329528Z",
     "iopub.status.busy": "2024-03-13T23:04:11.329131Z",
     "iopub.status.idle": "2024-03-13T23:04:11.333494Z",
     "shell.execute_reply": "2024-03-13T23:04:11.332666Z"
    },
    "papermill": {
     "duration": 0.061633,
     "end_time": "2024-03-13T23:04:11.335479",
     "exception": false,
     "start_time": "2024-03-13T23:04:11.273846",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # SANITY CHECK TO CONFIRM PREDICTIONS SUM TO ONE\n",
    "# finalrounding.iloc[:, -6:].sum(axis=1)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 7469972,
     "sourceId": 59093,
     "sourceType": "competition"
    },
    {
     "datasetId": 4297749,
     "sourceId": 7392733,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4297782,
     "sourceId": 7392775,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4304475,
     "sourceId": 7402356,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4304949,
     "sourceId": 7403069,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4334995,
     "sourceId": 7447509,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4336944,
     "sourceId": 7450712,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4317718,
     "sourceId": 7465251,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4407194,
     "sourceId": 7570342,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4413439,
     "sourceId": 7581697,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4413451,
     "sourceId": 7581715,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4413454,
     "sourceId": 7581720,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4415285,
     "sourceId": 7585255,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4465437,
     "sourceId": 7658681,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4382744,
     "sourceId": 7752462,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4536784,
     "sourceId": 7758086,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4527518,
     "sourceId": 7775601,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4494069,
     "sourceId": 7781969,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4578701,
     "sourceId": 7815824,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4474441,
     "sourceId": 7818473,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4417235,
     "sourceId": 7818976,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4585029,
     "sourceId": 7824772,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4430326,
     "sourceId": 7825358,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4587588,
     "sourceId": 7828317,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 158958765,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 159333316,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 159396114,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 165733109,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 166854550,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30636,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 331.903874,
   "end_time": "2024-03-13T23:04:14.458796",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-03-13T22:58:42.554922",
   "version": "2.4.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "00131f6a820f442b8cd1018e796eb31b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "08d4a534556b4f05be30980f52450935": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_b7cd54ea6d9a4fd580de87c60f55bcb5",
        "IPY_MODEL_daf68bd9f83040a2bbb601db2b6a36f7",
        "IPY_MODEL_fda9ee359b724fe09a3026225581793d"
       ],
       "layout": "IPY_MODEL_e105b137466d4a3f8025c8ae8ed892f0"
      }
     },
     "09ff4c6b3112451f97be0f9afe2d67a5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "0b9b334212804a4a9d9bc9f2e80ec754": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "0bd108a65cfe4aec936d33a405759069": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_7779e47adeeb4883b2005bf309b81a11",
       "max": 1,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_0d5517d3f6dc4dcb9cc63ee6c753a477",
       "value": 1
      }
     },
     "0d5517d3f6dc4dcb9cc63ee6c753a477": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "0d78c94de5744909b58d83d4c16f3bf9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "0dde60f87df94304a6989306fd72a0aa": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_bbcdd79beda0483896913b176909d55c",
       "max": 1,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_0d78c94de5744909b58d83d4c16f3bf9",
       "value": 1
      }
     },
     "1020c6a9e72046948a6975f517ba6fbb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1527e46ab4e14e458e399cf6e539ce27": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1711da140b8c4206b68ea3da371c33a1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1b87f801e14647d69cbe372c7fb7f12c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "1eb3d69b1814430b81576d7a8ae03838": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "2325ed2c939f4d9594acf18bd9d7f025": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_ef72c8759a0d456ebd04ceddf74c244c",
       "placeholder": "",
       "style": "IPY_MODEL_1eb3d69b1814430b81576d7a8ae03838",
       "value": ""
      }
     },
     "2596cbe694a64b898e80d66e4f700e4f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "295d91eda6ef4e44a08971311577111b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "29f445f759b44422a1c73f94655041b8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "346a79dcf1d345dba5c56a3fc267c945": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "35bd7ca67a9c4b3199fefc40cb20b6a9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3bf56ed19fd642f6b00f281b57eae275": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_77a1b29f09754d97b78217b310fd0ec5",
       "placeholder": "",
       "style": "IPY_MODEL_8f86f84e15d945529b8d745b0f1c35e0",
       "value": " 1/? [00:00&lt;00:00, 41.33it/s]"
      }
     },
     "3fbb538096774e77a5f85c2a0c50e5ea": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "45b5d73411274e4abe504fc3e8554280": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_cb6b97662db04f43897b2d04c9ffd8f3",
        "IPY_MODEL_7075d99ed9724ede8b6b6c067619dc0d",
        "IPY_MODEL_abdbb87178354e00baa74f9dfc2f3465"
       ],
       "layout": "IPY_MODEL_904eb827ac334048aea862ca0b85e399"
      }
     },
     "4f76c9df2c174b0a9c2cf2b8cf57f7ca": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5167b9cce6dd4a2c9b7f95a0ba726830": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "55a5674aef5146f8a0de103f211bb05f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "61d0b78db53543218cc74ff13301ca2b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_3fbb538096774e77a5f85c2a0c50e5ea",
       "placeholder": "",
       "style": "IPY_MODEL_883962814c5b47929c8434f017712ea2",
       "value": " 1/1 [00:00&lt;00:00, 20.56test_batch/s]"
      }
     },
     "625b35993eb2478ea787a73d7f99f154": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "654a5c18dd304d20b58b1cad3fc1a64d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "66b260efcb8848819b6504d383754418": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "672ea483ba8e4057aca11eb0ab9f8956": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6818322263d7426c99f0e8e5752b5f38": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "69c00cf9ba7e4ace928ef4b29ec36d9e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_a77b9935ad9c44638fc36d22c0b18082",
       "max": 1,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_839ab2dc79344a57a31de3dbd21bc6ac",
       "value": 1
      }
     },
     "6f7b5be90b644eaaabd8d61e92238c28": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_b9f2f122cc0f4ad3a6e1cbf92f7453f9",
       "max": 1,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_00131f6a820f442b8cd1018e796eb31b",
       "value": 1
      }
     },
     "7075d99ed9724ede8b6b6c067619dc0d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_29f445f759b44422a1c73f94655041b8",
       "max": 1,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_768e279e854d4e4c87d74ff5ff88e72b",
       "value": 1
      }
     },
     "718ab258e7e845398c83474a53242b4f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": "20px"
      }
     },
     "7668d4507d9e4477994bacc32e8ff6b4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "768e279e854d4e4c87d74ff5ff88e72b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "7779e47adeeb4883b2005bf309b81a11": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "77a1b29f09754d97b78217b310fd0ec5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "77bed38cbdde4ac9a182ae38369fd3e5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7b7c8ff52a904eb4949608c787e10ff6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "80263e71f37147aa888a590ba1d95d1a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_b577cfdbacc5442c8df354f2062fae0e",
       "placeholder": "",
       "style": "IPY_MODEL_55a5674aef5146f8a0de103f211bb05f",
       "value": " 1/1 [00:00&lt;00:00, 22.98test_batch/s]"
      }
     },
     "80ec8800746a480f933525adb15c91ca": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_4f76c9df2c174b0a9c2cf2b8cf57f7ca",
       "placeholder": "",
       "style": "IPY_MODEL_346a79dcf1d345dba5c56a3fc267c945",
       "value": "Inference: 100%"
      }
     },
     "839ab2dc79344a57a31de3dbd21bc6ac": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "883962814c5b47929c8434f017712ea2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "8856bdf926a9448f98da6c45df70e578": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_09ff4c6b3112451f97be0f9afe2d67a5",
       "placeholder": "",
       "style": "IPY_MODEL_7b7c8ff52a904eb4949608c787e10ff6",
       "value": " 1/1 [00:00&lt;00:00, 21.39test_batch/s]"
      }
     },
     "88cab840867f4ec1b2aaba5806d92232": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_aea7f42f478c4fe7b58996813d5b2e86",
       "max": 1,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_625b35993eb2478ea787a73d7f99f154",
       "value": 1
      }
     },
     "896a92941e6f42fdbc48a02635fbbece": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_718ab258e7e845398c83474a53242b4f",
       "max": 1,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_5167b9cce6dd4a2c9b7f95a0ba726830",
       "value": 1
      }
     },
     "8a7ff9eebcc74d62a29c06dd78651c24": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_d42a95d6b2584d478d18aa633d68eb89",
        "IPY_MODEL_69c00cf9ba7e4ace928ef4b29ec36d9e",
        "IPY_MODEL_61d0b78db53543218cc74ff13301ca2b"
       ],
       "layout": "IPY_MODEL_9e75c806743a4de3a27be78e2034ad7f"
      }
     },
     "8f55a672064e4001837eded121c95b5d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "8f86f84e15d945529b8d745b0f1c35e0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "9011a56c773e41828de0d2396d2626f8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "904eb827ac334048aea862ca0b85e399": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "95b8d2f56bd34bdd9071bb00d6aa6a23": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "999ca6f7f54a44ed9c7e999214a2f219": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_77bed38cbdde4ac9a182ae38369fd3e5",
       "placeholder": "",
       "style": "IPY_MODEL_ccd659d0fdee4a2191cf1c08da657ed3",
       "value": " 1/1 [00:00&lt;00:00,  3.17test_batch/s]"
      }
     },
     "9e75c806743a4de3a27be78e2034ad7f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a2f4f5dcef684203810efc66fda4c4ae": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_f1e622ba531840e7903525da20bf9545",
        "IPY_MODEL_6f7b5be90b644eaaabd8d61e92238c28",
        "IPY_MODEL_d3a3bd819ecf493dac7960c3789a90f1"
       ],
       "layout": "IPY_MODEL_35bd7ca67a9c4b3199fefc40cb20b6a9"
      }
     },
     "a77b9935ad9c44638fc36d22c0b18082": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "abdbb87178354e00baa74f9dfc2f3465": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_0b9b334212804a4a9d9bc9f2e80ec754",
       "placeholder": "",
       "style": "IPY_MODEL_df29c0d41de74d63ae3bf77369193cf8",
       "value": " 1/1 [00:00&lt;00:00, 58.83it/s]"
      }
     },
     "aea7f42f478c4fe7b58996813d5b2e86": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b577cfdbacc5442c8df354f2062fae0e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b5a5534833614d048cebc20d36bd8818": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "b5ffec78b56f4b6a9ad78d96419f4728": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b7cd54ea6d9a4fd580de87c60f55bcb5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_2596cbe694a64b898e80d66e4f700e4f",
       "placeholder": "",
       "style": "IPY_MODEL_b5a5534833614d048cebc20d36bd8818",
       "value": "Inference: 100%"
      }
     },
     "b82d85d45cf741cdbf76ac7815711b3e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "b9f2f122cc0f4ad3a6e1cbf92f7453f9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "bbcdd79beda0483896913b176909d55c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c0ea3266324b4923848eebec74d6e777": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "c35f87b22b1b4f25afa38cab467c4754": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_6818322263d7426c99f0e8e5752b5f38",
       "placeholder": "",
       "style": "IPY_MODEL_1b87f801e14647d69cbe372c7fb7f12c",
       "value": "Inference: 100%"
      }
     },
     "c70c8d249c124c2fbe30ecf6b5deae9f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c869cea3326d484ab255fedb0d4a6afb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "c8f52b9280174715827f0bc03d92f8c8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_2325ed2c939f4d9594acf18bd9d7f025",
        "IPY_MODEL_896a92941e6f42fdbc48a02635fbbece",
        "IPY_MODEL_3bf56ed19fd642f6b00f281b57eae275"
       ],
       "layout": "IPY_MODEL_1527e46ab4e14e458e399cf6e539ce27"
      }
     },
     "cb6b97662db04f43897b2d04c9ffd8f3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_1711da140b8c4206b68ea3da371c33a1",
       "placeholder": "",
       "style": "IPY_MODEL_66b260efcb8848819b6504d383754418",
       "value": "100%"
      }
     },
     "ccd659d0fdee4a2191cf1c08da657ed3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "d3a3bd819ecf493dac7960c3789a90f1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_7668d4507d9e4477994bacc32e8ff6b4",
       "placeholder": "",
       "style": "IPY_MODEL_295d91eda6ef4e44a08971311577111b",
       "value": " 1/1 [00:00&lt;00:00, 36.31it/s]"
      }
     },
     "d3a98b81e16e4de2ac9b3f48b781fd5f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_672ea483ba8e4057aca11eb0ab9f8956",
       "placeholder": "",
       "style": "IPY_MODEL_c869cea3326d484ab255fedb0d4a6afb",
       "value": "Inference: 100%"
      }
     },
     "d42a95d6b2584d478d18aa633d68eb89": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_654a5c18dd304d20b58b1cad3fc1a64d",
       "placeholder": "",
       "style": "IPY_MODEL_8f55a672064e4001837eded121c95b5d",
       "value": "Inference: 100%"
      }
     },
     "daf68bd9f83040a2bbb601db2b6a36f7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_95b8d2f56bd34bdd9071bb00d6aa6a23",
       "max": 1,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_b82d85d45cf741cdbf76ac7815711b3e",
       "value": 1
      }
     },
     "df29c0d41de74d63ae3bf77369193cf8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "e105b137466d4a3f8025c8ae8ed892f0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e46e2410f1cd4503bdbf8390a58e63d4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e6f5fb77299a4b3695d883cc3dba7140": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_80ec8800746a480f933525adb15c91ca",
        "IPY_MODEL_0bd108a65cfe4aec936d33a405759069",
        "IPY_MODEL_80263e71f37147aa888a590ba1d95d1a"
       ],
       "layout": "IPY_MODEL_b5ffec78b56f4b6a9ad78d96419f4728"
      }
     },
     "ef72c8759a0d456ebd04ceddf74c244c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f1e622ba531840e7903525da20bf9545": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_e46e2410f1cd4503bdbf8390a58e63d4",
       "placeholder": "",
       "style": "IPY_MODEL_fb4d5f653fb147f0bcd1489ef445d31e",
       "value": "100%"
      }
     },
     "f636bb6b20674d6d8244636317b58d90": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_c35f87b22b1b4f25afa38cab467c4754",
        "IPY_MODEL_0dde60f87df94304a6989306fd72a0aa",
        "IPY_MODEL_8856bdf926a9448f98da6c45df70e578"
       ],
       "layout": "IPY_MODEL_c70c8d249c124c2fbe30ecf6b5deae9f"
      }
     },
     "fb4d5f653fb147f0bcd1489ef445d31e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "fd492bd3505442319543a05a9d75f058": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_d3a98b81e16e4de2ac9b3f48b781fd5f",
        "IPY_MODEL_88cab840867f4ec1b2aaba5806d92232",
        "IPY_MODEL_999ca6f7f54a44ed9c7e999214a2f219"
       ],
       "layout": "IPY_MODEL_9011a56c773e41828de0d2396d2626f8"
      }
     },
     "fda9ee359b724fe09a3026225581793d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_1020c6a9e72046948a6975f517ba6fbb",
       "placeholder": "",
       "style": "IPY_MODEL_c0ea3266324b4923848eebec74d6e777",
       "value": " 1/1 [00:00&lt;00:00, 21.21test_batch/s]"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
